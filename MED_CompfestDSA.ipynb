{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statistics import LinearRegression\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Alkalinity, total</th>\n",
       "      <th>Calcium</th>\n",
       "      <th>Chloride</th>\n",
       "      <th>Fluoride</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Nitrate as N</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>Specific Conductivity</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Total Dissolved Solids</th>\n",
       "      <th>Hardness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.314</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.498</td>\n",
       "      <td>48.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>23.20</td>\n",
       "      <td>240.0</td>\n",
       "      <td>90.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>140.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.150</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.950</td>\n",
       "      <td>19.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>190.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>160.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.450</td>\n",
       "      <td>9.1</td>\n",
       "      <td>2.500</td>\n",
       "      <td>12.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>230.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>46.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.120</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.430</td>\n",
       "      <td>6.4</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>240.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>48.0</td>\n",
       "      <td>6.800</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>418.00</td>\n",
       "      <td>950.0</td>\n",
       "      <td>586.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6395</th>\n",
       "      <td>6395</td>\n",
       "      <td>180.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.180</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.600</td>\n",
       "      <td>22.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>48.00</td>\n",
       "      <td>400.0</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6396</th>\n",
       "      <td>6396</td>\n",
       "      <td>44.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.120</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.470</td>\n",
       "      <td>5.9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>56.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6397</th>\n",
       "      <td>6397</td>\n",
       "      <td>138.0</td>\n",
       "      <td>40.3</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.100</td>\n",
       "      <td>14.2</td>\n",
       "      <td>8.600</td>\n",
       "      <td>31.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>17.70</td>\n",
       "      <td>300.0</td>\n",
       "      <td>159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6398</th>\n",
       "      <td>6398</td>\n",
       "      <td>210.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.230</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.900</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>140.00</td>\n",
       "      <td>800.0</td>\n",
       "      <td>470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6399</th>\n",
       "      <td>6399</td>\n",
       "      <td>175.0</td>\n",
       "      <td>63.1</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.470</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.700</td>\n",
       "      <td>37.6</td>\n",
       "      <td>518.0</td>\n",
       "      <td>57.60</td>\n",
       "      <td>306.0</td>\n",
       "      <td>203.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6400 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  Alkalinity, total  Calcium  Chloride  Fluoride  Magnesium  \\\n",
       "0        0              120.0     24.0       6.9     0.314        7.1   \n",
       "1        1              140.0     41.0      11.0     0.150        6.5   \n",
       "2        2              160.0     51.0       9.0     0.450        9.1   \n",
       "3        3               46.0     13.0       2.9     0.120        2.7   \n",
       "4        4              240.0    147.0      70.0     0.600       48.0   \n",
       "...    ...                ...      ...       ...       ...        ...   \n",
       "6395  6395              180.0     58.0      40.0     0.180       25.0   \n",
       "6396  6396               44.0      5.7       3.0     0.120        3.7   \n",
       "6397  6397              138.0     40.3      28.4     0.100       14.2   \n",
       "6398  6398              210.0    110.0     190.0     0.230       47.0   \n",
       "6399  6399              175.0     63.1      26.8     0.470       11.2   \n",
       "\n",
       "      Nitrate as N  Sodium  Specific Conductivity  Sulfate  \\\n",
       "0            0.498    48.0                  510.0    23.20   \n",
       "1            0.950    19.0                  300.0     8.50   \n",
       "2            2.500    12.0                  370.0    25.00   \n",
       "3            0.430     6.4                  110.0     5.00   \n",
       "4            6.800    93.0                 1410.0   418.00   \n",
       "...            ...     ...                    ...      ...   \n",
       "6395         3.600    22.0                  540.0    48.00   \n",
       "6396         0.470     5.9                  100.0     0.85   \n",
       "6397         8.600    31.0                  438.0    17.70   \n",
       "6398         7.900   120.0                 1400.0   140.00   \n",
       "6399         0.700    37.6                  518.0    57.60   \n",
       "\n",
       "      Total Dissolved Solids  Hardness  \n",
       "0                      240.0      90.4  \n",
       "1                      190.0     130.0  \n",
       "2                      230.0     160.0  \n",
       "3                       97.0      41.0  \n",
       "4                      950.0     586.0  \n",
       "...                      ...       ...  \n",
       "6395                   400.0     219.0  \n",
       "6396                    56.0      30.0  \n",
       "6397                   300.0     159.0  \n",
       "6398                   800.0     470.0  \n",
       "6399                   306.0     203.0  \n",
       "\n",
       "[6400 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Alkalinity, total</th>\n",
       "      <th>Calcium</th>\n",
       "      <th>Chloride</th>\n",
       "      <th>Fluoride</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Nitrate as N</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>Specific Conductivity</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Total Dissolved Solids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1601.000000</td>\n",
       "      <td>1601.000000</td>\n",
       "      <td>1601.000000</td>\n",
       "      <td>1601.000000</td>\n",
       "      <td>1601.000000</td>\n",
       "      <td>1601.000000</td>\n",
       "      <td>1601.000000</td>\n",
       "      <td>1601.000000</td>\n",
       "      <td>1601.000000</td>\n",
       "      <td>1601.000000</td>\n",
       "      <td>1601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7200.000000</td>\n",
       "      <td>168.832299</td>\n",
       "      <td>55.668958</td>\n",
       "      <td>51.481462</td>\n",
       "      <td>0.349397</td>\n",
       "      <td>62.757297</td>\n",
       "      <td>3.423275</td>\n",
       "      <td>77.886431</td>\n",
       "      <td>659.276702</td>\n",
       "      <td>75.164221</td>\n",
       "      <td>409.850094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>462.313206</td>\n",
       "      <td>82.953613</td>\n",
       "      <td>41.717342</td>\n",
       "      <td>77.520902</td>\n",
       "      <td>0.551632</td>\n",
       "      <td>1724.080876</td>\n",
       "      <td>4.968633</td>\n",
       "      <td>780.983717</td>\n",
       "      <td>620.275872</td>\n",
       "      <td>121.649147</td>\n",
       "      <td>271.134286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6400.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6800.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>230.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7200.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>46.200000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>330.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7600.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>815.000000</td>\n",
       "      <td>94.600000</td>\n",
       "      <td>510.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8000.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>69000.000000</td>\n",
       "      <td>58.200000</td>\n",
       "      <td>27400.000000</td>\n",
       "      <td>17400.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  Alkalinity, total      Calcium     Chloride     Fluoride  \\\n",
       "count  1601.000000        1601.000000  1601.000000  1601.000000  1601.000000   \n",
       "mean   7200.000000         168.832299    55.668958    51.481462     0.349397   \n",
       "std     462.313206          82.953613    41.717342    77.520902     0.551632   \n",
       "min    6400.000000           9.400000     0.260000     0.460000     0.000000   \n",
       "25%    6800.000000         110.000000    26.000000    12.000000     0.140000   \n",
       "50%    7200.000000         160.000000    46.200000    31.000000     0.210000   \n",
       "75%    7600.000000         210.000000    74.000000    63.000000     0.380000   \n",
       "max    8000.000000         700.000000   460.000000  1300.000000     9.900000   \n",
       "\n",
       "          Magnesium  Nitrate as N        Sodium  Specific Conductivity  \\\n",
       "count   1601.000000   1601.000000   1601.000000            1601.000000   \n",
       "mean      62.757297      3.423275     77.886431             659.276702   \n",
       "std     1724.080876      4.968633    780.983717             620.275872   \n",
       "min        0.064000      0.004740      2.200000              66.000000   \n",
       "25%        7.800000      0.770000     21.000000             351.000000   \n",
       "50%       15.000000      2.000000     35.000000             530.000000   \n",
       "75%       25.000000      4.300000     61.000000             815.000000   \n",
       "max    69000.000000     58.200000  27400.000000           17400.000000   \n",
       "\n",
       "           Sulfate  Total Dissolved Solids  \n",
       "count  1601.000000             1601.000000  \n",
       "mean     75.164221              409.850094  \n",
       "std     121.649147              271.134286  \n",
       "min       0.390000               29.000000  \n",
       "25%      13.100000              230.000000  \n",
       "50%      34.000000              330.000000  \n",
       "75%      94.600000              510.000000  \n",
       "max    2100.000000             2300.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6400 entries, 0 to 6399\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   id                      6400 non-null   int64  \n",
      " 1   Alkalinity, total       6400 non-null   float64\n",
      " 2   Calcium                 6400 non-null   float64\n",
      " 3   Chloride                6400 non-null   float64\n",
      " 4   Fluoride                6400 non-null   float64\n",
      " 5   Magnesium               6400 non-null   float64\n",
      " 6   Nitrate as N            6400 non-null   float64\n",
      " 7   Sodium                  6400 non-null   float64\n",
      " 8   Specific Conductivity   6400 non-null   float64\n",
      " 9   Sulfate                 6400 non-null   float64\n",
      " 10  Total Dissolved Solids  6400 non-null   float64\n",
      " 11  Hardness                6400 non-null   float64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 600.1 KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Alkalinity, total</th>\n",
       "      <th>Calcium</th>\n",
       "      <th>Chloride</th>\n",
       "      <th>Fluoride</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Nitrate as N</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>Specific Conductivity</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Total Dissolved Solids</th>\n",
       "      <th>Hardness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6400.000000</td>\n",
       "      <td>6400.000000</td>\n",
       "      <td>6400.000000</td>\n",
       "      <td>6400.000000</td>\n",
       "      <td>6400.000000</td>\n",
       "      <td>6400.000000</td>\n",
       "      <td>6400.000000</td>\n",
       "      <td>6400.000000</td>\n",
       "      <td>6400.000000</td>\n",
       "      <td>6400.000000</td>\n",
       "      <td>6400.000000</td>\n",
       "      <td>6400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3199.500000</td>\n",
       "      <td>167.151047</td>\n",
       "      <td>69.350432</td>\n",
       "      <td>53.213620</td>\n",
       "      <td>0.333625</td>\n",
       "      <td>23.446335</td>\n",
       "      <td>3.382707</td>\n",
       "      <td>62.437731</td>\n",
       "      <td>637.631953</td>\n",
       "      <td>71.645934</td>\n",
       "      <td>409.570669</td>\n",
       "      <td>216.148203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1847.665193</td>\n",
       "      <td>83.157803</td>\n",
       "      <td>1052.136452</td>\n",
       "      <td>92.934505</td>\n",
       "      <td>0.452473</td>\n",
       "      <td>325.389503</td>\n",
       "      <td>4.878279</td>\n",
       "      <td>556.891904</td>\n",
       "      <td>597.297274</td>\n",
       "      <td>108.414049</td>\n",
       "      <td>302.958442</td>\n",
       "      <td>161.431526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>19.580000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1599.750000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>101.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3199.500000</td>\n",
       "      <td>153.500000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4799.250000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.382250</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>281.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6399.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>83000.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>26000.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>32000.000000</td>\n",
       "      <td>31400.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>4100.000000</td>\n",
       "      <td>1901.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  Alkalinity, total       Calcium     Chloride     Fluoride  \\\n",
       "count  6400.000000        6400.000000   6400.000000  6400.000000  6400.000000   \n",
       "mean   3199.500000         167.151047     69.350432    53.213620     0.333625   \n",
       "std    1847.665193          83.157803   1052.136452    92.934505     0.452473   \n",
       "min       0.000000          12.000000      0.610000     0.580000     0.049000   \n",
       "25%    1599.750000         110.000000     25.000000    11.000000     0.140000   \n",
       "50%    3199.500000         153.500000     45.000000    28.000000     0.210000   \n",
       "75%    4799.250000         209.000000     72.000000    62.000000     0.382250   \n",
       "max    6399.000000        1000.000000  83000.000000  2100.000000     9.000000   \n",
       "\n",
       "          Magnesium  Nitrate as N        Sodium  Specific Conductivity  \\\n",
       "count   6400.000000   6400.000000   6400.000000            6400.000000   \n",
       "mean      23.446335      3.382707     62.437731             637.631953   \n",
       "std      325.389503      4.878279    556.891904             597.297274   \n",
       "min        0.051000      0.002300      1.300000              40.000000   \n",
       "25%        7.300000      0.850000     21.000000             340.000000   \n",
       "50%       14.000000      2.000000     35.000000             520.000000   \n",
       "75%       25.000000      4.300000     60.000000             800.000000   \n",
       "max    26000.000000    106.000000  32000.000000           31400.000000   \n",
       "\n",
       "           Sulfate  Total Dissolved Solids     Hardness  \n",
       "count  6400.000000             6400.000000  6400.000000  \n",
       "mean     71.645934              409.570669   216.148203  \n",
       "std     108.414049              302.958442   161.431526  \n",
       "min       0.140000               19.580000     2.500000  \n",
       "25%      13.000000              220.000000   101.000000  \n",
       "50%      33.000000              320.000000   180.000000  \n",
       "75%      85.000000              500.000000   281.000000  \n",
       "max    2000.000000             4100.000000  1901.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Unuse Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alkalinity, total         0\n",
       "Calcium                   0\n",
       "Chloride                  0\n",
       "Fluoride                  0\n",
       "Magnesium                 0\n",
       "Nitrate as N              0\n",
       "Sodium                    0\n",
       "Specific Conductivity     0\n",
       "Sulfate                   0\n",
       "Total Dissolved Solids    0\n",
       "Hardness                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_outliers_iqr(df):\n",
    "    outliers_percentage = {}\n",
    "    for column in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outliers = ((df[column] < lower_bound) | (df[column] > upper_bound)).sum()\n",
    "        total = len(df[column])\n",
    "        percentage = (outliers / total) * 100\n",
    "        outliers_percentage[column] = percentage\n",
    "    return outliers_percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_percentage = percentage_outliers_iqr(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeOutlier(df, col):\n",
    "    kuartil1 = col.quantile(0.25)\n",
    "    kuartil3 = col.quantile(0.75)\n",
    "    IQR = kuartil3 - kuartil1\n",
    "    lower_bound = kuartil1 - 1.5 * IQR\n",
    "    upper_bound = kuartil3 + 1.5 * IQR\n",
    "    df = df[(col >= lower_bound) & (col <= upper_bound)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_df = train_df.copy()\n",
    "\n",
    "outliers_percentage = percentage_outliers_iqr(clean_train_df)\n",
    "\n",
    "for col in clean_train_df.columns:\n",
    "    if col != \"id\" and clean_train_df[col].dtypes != object:\n",
    "        if outliers_percentage[col] > 5:\n",
    "            clean_train_df[col] = np.log1p(clean_train_df[col])\n",
    "        else:\n",
    "            clean_train_df = removeOutlier(clean_train_df, clean_train_df[col])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alkalinity, total</th>\n",
       "      <th>Calcium</th>\n",
       "      <th>Chloride</th>\n",
       "      <th>Fluoride</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Nitrate as N</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>Specific Conductivity</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Total Dissolved Solids</th>\n",
       "      <th>Hardness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.066863</td>\n",
       "      <td>0.273076</td>\n",
       "      <td>2.091864</td>\n",
       "      <td>0.404131</td>\n",
       "      <td>3.891820</td>\n",
       "      <td>510.0</td>\n",
       "      <td>3.186353</td>\n",
       "      <td>5.484797</td>\n",
       "      <td>90.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>0.139762</td>\n",
       "      <td>2.014903</td>\n",
       "      <td>0.667829</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2.251292</td>\n",
       "      <td>5.252273</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>160.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>0.371564</td>\n",
       "      <td>2.312535</td>\n",
       "      <td>1.252763</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>370.0</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>5.442418</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.360977</td>\n",
       "      <td>0.113329</td>\n",
       "      <td>1.308333</td>\n",
       "      <td>0.357674</td>\n",
       "      <td>2.001480</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>4.584967</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>154.0</td>\n",
       "      <td>49.2</td>\n",
       "      <td>3.951244</td>\n",
       "      <td>0.223144</td>\n",
       "      <td>2.451005</td>\n",
       "      <td>0.438255</td>\n",
       "      <td>3.964615</td>\n",
       "      <td>619.0</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>5.826000</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6393</th>\n",
       "      <td>115.0</td>\n",
       "      <td>27.9</td>\n",
       "      <td>2.766319</td>\n",
       "      <td>0.095310</td>\n",
       "      <td>2.322388</td>\n",
       "      <td>1.360977</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>292.0</td>\n",
       "      <td>1.629241</td>\n",
       "      <td>5.384495</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6395</th>\n",
       "      <td>180.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>0.165514</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>1.526056</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.891820</td>\n",
       "      <td>5.993961</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6396</th>\n",
       "      <td>44.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.113329</td>\n",
       "      <td>1.547563</td>\n",
       "      <td>0.385262</td>\n",
       "      <td>1.931521</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.615186</td>\n",
       "      <td>4.043051</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6397</th>\n",
       "      <td>138.0</td>\n",
       "      <td>40.3</td>\n",
       "      <td>3.380995</td>\n",
       "      <td>0.095310</td>\n",
       "      <td>2.721295</td>\n",
       "      <td>2.261763</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>438.0</td>\n",
       "      <td>2.928524</td>\n",
       "      <td>5.707110</td>\n",
       "      <td>159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6399</th>\n",
       "      <td>175.0</td>\n",
       "      <td>63.1</td>\n",
       "      <td>3.325036</td>\n",
       "      <td>0.385262</td>\n",
       "      <td>2.501436</td>\n",
       "      <td>0.530628</td>\n",
       "      <td>3.653252</td>\n",
       "      <td>518.0</td>\n",
       "      <td>4.070735</td>\n",
       "      <td>5.726848</td>\n",
       "      <td>203.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5770 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Alkalinity, total  Calcium  Chloride  Fluoride  Magnesium  Nitrate as N  \\\n",
       "0                 120.0     24.0  2.066863  0.273076   2.091864      0.404131   \n",
       "1                 140.0     41.0  2.484907  0.139762   2.014903      0.667829   \n",
       "2                 160.0     51.0  2.302585  0.371564   2.312535      1.252763   \n",
       "3                  46.0     13.0  1.360977  0.113329   1.308333      0.357674   \n",
       "5                 154.0     49.2  3.951244  0.223144   2.451005      0.438255   \n",
       "...                 ...      ...       ...       ...        ...           ...   \n",
       "6393              115.0     27.9  2.766319  0.095310   2.322388      1.360977   \n",
       "6395              180.0     58.0  3.713572  0.165514   3.258097      1.526056   \n",
       "6396               44.0      5.7  1.386294  0.113329   1.547563      0.385262   \n",
       "6397              138.0     40.3  3.380995  0.095310   2.721295      2.261763   \n",
       "6399              175.0     63.1  3.325036  0.385262   2.501436      0.530628   \n",
       "\n",
       "        Sodium  Specific Conductivity   Sulfate  Total Dissolved Solids  \\\n",
       "0     3.891820                  510.0  3.186353                5.484797   \n",
       "1     2.995732                  300.0  2.251292                5.252273   \n",
       "2     2.564949                  370.0  3.258097                5.442418   \n",
       "3     2.001480                  110.0  1.791759                4.584967   \n",
       "5     3.964615                  619.0  4.615121                5.826000   \n",
       "...        ...                    ...       ...                     ...   \n",
       "6393  3.091042                  292.0  1.629241                5.384495   \n",
       "6395  3.135494                  540.0  3.891820                5.993961   \n",
       "6396  1.931521                  100.0  0.615186                4.043051   \n",
       "6397  3.465736                  438.0  2.928524                5.707110   \n",
       "6399  3.653252                  518.0  4.070735                5.726848   \n",
       "\n",
       "      Hardness  \n",
       "0         90.4  \n",
       "1        130.0  \n",
       "2        160.0  \n",
       "3         41.0  \n",
       "5        198.0  \n",
       "...        ...  \n",
       "6393     113.0  \n",
       "6395     219.0  \n",
       "6396      30.0  \n",
       "6397     159.0  \n",
       "6399     203.0  \n",
       "\n",
       "[5770 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alkalinity, total</th>\n",
       "      <th>Calcium</th>\n",
       "      <th>Chloride</th>\n",
       "      <th>Fluoride</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Nitrate as N</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>Specific Conductivity</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Total Dissolved Solids</th>\n",
       "      <th>Hardness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5770.000000</td>\n",
       "      <td>5770.000000</td>\n",
       "      <td>5770.000000</td>\n",
       "      <td>5770.000000</td>\n",
       "      <td>5770.000000</td>\n",
       "      <td>5770.000000</td>\n",
       "      <td>5770.000000</td>\n",
       "      <td>5770.000000</td>\n",
       "      <td>5770.000000</td>\n",
       "      <td>5770.000000</td>\n",
       "      <td>5770.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>154.255494</td>\n",
       "      <td>46.671512</td>\n",
       "      <td>3.201088</td>\n",
       "      <td>0.253165</td>\n",
       "      <td>2.529553</td>\n",
       "      <td>1.156416</td>\n",
       "      <td>3.511040</td>\n",
       "      <td>531.407192</td>\n",
       "      <td>3.352391</td>\n",
       "      <td>5.717488</td>\n",
       "      <td>181.621282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>64.660236</td>\n",
       "      <td>28.259291</td>\n",
       "      <td>1.015936</td>\n",
       "      <td>0.196209</td>\n",
       "      <td>0.812991</td>\n",
       "      <td>0.669267</td>\n",
       "      <td>0.692113</td>\n",
       "      <td>266.130708</td>\n",
       "      <td>1.140360</td>\n",
       "      <td>0.496596</td>\n",
       "      <td>105.101574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.457425</td>\n",
       "      <td>0.047837</td>\n",
       "      <td>0.049742</td>\n",
       "      <td>0.002297</td>\n",
       "      <td>0.832909</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.131028</td>\n",
       "      <td>3.024320</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>110.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>0.122218</td>\n",
       "      <td>2.054124</td>\n",
       "      <td>0.604316</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>2.553321</td>\n",
       "      <td>5.353040</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>41.200000</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>0.182322</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>5.707110</td>\n",
       "      <td>160.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>190.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>3.970292</td>\n",
       "      <td>0.314811</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>1.620376</td>\n",
       "      <td>3.970292</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>4.219508</td>\n",
       "      <td>6.066108</td>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>355.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>6.523562</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>10.165890</td>\n",
       "      <td>4.044804</td>\n",
       "      <td>10.373522</td>\n",
       "      <td>1350.000000</td>\n",
       "      <td>6.311735</td>\n",
       "      <td>7.741099</td>\n",
       "      <td>487.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Alkalinity, total      Calcium     Chloride     Fluoride    Magnesium  \\\n",
       "count        5770.000000  5770.000000  5770.000000  5770.000000  5770.000000   \n",
       "mean          154.255494    46.671512     3.201088     0.253165     2.529553   \n",
       "std            64.660236    28.259291     1.015936     0.196209     0.812991   \n",
       "min            21.000000     1.000000     0.457425     0.047837     0.049742   \n",
       "25%           110.000000    24.000000     2.397895     0.122218     2.054124   \n",
       "50%           150.000000    41.200000     3.218876     0.182322     2.639057   \n",
       "75%           190.000000    65.000000     3.970292     0.314811     3.091042   \n",
       "max           355.000000   140.000000     6.523562     2.302585    10.165890   \n",
       "\n",
       "       Nitrate as N       Sodium  Specific Conductivity      Sulfate  \\\n",
       "count   5770.000000  5770.000000            5770.000000  5770.000000   \n",
       "mean       1.156416     3.511040             531.407192     3.352391   \n",
       "std        0.669267     0.692113             266.130708     1.140360   \n",
       "min        0.002297     0.832909              40.000000     0.131028   \n",
       "25%        0.604316     3.044522             320.000000     2.553321   \n",
       "50%        1.098612     3.496508             480.000000     3.367296   \n",
       "75%        1.620376     3.970292             690.000000     4.219508   \n",
       "max        4.044804    10.373522            1350.000000     6.311735   \n",
       "\n",
       "       Total Dissolved Solids     Hardness  \n",
       "count             5770.000000  5770.000000  \n",
       "mean                 5.717488   181.621282  \n",
       "std                  0.496596   105.101574  \n",
       "min                  3.024320     3.500000  \n",
       "25%                  5.353040    99.000000  \n",
       "50%                  5.707110   160.000000  \n",
       "75%                  6.066108   250.000000  \n",
       "max                  7.741099   487.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LABEL CORRELATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the correlation matrix\n",
    "correlation_matrix = clean_train_df.corr()\n",
    "\n",
    "# Create a heatmap using seaborn\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL CREATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(columns=['Hardness'])\n",
    "y = train_df['Hardness']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6400.000000\n",
       "mean      216.148203\n",
       "std       161.431526\n",
       "min         2.500000\n",
       "25%       101.000000\n",
       "50%       180.000000\n",
       "75%       281.000000\n",
       "max      1901.000000\n",
       "Name: Hardness, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train)\n",
    "# X_train_scaled = scaler.transform(X_train)\n",
    "# X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Train the linear regression model\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = linear_reg.predict(X_train)\n",
    "y_val_pred = linear_reg.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9124644481700032\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'n_estimators': 76, 'max_depth': 32, 'min_samples_split': 2, 'min_samples_leaf': 1} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "best_params['random_state'] = 42\n",
    "random_forest = RandomForestRegressor(**best_params)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = random_forest.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9874729199454221\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(y_train, y_pred)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6914058841324628\n",
      "0.7683241238385222\n",
      "0.7752946624404238\n",
      "0.7937559926607152\n",
      "0.8035613755781128\n",
      "0.8162099946419373\n",
      "0.8097268503385763\n",
      "0.8036862193706299\n",
      "0.8072747629740007\n",
      "0.8143245399767691\n",
      "0.8099791409747046\n",
      "0.8083892020037934\n",
      "0.807273601569975\n",
      "0.8084491698294257\n",
      "0.8066609788492093\n",
      "0.8050311233133222\n",
      "0.8012550245860461\n",
      "0.8024463727219036\n",
      "0.8049619742056842\n",
      "0.8056529925826081\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "rmse_val = [] \n",
    "for K in range(20):\n",
    "    K = K+1\n",
    "    knn = neighbors.KNeighborsRegressor(n_neighbors = K)\n",
    "\n",
    "    knn.fit(X_train, y_train) \n",
    "    y_pred = knn.predict(X_val) \n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STACK: RF, KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "\n",
    "estimators = [('Random Forest', random_forest),\n",
    "              ('KNN', knn)]\n",
    "\n",
    "stacking_regressor_rf_knn = StackingRegressor(estimators=estimators, final_estimator=RidgeCV())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9094403009579306\n"
     ]
    }
   ],
   "source": [
    "stacking_regressor_rf_knn.fit(X_train, y_train) \n",
    "y_pred = stacking_regressor_rf_knn.predict(X_val) \n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STACK: KNN, RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "\n",
    "estimators = [('KNN', knn),\n",
    "              ('Random Forest', random_forest)]\n",
    "\n",
    "stacking_regressor_knn_rf = StackingRegressor(estimators=estimators, final_estimator=RidgeCV())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9094403013469152\n"
     ]
    }
   ],
   "source": [
    "stacking_regressor_knn_rf.fit(X_train, y_train) \n",
    "y_pred = stacking_regressor_knn_rf.predict(X_val) \n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:132.27989\tvalidation_1-rmse:136.97766\n",
      "[5]\tvalidation_0-rmse:60.02178\tvalidation_1-rmse:66.30036\n",
      "[10]\tvalidation_0-rmse:39.71821\tvalidation_1-rmse:47.82295\n",
      "[15]\tvalidation_0-rmse:32.47075\tvalidation_1-rmse:45.04887\n",
      "[20]\tvalidation_0-rmse:29.79959\tvalidation_1-rmse:44.43256\n",
      "[24]\tvalidation_0-rmse:28.81389\tvalidation_1-rmse:44.23375\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=2,\n",
       "             enable_categorical=False, eval_metric=&#x27;rmse&#x27;, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=25, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBRegressor<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=2,\n",
       "             enable_categorical=False, eval_metric=&#x27;rmse&#x27;, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=25, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=0, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=2,\n",
       "             enable_categorical=False, eval_metric='rmse', feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=25, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=0, ...)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_r = xgb.XGBRegressor(n_estimators=25, \n",
    "                         objective=\"reg:squarederror\", \n",
    "                         eval_metric=\"rmse\",\n",
    "                         early_stopping_rounds=2, \n",
    "                         learning_rate=0.2, \n",
    "                         random_state=0)\n",
    "\n",
    "xgb_r.fit(X_train, y_train,\n",
    "          eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "          verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9290308494441567\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_r.predict(X_val) \n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STACK: RF, XGBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingCVRegressor(meta_regressor=XGBRegressor(base_score=None, booster=None,\n",
       "                                                callbacks=None,\n",
       "                                                colsample_bylevel=None,\n",
       "                                                colsample_bynode=None,\n",
       "                                                colsample_bytree=None,\n",
       "                                                device=None,\n",
       "                                                early_stopping_rounds=None,\n",
       "                                                enable_categorical=False,\n",
       "                                                eval_metric=None,\n",
       "                                                feature_types=None, gamma=None,\n",
       "                                                grow_policy=None,\n",
       "                                                importance_type=None,\n",
       "                                                interaction_constraints=None,\n",
       "                                                learning_rate...\n",
       "                                             learning_rate=None, max_bin=None,\n",
       "                                             max_cat_threshold=None,\n",
       "                                             max_cat_to_onehot=None,\n",
       "                                             max_delta_step=None,\n",
       "                                             max_depth=None, max_leaves=None,\n",
       "                                             min_child_weight=None, missing=nan,\n",
       "                                             monotone_constraints=None,\n",
       "                                             multi_strategy=None,\n",
       "                                             n_estimators=None, n_jobs=None,\n",
       "                                             num_parallel_tree=None,\n",
       "                                             random_state=None, ...)),\n",
       "                    shuffle=False, store_train_meta_features=True,\n",
       "                    use_features_in_secondary=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StackingCVRegressor<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>StackingCVRegressor(meta_regressor=XGBRegressor(base_score=None, booster=None,\n",
       "                                                callbacks=None,\n",
       "                                                colsample_bylevel=None,\n",
       "                                                colsample_bynode=None,\n",
       "                                                colsample_bytree=None,\n",
       "                                                device=None,\n",
       "                                                early_stopping_rounds=None,\n",
       "                                                enable_categorical=False,\n",
       "                                                eval_metric=None,\n",
       "                                                feature_types=None, gamma=None,\n",
       "                                                grow_policy=None,\n",
       "                                                importance_type=None,\n",
       "                                                interaction_constraints=None,\n",
       "                                                learning_rate...\n",
       "                                             learning_rate=None, max_bin=None,\n",
       "                                             max_cat_threshold=None,\n",
       "                                             max_cat_to_onehot=None,\n",
       "                                             max_delta_step=None,\n",
       "                                             max_depth=None, max_leaves=None,\n",
       "                                             min_child_weight=None, missing=nan,\n",
       "                                             monotone_constraints=None,\n",
       "                                             multi_strategy=None,\n",
       "                                             n_estimators=None, n_jobs=None,\n",
       "                                             num_parallel_tree=None,\n",
       "                                             random_state=None, ...)),\n",
       "                    shuffle=False, store_train_meta_features=True,\n",
       "                    use_features_in_secondary=True)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">meta_regressor: XGBRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingCVRegressor(meta_regressor=XGBRegressor(base_score=None, booster=None,\n",
       "                                                callbacks=None,\n",
       "                                                colsample_bylevel=None,\n",
       "                                                colsample_bynode=None,\n",
       "                                                colsample_bytree=None,\n",
       "                                                device=None,\n",
       "                                                early_stopping_rounds=None,\n",
       "                                                enable_categorical=False,\n",
       "                                                eval_metric=None,\n",
       "                                                feature_types=None, gamma=None,\n",
       "                                                grow_policy=None,\n",
       "                                                importance_type=None,\n",
       "                                                interaction_constraints=None,\n",
       "                                                learning_rate...\n",
       "                                             learning_rate=None, max_bin=None,\n",
       "                                             max_cat_threshold=None,\n",
       "                                             max_cat_to_onehot=None,\n",
       "                                             max_delta_step=None,\n",
       "                                             max_depth=None, max_leaves=None,\n",
       "                                             min_child_weight=None, missing=nan,\n",
       "                                             monotone_constraints=None,\n",
       "                                             multi_strategy=None,\n",
       "                                             n_estimators=None, n_jobs=None,\n",
       "                                             num_parallel_tree=None,\n",
       "                                             random_state=None, ...)),\n",
       "                    shuffle=False, store_train_meta_features=True,\n",
       "                    use_features_in_secondary=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "xgb = XGBRegressor()\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "stacking_regressor_rf_xgb = StackingCVRegressor(regressors=(rf, xgb),\n",
    "                            meta_regressor=xgb, cv=5,\n",
    "                            use_features_in_secondary=True,\n",
    "                            store_train_meta_features=True,\n",
    "                            shuffle=False,\n",
    "                            random_state=42)\n",
    "\n",
    "stacking_regressor_rf_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingCVRegressor(meta_regressor=RandomForestRegressor(), random_state=42,\n",
       "                    regressors=(XGBRegressor(base_score=None, booster=None,\n",
       "                                             callbacks=None,\n",
       "                                             colsample_bylevel=None,\n",
       "                                             colsample_bynode=None,\n",
       "                                             colsample_bytree=None, device=None,\n",
       "                                             early_stopping_rounds=None,\n",
       "                                             enable_categorical=False,\n",
       "                                             eval_metric=None,\n",
       "                                             feature_types=None, gamma=None,\n",
       "                                             grow_policy=None,\n",
       "                                             importance_...\n",
       "                                             max_cat_threshold=None,\n",
       "                                             max_cat_to_onehot=None,\n",
       "                                             max_delta_step=None,\n",
       "                                             max_depth=None, max_leaves=None,\n",
       "                                             min_child_weight=None, missing=nan,\n",
       "                                             monotone_constraints=None,\n",
       "                                             multi_strategy=None,\n",
       "                                             n_estimators=None, n_jobs=None,\n",
       "                                             num_parallel_tree=None,\n",
       "                                             random_state=None, ...),\n",
       "                                RandomForestRegressor()),\n",
       "                    shuffle=False, store_train_meta_features=True,\n",
       "                    use_features_in_secondary=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StackingCVRegressor<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>StackingCVRegressor(meta_regressor=RandomForestRegressor(), random_state=42,\n",
       "                    regressors=(XGBRegressor(base_score=None, booster=None,\n",
       "                                             callbacks=None,\n",
       "                                             colsample_bylevel=None,\n",
       "                                             colsample_bynode=None,\n",
       "                                             colsample_bytree=None, device=None,\n",
       "                                             early_stopping_rounds=None,\n",
       "                                             enable_categorical=False,\n",
       "                                             eval_metric=None,\n",
       "                                             feature_types=None, gamma=None,\n",
       "                                             grow_policy=None,\n",
       "                                             importance_...\n",
       "                                             max_cat_threshold=None,\n",
       "                                             max_cat_to_onehot=None,\n",
       "                                             max_delta_step=None,\n",
       "                                             max_depth=None, max_leaves=None,\n",
       "                                             min_child_weight=None, missing=nan,\n",
       "                                             monotone_constraints=None,\n",
       "                                             multi_strategy=None,\n",
       "                                             n_estimators=None, n_jobs=None,\n",
       "                                             num_parallel_tree=None,\n",
       "                                             random_state=None, ...),\n",
       "                                RandomForestRegressor()),\n",
       "                    shuffle=False, store_train_meta_features=True,\n",
       "                    use_features_in_secondary=True)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">meta_regressor: RandomForestRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingCVRegressor(meta_regressor=RandomForestRegressor(), random_state=42,\n",
       "                    regressors=(XGBRegressor(base_score=None, booster=None,\n",
       "                                             callbacks=None,\n",
       "                                             colsample_bylevel=None,\n",
       "                                             colsample_bynode=None,\n",
       "                                             colsample_bytree=None, device=None,\n",
       "                                             early_stopping_rounds=None,\n",
       "                                             enable_categorical=False,\n",
       "                                             eval_metric=None,\n",
       "                                             feature_types=None, gamma=None,\n",
       "                                             grow_policy=None,\n",
       "                                             importance_...\n",
       "                                             max_cat_threshold=None,\n",
       "                                             max_cat_to_onehot=None,\n",
       "                                             max_delta_step=None,\n",
       "                                             max_depth=None, max_leaves=None,\n",
       "                                             min_child_weight=None, missing=nan,\n",
       "                                             monotone_constraints=None,\n",
       "                                             multi_strategy=None,\n",
       "                                             n_estimators=None, n_jobs=None,\n",
       "                                             num_parallel_tree=None,\n",
       "                                             random_state=None, ...),\n",
       "                                RandomForestRegressor()),\n",
       "                    shuffle=False, store_train_meta_features=True,\n",
       "                    use_features_in_secondary=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_regressor_xgb_rf = StackingCVRegressor(regressors=(xgb, rf),\n",
    "                            meta_regressor=rf, cv=5,\n",
    "                            use_features_in_secondary=True,\n",
    "                            store_train_meta_features=True,\n",
    "                            shuffle=False,\n",
    "                            random_state=42)\n",
    "\n",
    "stacking_regressor_xgb_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9160365525830882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred = stacking_regressor_rf_xgb.predict(X_val) \n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9068816766810665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred = stacking_regressor_xgb_rf.predict(X_val) \n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:53:28,608] A new study created in memory with name: no-name-07362f88-c200-4af6-a4e7-ff7540609041\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 704155.6250 - mean_absolute_error: 300.9185 - val_loss: 70001.7734 - val_mean_absolute_error: 214.6509\n",
      "Epoch 2/22\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 72566.2344 - mean_absolute_error: 218.2122 - val_loss: 70001.7734 - val_mean_absolute_error: 214.6509\n",
      "Epoch 3/22\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - loss: 68812.0703 - mean_absolute_error: 212.5668 - val_loss: 70001.7734 - val_mean_absolute_error: 214.6509\n",
      "Epoch 4/22\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 73943.2734 - mean_absolute_error: 218.3646 - val_loss: 70001.7734 - val_mean_absolute_error: 214.6509\n",
      "Epoch 5/22\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 75600.1094 - mean_absolute_error: 217.0367 - val_loss: 70001.7734 - val_mean_absolute_error: 214.6509\n",
      "Epoch 6/22\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - loss: 71239.2812 - mean_absolute_error: 215.1657 - val_loss: 70001.7734 - val_mean_absolute_error: 214.6509\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:53:30,870] Trial 0 finished with value: 215.42847832031254 and parameters: {'layer_1': 5, 'layer_2': 3, 'layer_3': 8, 'learning_rate': 0.05777371727789711, 'dropout_rate': 0.2845112319875573, 'epoch': 22, 'batch_size': 28, 'optimizer': 'SGD'}. Best is trial 0 with value: 215.42847832031254.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 71567.9766 - mean_absolute_error: 215.0333 - val_loss: 70001.7812 - val_mean_absolute_error: 214.6510\n",
      "Epoch 2/29\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72487.8672 - mean_absolute_error: 216.9514 - val_loss: 70001.7812 - val_mean_absolute_error: 214.6510\n",
      "Epoch 3/29\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72519.2812 - mean_absolute_error: 214.8104 - val_loss: 70001.7812 - val_mean_absolute_error: 214.6510\n",
      "Epoch 4/29\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73477.3359 - mean_absolute_error: 219.1075 - val_loss: 70001.7812 - val_mean_absolute_error: 214.6510\n",
      "Epoch 5/29\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73488.8359 - mean_absolute_error: 214.8275 - val_loss: 70001.7812 - val_mean_absolute_error: 214.6510\n",
      "Epoch 6/29\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69619.3594 - mean_absolute_error: 212.5677 - val_loss: 70001.7812 - val_mean_absolute_error: 214.6510\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:53:32,752] Trial 1 finished with value: 215.42847832031254 and parameters: {'layer_1': 4, 'layer_2': 2, 'layer_3': 4, 'learning_rate': 3.5855866375130506e-05, 'dropout_rate': 0.4228973223993803, 'epoch': 29, 'batch_size': 78, 'optimizer': 'Adadelta'}. Best is trial 0 with value: 215.42847832031254.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 73685.6719 - mean_absolute_error: 216.8115 - val_loss: 69978.7109 - val_mean_absolute_error: 214.5925\n",
      "Epoch 2/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70231.3984 - mean_absolute_error: 213.1811 - val_loss: 69937.7656 - val_mean_absolute_error: 214.4748\n",
      "Epoch 3/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74877.4688 - mean_absolute_error: 217.8784 - val_loss: 69882.8984 - val_mean_absolute_error: 214.3176\n",
      "Epoch 4/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71431.3828 - mean_absolute_error: 214.7520 - val_loss: 69814.9922 - val_mean_absolute_error: 214.1205\n",
      "Epoch 5/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74512.9531 - mean_absolute_error: 218.5716 - val_loss: 69728.0781 - val_mean_absolute_error: 213.8684\n",
      "Epoch 6/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73680.3438 - mean_absolute_error: 215.1406 - val_loss: 69626.5938 - val_mean_absolute_error: 213.5700\n",
      "Epoch 7/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 78927.5625 - mean_absolute_error: 222.9490 - val_loss: 69501.6719 - val_mean_absolute_error: 213.1865\n",
      "Epoch 8/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72906.9141 - mean_absolute_error: 215.7510 - val_loss: 69365.6797 - val_mean_absolute_error: 212.7680\n",
      "Epoch 9/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75866.5859 - mean_absolute_error: 217.3861 - val_loss: 69204.9844 - val_mean_absolute_error: 212.2714\n",
      "Epoch 10/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71353.5547 - mean_absolute_error: 211.7087 - val_loss: 69019.1875 - val_mean_absolute_error: 211.6967\n",
      "Epoch 11/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72640.5781 - mean_absolute_error: 214.8283 - val_loss: 68818.5469 - val_mean_absolute_error: 211.0687\n",
      "Epoch 12/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72636.7188 - mean_absolute_error: 212.6951 - val_loss: 68597.4922 - val_mean_absolute_error: 210.3595\n",
      "Epoch 13/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67657.9453 - mean_absolute_error: 207.6054 - val_loss: 68349.0234 - val_mean_absolute_error: 209.5791\n",
      "Epoch 14/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68903.5703 - mean_absolute_error: 209.7957 - val_loss: 68072.9844 - val_mean_absolute_error: 208.7308\n",
      "Epoch 15/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70498.6328 - mean_absolute_error: 212.4144 - val_loss: 67770.2188 - val_mean_absolute_error: 207.8169\n",
      "Epoch 16/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74146.7578 - mean_absolute_error: 214.5453 - val_loss: 67426.8750 - val_mean_absolute_error: 206.7938\n",
      "Epoch 17/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72145.9297 - mean_absolute_error: 209.2740 - val_loss: 67061.8047 - val_mean_absolute_error: 205.7286\n",
      "Epoch 18/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68021.2266 - mean_absolute_error: 207.2648 - val_loss: 66643.1953 - val_mean_absolute_error: 204.5332\n",
      "Epoch 19/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69803.8438 - mean_absolute_error: 205.5887 - val_loss: 66184.8281 - val_mean_absolute_error: 203.2638\n",
      "Epoch 20/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68643.8828 - mean_absolute_error: 206.0932 - val_loss: 65686.2812 - val_mean_absolute_error: 201.9811\n",
      "Epoch 21/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71152.3984 - mean_absolute_error: 206.9272 - val_loss: 65108.7266 - val_mean_absolute_error: 200.5476\n",
      "Epoch 22/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66672.2812 - mean_absolute_error: 202.5713 - val_loss: 64384.5195 - val_mean_absolute_error: 198.6455\n",
      "Epoch 23/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68178.0000 - mean_absolute_error: 202.7493 - val_loss: 63523.5000 - val_mean_absolute_error: 196.5544\n",
      "Epoch 24/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 63895.1250 - mean_absolute_error: 198.4517 - val_loss: 62418.9766 - val_mean_absolute_error: 194.1639\n",
      "Epoch 25/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68704.6250 - mean_absolute_error: 201.2834 - val_loss: 60918.6953 - val_mean_absolute_error: 191.2504\n",
      "Epoch 26/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 63150.7227 - mean_absolute_error: 192.3102 - val_loss: 58797.2852 - val_mean_absolute_error: 187.4288\n",
      "Epoch 27/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 64703.9102 - mean_absolute_error: 192.9093 - val_loss: 56462.6953 - val_mean_absolute_error: 183.1846\n",
      "Epoch 28/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65580.1250 - mean_absolute_error: 192.1728 - val_loss: 54168.8203 - val_mean_absolute_error: 178.9984\n",
      "Epoch 29/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59119.6523 - mean_absolute_error: 185.6455 - val_loss: 51595.8867 - val_mean_absolute_error: 174.3658\n",
      "Epoch 30/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57095.5586 - mean_absolute_error: 178.5701 - val_loss: 48688.9727 - val_mean_absolute_error: 169.1738\n",
      "Epoch 31/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55073.7539 - mean_absolute_error: 177.0701 - val_loss: 45852.5625 - val_mean_absolute_error: 164.1065\n",
      "Epoch 32/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52870.4883 - mean_absolute_error: 171.6628 - val_loss: 43510.2773 - val_mean_absolute_error: 159.8241\n",
      "Epoch 33/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53414.4883 - mean_absolute_error: 171.4650 - val_loss: 40800.5117 - val_mean_absolute_error: 154.8442\n",
      "Epoch 34/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 54247.2852 - mean_absolute_error: 170.9598 - val_loss: 38661.5391 - val_mean_absolute_error: 150.6914\n",
      "Epoch 35/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 51230.4531 - mean_absolute_error: 167.1136 - val_loss: 37240.9141 - val_mean_absolute_error: 147.8211\n",
      "Epoch 36/36\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 44073.2773 - mean_absolute_error: 156.8029 - val_loss: 35304.7422 - val_mean_absolute_error: 143.9240\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:53:38,145] Trial 2 finished with value: 144.26941491041777 and parameters: {'layer_1': 2, 'layer_2': 5, 'layer_3': 5, 'learning_rate': 0.0004959333388459634, 'dropout_rate': 0.479403944888495, 'epoch': 36, 'batch_size': 58, 'optimizer': 'Adam'}. Best is trial 2 with value: 144.26941491041777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 998us/step - loss: 71435.2344 - mean_absolute_error: 213.6592 - val_loss: 69962.3203 - val_mean_absolute_error: 214.5875\n",
      "Epoch 2/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 72903.6328 - mean_absolute_error: 215.8682 - val_loss: 69962.3047 - val_mean_absolute_error: 214.5874\n",
      "Epoch 3/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 73339.3672 - mean_absolute_error: 216.4323 - val_loss: 69962.2734 - val_mean_absolute_error: 214.5874\n",
      "Epoch 4/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - loss: 71883.6484 - mean_absolute_error: 215.1165 - val_loss: 69962.2500 - val_mean_absolute_error: 214.5873\n",
      "Epoch 5/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 72507.4297 - mean_absolute_error: 215.7699 - val_loss: 69962.2266 - val_mean_absolute_error: 214.5872\n",
      "Epoch 6/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 68866.8047 - mean_absolute_error: 210.8478 - val_loss: 69962.1875 - val_mean_absolute_error: 214.5872\n",
      "Epoch 7/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 70404.1719 - mean_absolute_error: 212.8834 - val_loss: 69962.1719 - val_mean_absolute_error: 214.5871\n",
      "Epoch 8/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 76604.2422 - mean_absolute_error: 221.1678 - val_loss: 69962.1406 - val_mean_absolute_error: 214.5870\n",
      "Epoch 9/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 72450.6094 - mean_absolute_error: 214.1134 - val_loss: 69962.1172 - val_mean_absolute_error: 214.5869\n",
      "Epoch 10/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 72296.9766 - mean_absolute_error: 215.8981 - val_loss: 69962.0703 - val_mean_absolute_error: 214.5869\n",
      "Epoch 11/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 72362.7969 - mean_absolute_error: 214.9408 - val_loss: 69962.0469 - val_mean_absolute_error: 214.5868\n",
      "Epoch 12/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 72576.7656 - mean_absolute_error: 216.9926 - val_loss: 69962.0078 - val_mean_absolute_error: 214.5867\n",
      "Epoch 13/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 71868.5781 - mean_absolute_error: 215.7849 - val_loss: 69961.9688 - val_mean_absolute_error: 214.5867\n",
      "Epoch 14/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 69986.8828 - mean_absolute_error: 214.2979 - val_loss: 69961.9375 - val_mean_absolute_error: 214.5866\n",
      "Epoch 15/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - loss: 71542.9219 - mean_absolute_error: 213.9965 - val_loss: 69961.9219 - val_mean_absolute_error: 214.5866\n",
      "Epoch 16/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 73263.2656 - mean_absolute_error: 213.4968 - val_loss: 69961.8906 - val_mean_absolute_error: 214.5865\n",
      "Epoch 17/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 71906.4688 - mean_absolute_error: 213.9755 - val_loss: 69961.8594 - val_mean_absolute_error: 214.5865\n",
      "Epoch 18/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - loss: 72813.4453 - mean_absolute_error: 217.2341 - val_loss: 69961.8281 - val_mean_absolute_error: 214.5864\n",
      "Epoch 19/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - loss: 71913.3438 - mean_absolute_error: 214.5903 - val_loss: 69961.8047 - val_mean_absolute_error: 214.5863\n",
      "Epoch 20/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 74838.1094 - mean_absolute_error: 218.2795 - val_loss: 69961.7969 - val_mean_absolute_error: 214.5863\n",
      "Epoch 21/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 69616.4375 - mean_absolute_error: 210.8615 - val_loss: 69961.7734 - val_mean_absolute_error: 214.5863\n",
      "Epoch 22/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 74828.5312 - mean_absolute_error: 218.3648 - val_loss: 69961.7422 - val_mean_absolute_error: 214.5862\n",
      "Epoch 23/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 71019.5938 - mean_absolute_error: 213.6927 - val_loss: 69961.7031 - val_mean_absolute_error: 214.5862\n",
      "Epoch 24/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 71102.6250 - mean_absolute_error: 215.0460 - val_loss: 69961.6875 - val_mean_absolute_error: 214.5861\n",
      "Epoch 25/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 71648.3203 - mean_absolute_error: 214.8790 - val_loss: 69961.6562 - val_mean_absolute_error: 214.5860\n",
      "Epoch 26/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 74627.5391 - mean_absolute_error: 217.6346 - val_loss: 69961.6094 - val_mean_absolute_error: 214.5859\n",
      "Epoch 27/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - loss: 71541.1562 - mean_absolute_error: 214.9499 - val_loss: 69961.5781 - val_mean_absolute_error: 214.5858\n",
      "Epoch 28/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 78330.4688 - mean_absolute_error: 218.9265 - val_loss: 69961.5625 - val_mean_absolute_error: 214.5857\n",
      "Epoch 29/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 76111.8750 - mean_absolute_error: 216.9100 - val_loss: 69961.5156 - val_mean_absolute_error: 214.5857\n",
      "Epoch 30/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 73436.6875 - mean_absolute_error: 215.8424 - val_loss: 69961.4922 - val_mean_absolute_error: 214.5856\n",
      "Epoch 31/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 70933.7422 - mean_absolute_error: 214.2412 - val_loss: 69961.4609 - val_mean_absolute_error: 214.5856\n",
      "Epoch 32/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - loss: 72307.3516 - mean_absolute_error: 213.5797 - val_loss: 69961.4453 - val_mean_absolute_error: 214.5855\n",
      "Epoch 33/33\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 70838.4141 - mean_absolute_error: 213.3405 - val_loss: 69961.3984 - val_mean_absolute_error: 214.5855\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:53:52,585] Trial 3 finished with value: 215.36819747944483 and parameters: {'layer_1': 4, 'layer_2': 2, 'layer_3': 4, 'learning_rate': 3.132124083719185e-05, 'dropout_rate': 0.3241636811583669, 'epoch': 33, 'batch_size': 9, 'optimizer': 'Adadelta'}. Best is trial 2 with value: 144.26941491041777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66132.8594 - mean_absolute_error: 203.2901 - val_loss: 18564.5410 - val_mean_absolute_error: 110.7352\n",
      "Epoch 2/18\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 45680.9102 - mean_absolute_error: 145.3235 - val_loss: 18930.4473 - val_mean_absolute_error: 105.6652\n",
      "Epoch 3/18\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 40423.3047 - mean_absolute_error: 135.5220 - val_loss: 18253.3848 - val_mean_absolute_error: 104.6376\n",
      "Epoch 4/18\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 36552.6328 - mean_absolute_error: 126.4411 - val_loss: 16133.3340 - val_mean_absolute_error: 97.7265\n",
      "Epoch 5/18\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 36059.4102 - mean_absolute_error: 127.1542 - val_loss: 15098.9678 - val_mean_absolute_error: 92.1586\n",
      "Epoch 6/18\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33062.0820 - mean_absolute_error: 121.9811 - val_loss: 16212.5986 - val_mean_absolute_error: 94.7563\n",
      "Epoch 7/18\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32574.0273 - mean_absolute_error: 119.7757 - val_loss: 17164.9258 - val_mean_absolute_error: 96.2373\n",
      "Epoch 8/18\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32003.7441 - mean_absolute_error: 121.1993 - val_loss: 19102.7305 - val_mean_absolute_error: 100.5218\n",
      "Epoch 9/18\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 29901.2207 - mean_absolute_error: 119.9518 - val_loss: 14673.1426 - val_mean_absolute_error: 88.2826\n",
      "Epoch 10/18\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32448.7266 - mean_absolute_error: 121.6077 - val_loss: 15361.3711 - val_mean_absolute_error: 88.2405\n",
      "Epoch 11/18\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33312.4961 - mean_absolute_error: 119.5151 - val_loss: 15389.8818 - val_mean_absolute_error: 88.9016\n",
      "Epoch 12/18\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 29926.0840 - mean_absolute_error: 117.0645 - val_loss: 14833.4990 - val_mean_absolute_error: 88.3535\n",
      "Epoch 13/18\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28113.5781 - mean_absolute_error: 111.9636 - val_loss: 14308.8027 - val_mean_absolute_error: 86.7406\n",
      "Epoch 14/18\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32560.4453 - mean_absolute_error: 118.3782 - val_loss: 16904.4434 - val_mean_absolute_error: 93.6314\n",
      "Epoch 15/18\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30927.5859 - mean_absolute_error: 115.5343 - val_loss: 14982.6748 - val_mean_absolute_error: 87.1701\n",
      "Epoch 16/18\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 29816.0430 - mean_absolute_error: 114.8773 - val_loss: 15215.3340 - val_mean_absolute_error: 89.2909\n",
      "Epoch 17/18\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28792.6934 - mean_absolute_error: 113.7110 - val_loss: 15272.6094 - val_mean_absolute_error: 89.2660\n",
      "Epoch 18/18\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28179.9785 - mean_absolute_error: 111.3028 - val_loss: 14746.3291 - val_mean_absolute_error: 87.3511\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:53:56,536] Trial 4 finished with value: 88.19060409088135 and parameters: {'layer_1': 5, 'layer_2': 6, 'layer_3': 3, 'learning_rate': 0.01228602782708528, 'dropout_rate': 0.3330752186255173, 'epoch': 18, 'batch_size': 39, 'optimizer': 'Adam'}. Best is trial 4 with value: 88.19060409088135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 75550.2500 - mean_absolute_error: 218.0569 - val_loss: 70001.7812 - val_mean_absolute_error: 214.6509\n",
      "Epoch 2/38\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 72804.1250 - mean_absolute_error: 214.8903 - val_loss: 70001.7812 - val_mean_absolute_error: 214.6509\n",
      "Epoch 3/38\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 70947.8359 - mean_absolute_error: 215.1812 - val_loss: 70001.7812 - val_mean_absolute_error: 214.6509\n",
      "Epoch 4/38\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 73197.8125 - mean_absolute_error: 218.4433 - val_loss: 70001.7812 - val_mean_absolute_error: 214.6509\n",
      "Epoch 5/38\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 72996.6406 - mean_absolute_error: 214.3139 - val_loss: 70001.7812 - val_mean_absolute_error: 214.6509\n",
      "Epoch 6/38\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 70755.4297 - mean_absolute_error: 215.4490 - val_loss: 70001.7812 - val_mean_absolute_error: 214.6509\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:53:58,730] Trial 5 finished with value: 215.42847832031254 and parameters: {'layer_1': 5, 'layer_2': 7, 'layer_3': 3, 'learning_rate': 0.0006005064050223003, 'dropout_rate': 0.42813759992099215, 'epoch': 38, 'batch_size': 14, 'optimizer': 'SGD'}. Best is trial 4 with value: 88.19060409088135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1366/1366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 817us/step - loss: 43283.4805 - mean_absolute_error: 142.1022 - val_loss: 3787.2742 - val_mean_absolute_error: 42.0266\n",
      "Epoch 2/45\n",
      "\u001b[1m1366/1366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - loss: 20082.7539 - mean_absolute_error: 61.9912 - val_loss: 2778.1973 - val_mean_absolute_error: 35.0126\n",
      "Epoch 3/45\n",
      "\u001b[1m1366/1366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 750us/step - loss: 8588.6953 - mean_absolute_error: 55.6469 - val_loss: 2900.8413 - val_mean_absolute_error: 37.2401\n",
      "Epoch 4/45\n",
      "\u001b[1m1366/1366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 773us/step - loss: 12843.8262 - mean_absolute_error: 54.4360 - val_loss: 2424.0591 - val_mean_absolute_error: 31.7811\n",
      "Epoch 5/45\n",
      "\u001b[1m1366/1366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 778us/step - loss: 13904.4824 - mean_absolute_error: 52.9975 - val_loss: 2508.6426 - val_mean_absolute_error: 32.4635\n",
      "Epoch 6/45\n",
      "\u001b[1m1366/1366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739us/step - loss: 18818.1895 - mean_absolute_error: 52.4194 - val_loss: 2928.9131 - val_mean_absolute_error: 36.1688\n",
      "Epoch 7/45\n",
      "\u001b[1m1366/1366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - loss: 18513.3809 - mean_absolute_error: 50.5957 - val_loss: 2817.7673 - val_mean_absolute_error: 33.9975\n",
      "Epoch 8/45\n",
      "\u001b[1m1366/1366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - loss: 9910.3760 - mean_absolute_error: 47.8286 - val_loss: 2108.5469 - val_mean_absolute_error: 29.0737\n",
      "Epoch 9/45\n",
      "\u001b[1m1366/1366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - loss: 6685.7217 - mean_absolute_error: 45.3344 - val_loss: 2839.6692 - val_mean_absolute_error: 35.5699\n",
      "Epoch 10/45\n",
      "\u001b[1m1366/1366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754us/step - loss: 6533.4155 - mean_absolute_error: 44.0960 - val_loss: 2337.0127 - val_mean_absolute_error: 31.9898\n",
      "Epoch 11/45\n",
      "\u001b[1m1366/1366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - loss: 9233.8994 - mean_absolute_error: 45.3469 - val_loss: 2709.7266 - val_mean_absolute_error: 34.0185\n",
      "Epoch 12/45\n",
      "\u001b[1m1366/1366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754us/step - loss: 7050.3584 - mean_absolute_error: 46.4960 - val_loss: 2654.3992 - val_mean_absolute_error: 33.7681\n",
      "Epoch 13/45\n",
      "\u001b[1m1366/1366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - loss: 11803.7168 - mean_absolute_error: 46.8335 - val_loss: 2845.1899 - val_mean_absolute_error: 35.6978\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:54:13,550] Trial 6 finished with value: 30.030791844546798 and parameters: {'layer_1': 2, 'layer_2': 5, 'layer_3': 8, 'learning_rate': 0.005379733841438167, 'dropout_rate': 0.08376591860407234, 'epoch': 45, 'batch_size': 3, 'optimizer': 'RMSprop'}. Best is trial 6 with value: 30.030791844546798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 72522.8359 - mean_absolute_error: 212.2730 - val_loss: 64543.8242 - val_mean_absolute_error: 199.1169\n",
      "Epoch 2/30\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 60765.1328 - mean_absolute_error: 183.9534 - val_loss: 32535.7422 - val_mean_absolute_error: 120.3778\n",
      "Epoch 3/30\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 45726.1250 - mean_absolute_error: 155.9027 - val_loss: 30009.6875 - val_mean_absolute_error: 118.6964\n",
      "Epoch 4/30\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 47891.9688 - mean_absolute_error: 152.4966 - val_loss: 30806.8457 - val_mean_absolute_error: 118.9891\n",
      "Epoch 5/30\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 45841.1133 - mean_absolute_error: 151.4913 - val_loss: 28135.0508 - val_mean_absolute_error: 114.5725\n",
      "Epoch 6/30\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 41206.1953 - mean_absolute_error: 140.9791 - val_loss: 28315.7578 - val_mean_absolute_error: 115.1414\n",
      "Epoch 7/30\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 43543.1797 - mean_absolute_error: 145.6032 - val_loss: 23096.5488 - val_mean_absolute_error: 104.7769\n",
      "Epoch 8/30\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 40419.9453 - mean_absolute_error: 141.8912 - val_loss: 31290.3262 - val_mean_absolute_error: 120.2518\n",
      "Epoch 9/30\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 40747.4844 - mean_absolute_error: 140.1601 - val_loss: 28110.0312 - val_mean_absolute_error: 114.0250\n",
      "Epoch 10/30\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - loss: 34741.9883 - mean_absolute_error: 130.3140 - val_loss: 28417.9277 - val_mean_absolute_error: 114.2196\n",
      "Epoch 11/30\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 40036.2539 - mean_absolute_error: 138.6411 - val_loss: 29210.3516 - val_mean_absolute_error: 116.3398\n",
      "Epoch 12/30\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 37597.2305 - mean_absolute_error: 136.4643 - val_loss: 26138.1113 - val_mean_absolute_error: 109.7884\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:54:17,206] Trial 7 finished with value: 106.18303021386862 and parameters: {'layer_1': 5, 'layer_2': 2, 'layer_3': 5, 'learning_rate': 6.771031546079807e-05, 'dropout_rate': 0.46701291753153595, 'epoch': 30, 'batch_size': 14, 'optimizer': 'SGD'}. Best is trial 6 with value: 30.030791844546798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2849697169408.0000 - mean_absolute_error: 195528.7656 - val_loss: 70001.7812 - val_mean_absolute_error: 214.6509\n",
      "Epoch 2/14\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74452.7422 - mean_absolute_error: 218.4215 - val_loss: 70001.7812 - val_mean_absolute_error: 214.6509\n",
      "Epoch 3/14\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70493.5391 - mean_absolute_error: 214.0704 - val_loss: 70001.7812 - val_mean_absolute_error: 214.6509\n",
      "Epoch 4/14\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71956.1484 - mean_absolute_error: 215.3089 - val_loss: 70001.7812 - val_mean_absolute_error: 214.6509\n",
      "Epoch 5/14\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71387.6250 - mean_absolute_error: 215.0051 - val_loss: 70001.7812 - val_mean_absolute_error: 214.6509\n",
      "Epoch 6/14\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75984.1094 - mean_absolute_error: 217.6270 - val_loss: 70001.7812 - val_mean_absolute_error: 214.6509\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:54:18,543] Trial 8 finished with value: 215.42847832031254 and parameters: {'layer_1': 3, 'layer_2': 2, 'layer_3': 8, 'learning_rate': 0.007420093909601562, 'dropout_rate': 0.156607394186828, 'epoch': 14, 'batch_size': 73, 'optimizer': 'SGD'}. Best is trial 6 with value: 30.030791844546798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77727.6953 - mean_absolute_error: 217.7728 - val_loss: 69930.7578 - val_mean_absolute_error: 214.3929\n",
      "Epoch 2/11\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71691.9219 - mean_absolute_error: 214.2579 - val_loss: 69919.6406 - val_mean_absolute_error: 214.3580\n",
      "Epoch 3/11\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72492.7188 - mean_absolute_error: 214.0075 - val_loss: 69907.7656 - val_mean_absolute_error: 214.3215\n",
      "Epoch 4/11\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70613.1094 - mean_absolute_error: 212.7984 - val_loss: 69895.0000 - val_mean_absolute_error: 214.2831\n",
      "Epoch 5/11\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70755.5312 - mean_absolute_error: 212.7117 - val_loss: 69881.8281 - val_mean_absolute_error: 214.2437\n",
      "Epoch 6/11\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74273.4688 - mean_absolute_error: 217.3643 - val_loss: 69868.0859 - val_mean_absolute_error: 214.2030\n",
      "Epoch 7/11\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70613.4766 - mean_absolute_error: 212.8554 - val_loss: 69853.3203 - val_mean_absolute_error: 214.1598\n",
      "Epoch 8/11\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71956.5938 - mean_absolute_error: 213.8929 - val_loss: 69838.3750 - val_mean_absolute_error: 214.1155\n",
      "Epoch 9/11\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73063.4766 - mean_absolute_error: 214.8394 - val_loss: 69822.7500 - val_mean_absolute_error: 214.0697\n",
      "Epoch 10/11\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73951.9141 - mean_absolute_error: 215.6415 - val_loss: 69806.6016 - val_mean_absolute_error: 214.0226\n",
      "Epoch 11/11\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70930.0781 - mean_absolute_error: 214.2812 - val_loss: 69789.7188 - val_mean_absolute_error: 213.9744\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:54:20,905] Trial 9 finished with value: 214.76258534765725 and parameters: {'layer_1': 2, 'layer_2': 4, 'layer_3': 2, 'learning_rate': 6.90539134846753e-05, 'dropout_rate': 0.0981923891173963, 'epoch': 11, 'batch_size': 44, 'optimizer': 'RMSprop'}. Best is trial 6 with value: 30.030791844546798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 72335.4688 - mean_absolute_error: 215.4010 - val_loss: 66955.2500 - val_mean_absolute_error: 208.6158\n",
      "Epoch 2/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67433.8672 - mean_absolute_error: 207.8245 - val_loss: 55456.0234 - val_mean_absolute_error: 188.1946\n",
      "Epoch 3/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 50926.7930 - mean_absolute_error: 178.7907 - val_loss: 34964.7695 - val_mean_absolute_error: 148.8342\n",
      "Epoch 4/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31024.8027 - mean_absolute_error: 138.1380 - val_loss: 18088.7539 - val_mean_absolute_error: 109.2318\n",
      "Epoch 5/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20182.4824 - mean_absolute_error: 105.8063 - val_loss: 13588.9902 - val_mean_absolute_error: 94.8865\n",
      "Epoch 6/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 17031.5684 - mean_absolute_error: 94.6761 - val_loss: 11660.7344 - val_mean_absolute_error: 87.4030\n",
      "Epoch 7/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13578.9746 - mean_absolute_error: 86.0653 - val_loss: 9756.0879 - val_mean_absolute_error: 78.8009\n",
      "Epoch 8/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12120.7930 - mean_absolute_error: 78.9305 - val_loss: 8223.9092 - val_mean_absolute_error: 71.1009\n",
      "Epoch 9/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11881.7803 - mean_absolute_error: 70.8468 - val_loss: 6981.9795 - val_mean_absolute_error: 63.1467\n",
      "Epoch 10/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7734.9727 - mean_absolute_error: 60.7562 - val_loss: 5803.6514 - val_mean_absolute_error: 55.7397\n",
      "Epoch 11/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8029.8052 - mean_absolute_error: 54.9264 - val_loss: 4892.1733 - val_mean_absolute_error: 48.6941\n",
      "Epoch 12/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5688.8442 - mean_absolute_error: 48.6340 - val_loss: 4279.2026 - val_mean_absolute_error: 44.7145\n",
      "Epoch 13/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7112.0361 - mean_absolute_error: 45.6533 - val_loss: 3888.9766 - val_mean_absolute_error: 40.1492\n",
      "Epoch 14/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5645.7764 - mean_absolute_error: 42.1029 - val_loss: 3710.5110 - val_mean_absolute_error: 39.8100\n",
      "Epoch 15/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5137.7622 - mean_absolute_error: 40.7014 - val_loss: 3530.1309 - val_mean_absolute_error: 38.2000\n",
      "Epoch 16/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5340.4243 - mean_absolute_error: 40.0857 - val_loss: 3380.7305 - val_mean_absolute_error: 37.9647\n",
      "Epoch 17/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5909.6265 - mean_absolute_error: 38.4728 - val_loss: 3225.7520 - val_mean_absolute_error: 36.6289\n",
      "Epoch 18/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4873.5889 - mean_absolute_error: 37.1704 - val_loss: 3087.2808 - val_mean_absolute_error: 35.7924\n",
      "Epoch 19/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3672.9453 - mean_absolute_error: 36.3108 - val_loss: 2983.4651 - val_mean_absolute_error: 34.6768\n",
      "Epoch 20/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4603.0659 - mean_absolute_error: 37.2454 - val_loss: 2908.8943 - val_mean_absolute_error: 34.1271\n",
      "Epoch 21/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5528.5518 - mean_absolute_error: 37.2000 - val_loss: 2838.1626 - val_mean_absolute_error: 33.1207\n",
      "Epoch 22/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4896.8643 - mean_absolute_error: 35.2452 - val_loss: 2726.1008 - val_mean_absolute_error: 32.7202\n",
      "Epoch 23/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4011.2566 - mean_absolute_error: 34.4764 - val_loss: 2654.7769 - val_mean_absolute_error: 31.3890\n",
      "Epoch 24/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4590.8618 - mean_absolute_error: 34.2827 - val_loss: 2540.4573 - val_mean_absolute_error: 31.1554\n",
      "Epoch 25/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3263.7615 - mean_absolute_error: 32.8004 - val_loss: 2449.0352 - val_mean_absolute_error: 30.4760\n",
      "Epoch 26/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3961.3435 - mean_absolute_error: 31.9419 - val_loss: 2508.6604 - val_mean_absolute_error: 31.0115\n",
      "Epoch 27/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3615.4172 - mean_absolute_error: 32.1911 - val_loss: 2528.1362 - val_mean_absolute_error: 31.5072\n",
      "Epoch 28/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4283.7563 - mean_absolute_error: 32.6431 - val_loss: 2227.7573 - val_mean_absolute_error: 28.1075\n",
      "Epoch 29/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2756.4202 - mean_absolute_error: 29.8320 - val_loss: 2151.2205 - val_mean_absolute_error: 27.4343\n",
      "Epoch 30/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4314.8613 - mean_absolute_error: 31.4829 - val_loss: 2097.7776 - val_mean_absolute_error: 26.6015\n",
      "Epoch 31/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3522.3384 - mean_absolute_error: 29.9395 - val_loss: 2431.3364 - val_mean_absolute_error: 30.5714\n",
      "Epoch 32/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2497.2876 - mean_absolute_error: 28.2381 - val_loss: 1998.7242 - val_mean_absolute_error: 25.9503\n",
      "Epoch 33/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3289.7983 - mean_absolute_error: 28.0987 - val_loss: 1972.1115 - val_mean_absolute_error: 26.0309\n",
      "Epoch 34/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2662.3284 - mean_absolute_error: 28.2095 - val_loss: 1904.0657 - val_mean_absolute_error: 25.0849\n",
      "Epoch 35/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3398.0952 - mean_absolute_error: 27.5903 - val_loss: 1857.0602 - val_mean_absolute_error: 24.7932\n",
      "Epoch 36/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4973.9268 - mean_absolute_error: 29.5031 - val_loss: 1817.7020 - val_mean_absolute_error: 24.0968\n",
      "Epoch 37/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4502.9404 - mean_absolute_error: 28.3072 - val_loss: 1759.5778 - val_mean_absolute_error: 23.2525\n",
      "Epoch 38/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3514.5132 - mean_absolute_error: 27.8802 - val_loss: 1734.1404 - val_mean_absolute_error: 23.2320\n",
      "Epoch 39/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3288.6011 - mean_absolute_error: 26.4931 - val_loss: 1719.0238 - val_mean_absolute_error: 22.7212\n",
      "Epoch 40/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3254.4824 - mean_absolute_error: 25.4945 - val_loss: 1771.6222 - val_mean_absolute_error: 23.6762\n",
      "Epoch 41/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4330.9233 - mean_absolute_error: 26.6734 - val_loss: 1666.9756 - val_mean_absolute_error: 22.2963\n",
      "Epoch 42/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3151.6885 - mean_absolute_error: 25.7103 - val_loss: 1933.0903 - val_mean_absolute_error: 25.2729\n",
      "Epoch 43/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2657.3940 - mean_absolute_error: 26.7220 - val_loss: 1693.6450 - val_mean_absolute_error: 23.1231\n",
      "Epoch 44/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2746.4915 - mean_absolute_error: 25.0917 - val_loss: 1652.3815 - val_mean_absolute_error: 21.9373\n",
      "Epoch 45/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2952.0203 - mean_absolute_error: 25.3539 - val_loss: 1620.5389 - val_mean_absolute_error: 21.8458\n",
      "Epoch 46/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3950.5361 - mean_absolute_error: 26.6479 - val_loss: 1601.3190 - val_mean_absolute_error: 21.4032\n",
      "Epoch 47/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3395.0542 - mean_absolute_error: 25.5825 - val_loss: 1594.7577 - val_mean_absolute_error: 21.1785\n",
      "Epoch 48/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4687.1968 - mean_absolute_error: 26.6416 - val_loss: 1579.3939 - val_mean_absolute_error: 20.9425\n",
      "Epoch 49/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2867.3601 - mean_absolute_error: 25.1271 - val_loss: 1642.1658 - val_mean_absolute_error: 22.0613\n",
      "Epoch 50/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2588.6533 - mean_absolute_error: 25.6301 - val_loss: 1612.3097 - val_mean_absolute_error: 21.1700\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:54:26,690] Trial 10 finished with value: 21.473532783144712 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 7, 'learning_rate': 0.0029385259326003767, 'dropout_rate': 0.0074237300614549695, 'epoch': 50, 'batch_size': 91, 'optimizer': 'RMSprop'}. Best is trial 10 with value: 21.473532783144712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 71943.9062 - mean_absolute_error: 214.6398 - val_loss: 66131.0000 - val_mean_absolute_error: 209.0518\n",
      "Epoch 2/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65970.1250 - mean_absolute_error: 206.3495 - val_loss: 54093.1914 - val_mean_absolute_error: 192.3516\n",
      "Epoch 3/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49713.4531 - mean_absolute_error: 182.9945 - val_loss: 32439.4609 - val_mean_absolute_error: 154.3814\n",
      "Epoch 4/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29473.7930 - mean_absolute_error: 143.4943 - val_loss: 18489.3301 - val_mean_absolute_error: 114.8239\n",
      "Epoch 5/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23494.0352 - mean_absolute_error: 114.0095 - val_loss: 14445.4043 - val_mean_absolute_error: 96.9122\n",
      "Epoch 6/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18407.9609 - mean_absolute_error: 96.8144 - val_loss: 11440.5234 - val_mean_absolute_error: 83.2090\n",
      "Epoch 7/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15043.9629 - mean_absolute_error: 80.9471 - val_loss: 8988.6133 - val_mean_absolute_error: 73.3372\n",
      "Epoch 8/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12144.7676 - mean_absolute_error: 72.6067 - val_loss: 7350.6382 - val_mean_absolute_error: 63.9880\n",
      "Epoch 9/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9383.0938 - mean_absolute_error: 61.8483 - val_loss: 6128.7144 - val_mean_absolute_error: 56.7587\n",
      "Epoch 10/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12636.6904 - mean_absolute_error: 58.7060 - val_loss: 5309.7158 - val_mean_absolute_error: 51.4218\n",
      "Epoch 11/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7077.7520 - mean_absolute_error: 51.2442 - val_loss: 4710.0483 - val_mean_absolute_error: 47.3204\n",
      "Epoch 12/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9415.4092 - mean_absolute_error: 48.6738 - val_loss: 4295.2686 - val_mean_absolute_error: 43.6825\n",
      "Epoch 13/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6016.7793 - mean_absolute_error: 45.0929 - val_loss: 4022.8940 - val_mean_absolute_error: 40.6686\n",
      "Epoch 14/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6989.0425 - mean_absolute_error: 43.5752 - val_loss: 3811.3931 - val_mean_absolute_error: 40.0980\n",
      "Epoch 15/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6482.9492 - mean_absolute_error: 42.6297 - val_loss: 3648.6216 - val_mean_absolute_error: 38.8369\n",
      "Epoch 16/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5133.7456 - mean_absolute_error: 41.2846 - val_loss: 3545.6282 - val_mean_absolute_error: 37.8949\n",
      "Epoch 17/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7643.8179 - mean_absolute_error: 41.3859 - val_loss: 3427.8638 - val_mean_absolute_error: 37.4566\n",
      "Epoch 18/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6780.5815 - mean_absolute_error: 40.3906 - val_loss: 3332.8584 - val_mean_absolute_error: 36.8551\n",
      "Epoch 19/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5591.7451 - mean_absolute_error: 38.1883 - val_loss: 3330.9446 - val_mean_absolute_error: 37.3323\n",
      "Epoch 20/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4863.9478 - mean_absolute_error: 38.8273 - val_loss: 3177.7964 - val_mean_absolute_error: 36.1945\n",
      "Epoch 21/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4595.0098 - mean_absolute_error: 37.1071 - val_loss: 3138.2244 - val_mean_absolute_error: 35.1938\n",
      "Epoch 22/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4318.3745 - mean_absolute_error: 35.8860 - val_loss: 3008.6990 - val_mean_absolute_error: 35.1880\n",
      "Epoch 23/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4824.8794 - mean_absolute_error: 37.3701 - val_loss: 2903.9568 - val_mean_absolute_error: 33.6626\n",
      "Epoch 24/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4282.6895 - mean_absolute_error: 36.3961 - val_loss: 2916.9373 - val_mean_absolute_error: 34.5892\n",
      "Epoch 25/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3493.3254 - mean_absolute_error: 34.5347 - val_loss: 2688.1755 - val_mean_absolute_error: 32.5934\n",
      "Epoch 26/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3613.7595 - mean_absolute_error: 34.4503 - val_loss: 2584.1653 - val_mean_absolute_error: 31.6988\n",
      "Epoch 27/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4119.1592 - mean_absolute_error: 33.9258 - val_loss: 2482.2161 - val_mean_absolute_error: 30.9243\n",
      "Epoch 28/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3426.9255 - mean_absolute_error: 32.0133 - val_loss: 2386.7161 - val_mean_absolute_error: 29.9911\n",
      "Epoch 29/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2812.3210 - mean_absolute_error: 30.7055 - val_loss: 2330.0107 - val_mean_absolute_error: 29.3741\n",
      "Epoch 30/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3398.4998 - mean_absolute_error: 29.7071 - val_loss: 2326.8042 - val_mean_absolute_error: 29.8420\n",
      "Epoch 31/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3257.2637 - mean_absolute_error: 29.9728 - val_loss: 2157.1997 - val_mean_absolute_error: 28.3004\n",
      "Epoch 32/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3955.8374 - mean_absolute_error: 30.4023 - val_loss: 2160.3186 - val_mean_absolute_error: 28.2849\n",
      "Epoch 33/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3264.9875 - mean_absolute_error: 29.5170 - val_loss: 1940.2465 - val_mean_absolute_error: 26.0736\n",
      "Epoch 34/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3828.8352 - mean_absolute_error: 28.3419 - val_loss: 1877.0603 - val_mean_absolute_error: 25.4533\n",
      "Epoch 35/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3003.8689 - mean_absolute_error: 27.1770 - val_loss: 1843.5342 - val_mean_absolute_error: 25.1487\n",
      "Epoch 36/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2795.9851 - mean_absolute_error: 26.0642 - val_loss: 1918.3005 - val_mean_absolute_error: 25.5533\n",
      "Epoch 37/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2570.9673 - mean_absolute_error: 26.2261 - val_loss: 1744.9554 - val_mean_absolute_error: 24.1493\n",
      "Epoch 38/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2625.1641 - mean_absolute_error: 25.6195 - val_loss: 1721.6611 - val_mean_absolute_error: 23.6966\n",
      "Epoch 39/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2580.3870 - mean_absolute_error: 25.5019 - val_loss: 1666.6135 - val_mean_absolute_error: 23.1308\n",
      "Epoch 40/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3390.2361 - mean_absolute_error: 26.4513 - val_loss: 1680.2716 - val_mean_absolute_error: 23.0201\n",
      "Epoch 41/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3605.0334 - mean_absolute_error: 26.7588 - val_loss: 1644.6198 - val_mean_absolute_error: 22.7368\n",
      "Epoch 42/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1922.0524 - mean_absolute_error: 23.8900 - val_loss: 1627.8193 - val_mean_absolute_error: 22.4448\n",
      "Epoch 43/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2323.1790 - mean_absolute_error: 24.8046 - val_loss: 1745.4863 - val_mean_absolute_error: 23.7702\n",
      "Epoch 44/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2219.4766 - mean_absolute_error: 23.8706 - val_loss: 1612.7159 - val_mean_absolute_error: 22.3558\n",
      "Epoch 45/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2356.3740 - mean_absolute_error: 23.7950 - val_loss: 1643.6544 - val_mean_absolute_error: 22.5279\n",
      "Epoch 46/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2629.9731 - mean_absolute_error: 24.6867 - val_loss: 1592.0941 - val_mean_absolute_error: 21.6957\n",
      "Epoch 47/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2218.9290 - mean_absolute_error: 24.1658 - val_loss: 1691.5553 - val_mean_absolute_error: 22.7595\n",
      "Epoch 48/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2451.2107 - mean_absolute_error: 24.1758 - val_loss: 1699.0084 - val_mean_absolute_error: 22.7471\n",
      "Epoch 49/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2075.8362 - mean_absolute_error: 23.3461 - val_loss: 1582.7639 - val_mean_absolute_error: 21.7470\n",
      "Epoch 50/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2029.9634 - mean_absolute_error: 24.1536 - val_loss: 1725.6194 - val_mean_absolute_error: 22.8266\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:54:32,503] Trial 11 finished with value: 22.194453937318922 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 7, 'learning_rate': 0.003575879566368163, 'dropout_rate': 0.004430154263754588, 'epoch': 50, 'batch_size': 99, 'optimizer': 'RMSprop'}. Best is trial 10 with value: 21.473532783144712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 70712.8438 - mean_absolute_error: 214.3558 - val_loss: 69974.6250 - val_mean_absolute_error: 214.5774\n",
      "Epoch 2/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 69641.9844 - mean_absolute_error: 213.9288 - val_loss: 69921.6641 - val_mean_absolute_error: 214.4636\n",
      "Epoch 3/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71632.4297 - mean_absolute_error: 213.8933 - val_loss: 69867.9141 - val_mean_absolute_error: 214.3573\n",
      "Epoch 4/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72447.3594 - mean_absolute_error: 217.5290 - val_loss: 69823.3672 - val_mean_absolute_error: 214.2648\n",
      "Epoch 5/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71467.1328 - mean_absolute_error: 213.3253 - val_loss: 69782.4375 - val_mean_absolute_error: 214.1782\n",
      "Epoch 6/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74583.7578 - mean_absolute_error: 216.9643 - val_loss: 69742.4609 - val_mean_absolute_error: 214.0931\n",
      "Epoch 7/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72054.3203 - mean_absolute_error: 215.2725 - val_loss: 69702.3750 - val_mean_absolute_error: 214.0078\n",
      "Epoch 8/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73042.0625 - mean_absolute_error: 214.8107 - val_loss: 69661.1875 - val_mean_absolute_error: 213.9217\n",
      "Epoch 9/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 69673.1797 - mean_absolute_error: 213.2330 - val_loss: 69619.2578 - val_mean_absolute_error: 213.8344\n",
      "Epoch 10/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71395.6406 - mean_absolute_error: 215.5358 - val_loss: 69576.6797 - val_mean_absolute_error: 213.7462\n",
      "Epoch 11/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72208.5781 - mean_absolute_error: 215.4000 - val_loss: 69532.7969 - val_mean_absolute_error: 213.6563\n",
      "Epoch 12/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73982.6953 - mean_absolute_error: 217.6342 - val_loss: 69487.1172 - val_mean_absolute_error: 213.5639\n",
      "Epoch 13/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72451.3203 - mean_absolute_error: 214.1575 - val_loss: 69439.4141 - val_mean_absolute_error: 213.4690\n",
      "Epoch 14/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67645.6484 - mean_absolute_error: 211.0067 - val_loss: 69389.7422 - val_mean_absolute_error: 213.3712\n",
      "Epoch 15/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70765.2656 - mean_absolute_error: 213.1521 - val_loss: 69338.7031 - val_mean_absolute_error: 213.2712\n",
      "Epoch 16/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 69318.3672 - mean_absolute_error: 210.8373 - val_loss: 69286.2266 - val_mean_absolute_error: 213.1689\n",
      "Epoch 17/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70055.1484 - mean_absolute_error: 213.6053 - val_loss: 69232.1797 - val_mean_absolute_error: 213.0643\n",
      "Epoch 18/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72347.8203 - mean_absolute_error: 213.9983 - val_loss: 69176.5391 - val_mean_absolute_error: 212.9573\n",
      "Epoch 19/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72570.6641 - mean_absolute_error: 215.1755 - val_loss: 69119.7812 - val_mean_absolute_error: 212.8484\n",
      "Epoch 20/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71757.6172 - mean_absolute_error: 213.5178 - val_loss: 69061.7500 - val_mean_absolute_error: 212.7372\n",
      "Epoch 21/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70853.1484 - mean_absolute_error: 212.2035 - val_loss: 69002.5703 - val_mean_absolute_error: 212.6238\n",
      "Epoch 22/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71667.4531 - mean_absolute_error: 213.3989 - val_loss: 68942.2734 - val_mean_absolute_error: 212.5085\n",
      "Epoch 23/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 77220.6094 - mean_absolute_error: 217.7014 - val_loss: 68880.9141 - val_mean_absolute_error: 212.3911\n",
      "Epoch 24/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73942.8906 - mean_absolute_error: 215.4105 - val_loss: 68818.5703 - val_mean_absolute_error: 212.2717\n",
      "Epoch 25/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 74410.6562 - mean_absolute_error: 213.8861 - val_loss: 68755.2656 - val_mean_absolute_error: 212.1502\n",
      "Epoch 26/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71918.9453 - mean_absolute_error: 214.6365 - val_loss: 68691.0234 - val_mean_absolute_error: 212.0269\n",
      "Epoch 27/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73906.4609 - mean_absolute_error: 215.9636 - val_loss: 68625.6094 - val_mean_absolute_error: 211.9013\n",
      "Epoch 28/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 76531.6406 - mean_absolute_error: 218.8335 - val_loss: 68559.1328 - val_mean_absolute_error: 211.7737\n",
      "Epoch 29/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67945.4297 - mean_absolute_error: 208.6851 - val_loss: 68491.6406 - val_mean_absolute_error: 211.6444\n",
      "Epoch 30/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 69180.9766 - mean_absolute_error: 211.9982 - val_loss: 68422.9141 - val_mean_absolute_error: 211.5127\n",
      "Epoch 31/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72568.7344 - mean_absolute_error: 214.4247 - val_loss: 68353.4141 - val_mean_absolute_error: 211.3793\n",
      "Epoch 32/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 74822.2500 - mean_absolute_error: 215.0104 - val_loss: 68282.8906 - val_mean_absolute_error: 211.2439\n",
      "Epoch 33/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72448.0859 - mean_absolute_error: 212.6195 - val_loss: 68211.1016 - val_mean_absolute_error: 211.1061\n",
      "Epoch 34/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67611.3906 - mean_absolute_error: 208.0584 - val_loss: 68138.0703 - val_mean_absolute_error: 210.9659\n",
      "Epoch 35/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72849.9922 - mean_absolute_error: 214.0348 - val_loss: 68064.0703 - val_mean_absolute_error: 210.8236\n",
      "Epoch 36/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68901.1094 - mean_absolute_error: 210.2192 - val_loss: 67988.8125 - val_mean_absolute_error: 210.6789\n",
      "Epoch 37/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71441.9297 - mean_absolute_error: 211.6045 - val_loss: 67912.4922 - val_mean_absolute_error: 210.5320\n",
      "Epoch 38/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72840.7422 - mean_absolute_error: 211.7889 - val_loss: 67835.0938 - val_mean_absolute_error: 210.3831\n",
      "Epoch 39/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71350.0781 - mean_absolute_error: 212.6512 - val_loss: 67756.6406 - val_mean_absolute_error: 210.2319\n",
      "Epoch 40/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 69664.8125 - mean_absolute_error: 211.8613 - val_loss: 67676.8359 - val_mean_absolute_error: 210.0785\n",
      "Epoch 41/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71746.8516 - mean_absolute_error: 211.5503 - val_loss: 67595.7500 - val_mean_absolute_error: 209.9223\n",
      "Epoch 42/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70115.2344 - mean_absolute_error: 209.8253 - val_loss: 67513.3906 - val_mean_absolute_error: 209.7638\n",
      "Epoch 43/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70493.8281 - mean_absolute_error: 211.1125 - val_loss: 67429.9062 - val_mean_absolute_error: 209.6029\n",
      "Epoch 44/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68115.2500 - mean_absolute_error: 208.1035 - val_loss: 67345.1484 - val_mean_absolute_error: 209.4396\n",
      "Epoch 45/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68746.3359 - mean_absolute_error: 207.8593 - val_loss: 67259.3906 - val_mean_absolute_error: 209.2741\n",
      "Epoch 46/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67904.7188 - mean_absolute_error: 208.4386 - val_loss: 67172.2578 - val_mean_absolute_error: 209.1062\n",
      "Epoch 47/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67324.3750 - mean_absolute_error: 207.2216 - val_loss: 67083.7188 - val_mean_absolute_error: 208.9357\n",
      "Epoch 48/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66692.9219 - mean_absolute_error: 206.3914 - val_loss: 66994.2422 - val_mean_absolute_error: 208.7635\n",
      "Epoch 49/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71353.3984 - mean_absolute_error: 210.4508 - val_loss: 66903.3281 - val_mean_absolute_error: 208.5885\n",
      "Epoch 50/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69550.3984 - mean_absolute_error: 212.5368 - val_loss: 66811.1719 - val_mean_absolute_error: 208.4117\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:54:38,157] Trial 12 finished with value: 209.25675267082806 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 7, 'learning_rate': 0.001949328647193513, 'dropout_rate': 0.001126394104576451, 'epoch': 50, 'batch_size': 100, 'optimizer': 'Adagrad'}. Best is trial 10 with value: 21.473532783144712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 27329.5293 - mean_absolute_error: 112.1567 - val_loss: 3094.6362 - val_mean_absolute_error: 34.0288\n",
      "Epoch 2/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4284.7466 - mean_absolute_error: 35.4780 - val_loss: 3699.9451 - val_mean_absolute_error: 37.2171\n",
      "Epoch 3/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4959.7456 - mean_absolute_error: 36.9759 - val_loss: 1785.5381 - val_mean_absolute_error: 23.1694\n",
      "Epoch 4/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4043.6060 - mean_absolute_error: 31.6338 - val_loss: 1871.6735 - val_mean_absolute_error: 24.8208\n",
      "Epoch 5/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3524.0061 - mean_absolute_error: 30.6112 - val_loss: 1939.0328 - val_mean_absolute_error: 27.0698\n",
      "Epoch 6/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3417.1414 - mean_absolute_error: 29.5118 - val_loss: 1830.4108 - val_mean_absolute_error: 24.2861\n",
      "Epoch 7/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2549.0581 - mean_absolute_error: 28.9892 - val_loss: 2230.8479 - val_mean_absolute_error: 30.8738\n",
      "Epoch 8/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2920.7131 - mean_absolute_error: 31.0757 - val_loss: 1593.0120 - val_mean_absolute_error: 21.1435\n",
      "Epoch 9/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4817.2061 - mean_absolute_error: 30.1688 - val_loss: 2044.2065 - val_mean_absolute_error: 26.4887\n",
      "Epoch 10/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3892.6707 - mean_absolute_error: 29.5171 - val_loss: 2094.9390 - val_mean_absolute_error: 26.8072\n",
      "Epoch 11/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2911.3118 - mean_absolute_error: 29.4362 - val_loss: 1843.1335 - val_mean_absolute_error: 24.8765\n",
      "Epoch 12/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3078.0356 - mean_absolute_error: 28.3492 - val_loss: 2778.7715 - val_mean_absolute_error: 32.0218\n",
      "Epoch 13/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4081.0332 - mean_absolute_error: 30.8348 - val_loss: 1751.9183 - val_mean_absolute_error: 23.0514\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:54:40,323] Trial 13 finished with value: 21.728389999121426 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 6, 'learning_rate': 0.04568519171679834, 'dropout_rate': 0.007594019076526404, 'epoch': 44, 'batch_size': 96, 'optimizer': 'RMSprop'}. Best is trial 10 with value: 21.473532783144712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 31975.9375 - mean_absolute_error: 125.2458 - val_loss: 4226.8564 - val_mean_absolute_error: 39.7096\n",
      "Epoch 2/42\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15462.6611 - mean_absolute_error: 72.4487 - val_loss: 9448.6953 - val_mean_absolute_error: 67.6971\n",
      "Epoch 3/42\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12233.9121 - mean_absolute_error: 69.5335 - val_loss: 2500.8669 - val_mean_absolute_error: 29.8789\n",
      "Epoch 4/42\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15043.8652 - mean_absolute_error: 72.7609 - val_loss: 1947.1917 - val_mean_absolute_error: 27.2564\n",
      "Epoch 5/42\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12374.3799 - mean_absolute_error: 65.4422 - val_loss: 2543.7021 - val_mean_absolute_error: 31.4606\n",
      "Epoch 6/42\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11054.4814 - mean_absolute_error: 65.3964 - val_loss: 2320.8958 - val_mean_absolute_error: 30.1334\n",
      "Epoch 7/42\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9628.2266 - mean_absolute_error: 61.5069 - val_loss: 9300.0703 - val_mean_absolute_error: 63.7292\n",
      "Epoch 8/42\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11187.2832 - mean_absolute_error: 64.2665 - val_loss: 2311.8345 - val_mean_absolute_error: 31.4119\n",
      "Epoch 9/42\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9299.7383 - mean_absolute_error: 61.5172 - val_loss: 5737.9111 - val_mean_absolute_error: 47.0391\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:54:42,176] Trial 14 finished with value: 27.763756472897523 and parameters: {'layer_1': 7, 'layer_2': 7, 'layer_3': 6, 'learning_rate': 0.09318117366635625, 'dropout_rate': 0.18538616285903822, 'epoch': 42, 'batch_size': 81, 'optimizer': 'RMSprop'}. Best is trial 10 with value: 21.473532783144712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 57935.3828 - mean_absolute_error: 177.6157 - val_loss: 8096.7925 - val_mean_absolute_error: 68.2266\n",
      "Epoch 2/44\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14577.0225 - mean_absolute_error: 71.6013 - val_loss: 5738.0210 - val_mean_absolute_error: 55.2564\n",
      "Epoch 3/44\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8396.1113 - mean_absolute_error: 55.0275 - val_loss: 3035.4709 - val_mean_absolute_error: 34.0253\n",
      "Epoch 4/44\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6563.3750 - mean_absolute_error: 49.1909 - val_loss: 2373.8621 - val_mean_absolute_error: 30.0066\n",
      "Epoch 5/44\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7707.6099 - mean_absolute_error: 49.3762 - val_loss: 2089.1653 - val_mean_absolute_error: 27.5692\n",
      "Epoch 6/44\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7749.5015 - mean_absolute_error: 48.3382 - val_loss: 2180.4675 - val_mean_absolute_error: 29.0859\n",
      "Epoch 7/44\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5644.1479 - mean_absolute_error: 45.1001 - val_loss: 2776.7275 - val_mean_absolute_error: 33.7651\n",
      "Epoch 8/44\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5786.5879 - mean_absolute_error: 44.0760 - val_loss: 3100.5876 - val_mean_absolute_error: 35.2524\n",
      "Epoch 9/44\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5508.9819 - mean_absolute_error: 43.2625 - val_loss: 1798.1541 - val_mean_absolute_error: 24.1259\n",
      "Epoch 10/44\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5665.5381 - mean_absolute_error: 44.5623 - val_loss: 1642.3250 - val_mean_absolute_error: 22.3857\n",
      "Epoch 11/44\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5914.7471 - mean_absolute_error: 44.5669 - val_loss: 2345.5049 - val_mean_absolute_error: 30.1223\n",
      "Epoch 12/44\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4710.5469 - mean_absolute_error: 42.7782 - val_loss: 1662.4946 - val_mean_absolute_error: 22.8507\n",
      "Epoch 13/44\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5365.9102 - mean_absolute_error: 44.3233 - val_loss: 1951.9589 - val_mean_absolute_error: 25.1275\n",
      "Epoch 14/44\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4310.8882 - mean_absolute_error: 42.0976 - val_loss: 1731.2823 - val_mean_absolute_error: 23.3956\n",
      "Epoch 15/44\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5638.1758 - mean_absolute_error: 43.1916 - val_loss: 4479.4321 - val_mean_absolute_error: 43.5704\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:54:44,896] Trial 15 finished with value: 23.10667681033015 and parameters: {'layer_1': 7, 'layer_2': 7, 'layer_3': 6, 'learning_rate': 0.023565357227572924, 'dropout_rate': 0.06437555327429811, 'epoch': 44, 'batch_size': 90, 'optimizer': 'RMSprop'}. Best is trial 10 with value: 21.473532783144712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 73664.8672 - mean_absolute_error: 213.3469 - val_loss: 69879.7656 - val_mean_absolute_error: 214.4142\n",
      "Epoch 2/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69389.1328 - mean_absolute_error: 211.5356 - val_loss: 69873.4062 - val_mean_absolute_error: 214.4003\n",
      "Epoch 3/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68196.1328 - mean_absolute_error: 211.4563 - val_loss: 69868.5156 - val_mean_absolute_error: 214.3895\n",
      "Epoch 4/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69078.8672 - mean_absolute_error: 212.5571 - val_loss: 69864.2109 - val_mean_absolute_error: 214.3801\n",
      "Epoch 5/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71482.5312 - mean_absolute_error: 213.6162 - val_loss: 69860.3438 - val_mean_absolute_error: 214.3715\n",
      "Epoch 6/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70087.8672 - mean_absolute_error: 215.5504 - val_loss: 69856.8828 - val_mean_absolute_error: 214.3638\n",
      "Epoch 7/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76313.9922 - mean_absolute_error: 218.8181 - val_loss: 69853.6406 - val_mean_absolute_error: 214.3565\n",
      "Epoch 8/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72843.7422 - mean_absolute_error: 215.5359 - val_loss: 69850.5703 - val_mean_absolute_error: 214.3497\n",
      "Epoch 9/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74309.2188 - mean_absolute_error: 217.9277 - val_loss: 69847.6641 - val_mean_absolute_error: 214.3433\n",
      "Epoch 10/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71445.8750 - mean_absolute_error: 213.0148 - val_loss: 69844.9141 - val_mean_absolute_error: 214.3372\n",
      "Epoch 11/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72570.4609 - mean_absolute_error: 216.5483 - val_loss: 69842.2969 - val_mean_absolute_error: 214.3313\n",
      "Epoch 12/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71132.2578 - mean_absolute_error: 214.8847 - val_loss: 69839.6484 - val_mean_absolute_error: 214.3255\n",
      "Epoch 13/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68959.1484 - mean_absolute_error: 210.1392 - val_loss: 69837.1016 - val_mean_absolute_error: 214.3198\n",
      "Epoch 14/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73795.8984 - mean_absolute_error: 218.1395 - val_loss: 69834.5000 - val_mean_absolute_error: 214.3141\n",
      "Epoch 15/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71389.8672 - mean_absolute_error: 213.3600 - val_loss: 69832.1250 - val_mean_absolute_error: 214.3088\n",
      "Epoch 16/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71202.2188 - mean_absolute_error: 213.3805 - val_loss: 69829.8359 - val_mean_absolute_error: 214.3037\n",
      "Epoch 17/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70786.8438 - mean_absolute_error: 213.2381 - val_loss: 69827.5469 - val_mean_absolute_error: 214.2986\n",
      "Epoch 18/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72852.8984 - mean_absolute_error: 215.2104 - val_loss: 69825.2734 - val_mean_absolute_error: 214.2935\n",
      "Epoch 19/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71757.1172 - mean_absolute_error: 213.5745 - val_loss: 69823.0391 - val_mean_absolute_error: 214.2886\n",
      "Epoch 20/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74212.0391 - mean_absolute_error: 216.0118 - val_loss: 69820.8203 - val_mean_absolute_error: 214.2836\n",
      "Epoch 21/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73822.2812 - mean_absolute_error: 215.6952 - val_loss: 69818.6875 - val_mean_absolute_error: 214.2789\n",
      "Epoch 22/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73106.9766 - mean_absolute_error: 215.8815 - val_loss: 69816.5938 - val_mean_absolute_error: 214.2741\n",
      "Epoch 23/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71521.0312 - mean_absolute_error: 213.4758 - val_loss: 69814.5000 - val_mean_absolute_error: 214.2695\n",
      "Epoch 24/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73097.9453 - mean_absolute_error: 215.1364 - val_loss: 69812.4531 - val_mean_absolute_error: 214.2649\n",
      "Epoch 25/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74971.8281 - mean_absolute_error: 218.4845 - val_loss: 69810.4688 - val_mean_absolute_error: 214.2605\n",
      "Epoch 26/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70884.1094 - mean_absolute_error: 213.3392 - val_loss: 69808.4688 - val_mean_absolute_error: 214.2560\n",
      "Epoch 27/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72946.2188 - mean_absolute_error: 216.7731 - val_loss: 69806.5000 - val_mean_absolute_error: 214.2516\n",
      "Epoch 28/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70853.8438 - mean_absolute_error: 213.6984 - val_loss: 69804.5703 - val_mean_absolute_error: 214.2473\n",
      "Epoch 29/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72717.7656 - mean_absolute_error: 215.1454 - val_loss: 69802.6719 - val_mean_absolute_error: 214.2430\n",
      "Epoch 30/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72307.5781 - mean_absolute_error: 213.8078 - val_loss: 69800.7500 - val_mean_absolute_error: 214.2387\n",
      "Epoch 31/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70552.5391 - mean_absolute_error: 213.9684 - val_loss: 69798.8594 - val_mean_absolute_error: 214.2345\n",
      "Epoch 32/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74843.9219 - mean_absolute_error: 216.7446 - val_loss: 69796.9844 - val_mean_absolute_error: 214.2302\n",
      "Epoch 33/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68907.1250 - mean_absolute_error: 211.3623 - val_loss: 69795.1562 - val_mean_absolute_error: 214.2261\n",
      "Epoch 34/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71773.4141 - mean_absolute_error: 214.7003 - val_loss: 69793.3203 - val_mean_absolute_error: 214.2220\n",
      "Epoch 35/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69012.6875 - mean_absolute_error: 212.4621 - val_loss: 69791.5391 - val_mean_absolute_error: 214.2179\n",
      "Epoch 36/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76672.6328 - mean_absolute_error: 220.6118 - val_loss: 69789.7812 - val_mean_absolute_error: 214.2140\n",
      "Epoch 37/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69414.2031 - mean_absolute_error: 212.7514 - val_loss: 69787.9844 - val_mean_absolute_error: 214.2099\n",
      "Epoch 38/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72705.0625 - mean_absolute_error: 216.2782 - val_loss: 69786.2656 - val_mean_absolute_error: 214.2061\n",
      "Epoch 39/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69608.6250 - mean_absolute_error: 212.4771 - val_loss: 69784.5234 - val_mean_absolute_error: 214.2021\n",
      "Epoch 40/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73846.3672 - mean_absolute_error: 218.4996 - val_loss: 69782.7891 - val_mean_absolute_error: 214.1983\n",
      "Epoch 41/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72166.4766 - mean_absolute_error: 215.3205 - val_loss: 69781.0781 - val_mean_absolute_error: 214.1944\n",
      "Epoch 42/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73874.3672 - mean_absolute_error: 217.1437 - val_loss: 69779.3438 - val_mean_absolute_error: 214.1905\n",
      "Epoch 43/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74852.2266 - mean_absolute_error: 218.1296 - val_loss: 69777.6250 - val_mean_absolute_error: 214.1866\n",
      "Epoch 44/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71079.5781 - mean_absolute_error: 214.6411 - val_loss: 69775.9453 - val_mean_absolute_error: 214.1829\n",
      "Epoch 45/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69357.1406 - mean_absolute_error: 212.6340 - val_loss: 69774.2266 - val_mean_absolute_error: 214.1790\n",
      "Epoch 46/46\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71837.8438 - mean_absolute_error: 213.7295 - val_loss: 69772.5234 - val_mean_absolute_error: 214.1752\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:54:50,312] Trial 16 finished with value: 214.94915919204354 and parameters: {'layer_1': 7, 'layer_2': 8, 'layer_3': 6, 'learning_rate': 0.0002632614063830047, 'dropout_rate': 0.18425184310243692, 'epoch': 46, 'batch_size': 64, 'optimizer': 'Adagrad'}. Best is trial 10 with value: 21.473532783144712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 43588.2539 - mean_absolute_error: 148.4813 - val_loss: 5877.1074 - val_mean_absolute_error: 54.4187\n",
      "Epoch 2/40\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11724.9482 - mean_absolute_error: 70.7370 - val_loss: 4307.4404 - val_mean_absolute_error: 47.4343\n",
      "Epoch 3/40\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9696.1738 - mean_absolute_error: 61.6153 - val_loss: 2276.2197 - val_mean_absolute_error: 28.3234\n",
      "Epoch 4/40\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11152.5264 - mean_absolute_error: 63.1880 - val_loss: 4842.0068 - val_mean_absolute_error: 52.0828\n",
      "Epoch 5/40\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10126.1475 - mean_absolute_error: 62.5220 - val_loss: 8467.7861 - val_mean_absolute_error: 61.8563\n",
      "Epoch 6/40\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10421.1582 - mean_absolute_error: 60.2860 - val_loss: 2957.5603 - val_mean_absolute_error: 35.2006\n",
      "Epoch 7/40\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8598.7988 - mean_absolute_error: 58.0381 - val_loss: 2033.7607 - val_mean_absolute_error: 26.9592\n",
      "Epoch 8/40\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8732.8359 - mean_absolute_error: 58.6217 - val_loss: 2758.9109 - val_mean_absolute_error: 34.9220\n",
      "Epoch 9/40\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8443.1162 - mean_absolute_error: 57.4493 - val_loss: 2172.7361 - val_mean_absolute_error: 29.8831\n",
      "Epoch 10/40\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7146.9531 - mean_absolute_error: 54.7410 - val_loss: 2880.6443 - val_mean_absolute_error: 34.5363\n",
      "Epoch 11/40\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9838.3926 - mean_absolute_error: 60.6521 - val_loss: 3390.4980 - val_mean_absolute_error: 39.5482\n",
      "Epoch 12/40\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7728.6846 - mean_absolute_error: 55.4016 - val_loss: 3289.8101 - val_mean_absolute_error: 38.3436\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:54:52,417] Trial 17 finished with value: 27.84658903698921 and parameters: {'layer_1': 6, 'layer_2': 6, 'layer_3': 7, 'learning_rate': 0.03739630610258247, 'dropout_rate': 0.1312010841031853, 'epoch': 40, 'batch_size': 85, 'optimizer': 'RMSprop'}. Best is trial 10 with value: 21.473532783144712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 73361.1094 - mean_absolute_error: 217.2784 - val_loss: 69179.3672 - val_mean_absolute_error: 213.1152\n",
      "Epoch 2/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71795.5625 - mean_absolute_error: 214.0976 - val_loss: 67117.9688 - val_mean_absolute_error: 209.9385\n",
      "Epoch 3/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70480.7266 - mean_absolute_error: 212.5416 - val_loss: 63308.1758 - val_mean_absolute_error: 204.2135\n",
      "Epoch 4/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 63925.6016 - mean_absolute_error: 202.7246 - val_loss: 56729.4258 - val_mean_absolute_error: 194.1437\n",
      "Epoch 5/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55249.1094 - mean_absolute_error: 191.5266 - val_loss: 46246.6836 - val_mean_absolute_error: 176.9780\n",
      "Epoch 6/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 45177.6875 - mean_absolute_error: 172.5438 - val_loss: 33862.7891 - val_mean_absolute_error: 153.4919\n",
      "Epoch 7/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31245.8281 - mean_absolute_error: 146.5248 - val_loss: 22068.6348 - val_mean_absolute_error: 124.2914\n",
      "Epoch 8/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25199.2383 - mean_absolute_error: 124.9425 - val_loss: 17092.1582 - val_mean_absolute_error: 107.7953\n",
      "Epoch 9/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22328.0332 - mean_absolute_error: 108.6048 - val_loss: 14383.0225 - val_mean_absolute_error: 97.2556\n",
      "Epoch 10/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 18364.6465 - mean_absolute_error: 101.0362 - val_loss: 12449.7354 - val_mean_absolute_error: 88.8891\n",
      "Epoch 11/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 18619.9336 - mean_absolute_error: 92.9135 - val_loss: 11380.7354 - val_mean_absolute_error: 84.8599\n",
      "Epoch 12/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18492.8809 - mean_absolute_error: 93.1641 - val_loss: 10536.6611 - val_mean_absolute_error: 81.7027\n",
      "Epoch 13/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 16692.3223 - mean_absolute_error: 88.2853 - val_loss: 9548.7715 - val_mean_absolute_error: 76.6853\n",
      "Epoch 14/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 18040.4668 - mean_absolute_error: 82.3968 - val_loss: 8775.3291 - val_mean_absolute_error: 72.9024\n",
      "Epoch 15/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13326.9219 - mean_absolute_error: 78.3136 - val_loss: 8132.6479 - val_mean_absolute_error: 69.8571\n",
      "Epoch 16/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12255.5518 - mean_absolute_error: 73.1092 - val_loss: 7479.8267 - val_mean_absolute_error: 66.1912\n",
      "Epoch 17/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11798.7178 - mean_absolute_error: 70.9483 - val_loss: 6773.4990 - val_mean_absolute_error: 61.3352\n",
      "Epoch 18/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 16674.8203 - mean_absolute_error: 71.1022 - val_loss: 6288.6768 - val_mean_absolute_error: 58.0738\n",
      "Epoch 19/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14776.1113 - mean_absolute_error: 66.2171 - val_loss: 6068.5610 - val_mean_absolute_error: 57.3629\n",
      "Epoch 20/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12477.2832 - mean_absolute_error: 63.3377 - val_loss: 5630.0986 - val_mean_absolute_error: 54.3513\n",
      "Epoch 21/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8993.7041 - mean_absolute_error: 60.7657 - val_loss: 5352.9971 - val_mean_absolute_error: 52.5249\n",
      "Epoch 22/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6821.0728 - mean_absolute_error: 55.2799 - val_loss: 5034.1123 - val_mean_absolute_error: 50.1225\n",
      "Epoch 23/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9939.4395 - mean_absolute_error: 57.4001 - val_loss: 4765.2871 - val_mean_absolute_error: 47.7917\n",
      "Epoch 24/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10776.0234 - mean_absolute_error: 55.8114 - val_loss: 4613.9434 - val_mean_absolute_error: 46.7586\n",
      "Epoch 25/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9351.0635 - mean_absolute_error: 54.6743 - val_loss: 4426.4058 - val_mean_absolute_error: 45.0834\n",
      "Epoch 26/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8469.1514 - mean_absolute_error: 51.5022 - val_loss: 4328.6157 - val_mean_absolute_error: 44.2617\n",
      "Epoch 27/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14632.0479 - mean_absolute_error: 53.3518 - val_loss: 4213.0938 - val_mean_absolute_error: 43.2497\n",
      "Epoch 28/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5952.7715 - mean_absolute_error: 50.3068 - val_loss: 4109.7896 - val_mean_absolute_error: 42.7070\n",
      "Epoch 29/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5917.8179 - mean_absolute_error: 48.0711 - val_loss: 3988.7102 - val_mean_absolute_error: 41.5781\n",
      "Epoch 30/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8175.4634 - mean_absolute_error: 49.2014 - val_loss: 3868.1445 - val_mean_absolute_error: 40.4807\n",
      "Epoch 31/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6737.0112 - mean_absolute_error: 49.2509 - val_loss: 3828.9067 - val_mean_absolute_error: 40.4380\n",
      "Epoch 32/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7088.2046 - mean_absolute_error: 46.9938 - val_loss: 3739.4062 - val_mean_absolute_error: 39.5806\n",
      "Epoch 33/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8391.5332 - mean_absolute_error: 47.6436 - val_loss: 3699.8882 - val_mean_absolute_error: 39.4163\n",
      "Epoch 34/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7473.4458 - mean_absolute_error: 47.4077 - val_loss: 3698.4978 - val_mean_absolute_error: 39.7045\n",
      "Epoch 35/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7676.8599 - mean_absolute_error: 49.0591 - val_loss: 3584.8430 - val_mean_absolute_error: 38.6161\n",
      "Epoch 36/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8008.9746 - mean_absolute_error: 47.4276 - val_loss: 3553.8218 - val_mean_absolute_error: 38.4085\n",
      "Epoch 37/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7515.7803 - mean_absolute_error: 47.9562 - val_loss: 3520.1611 - val_mean_absolute_error: 38.2209\n",
      "Epoch 38/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13008.3262 - mean_absolute_error: 50.0214 - val_loss: 3455.1611 - val_mean_absolute_error: 37.8638\n",
      "Epoch 39/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5564.7686 - mean_absolute_error: 44.1979 - val_loss: 3441.7791 - val_mean_absolute_error: 37.9384\n",
      "Epoch 40/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7167.0513 - mean_absolute_error: 46.7192 - val_loss: 3394.2700 - val_mean_absolute_error: 37.5590\n",
      "Epoch 41/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6496.6089 - mean_absolute_error: 46.0653 - val_loss: 3411.7156 - val_mean_absolute_error: 37.9470\n",
      "Epoch 42/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5801.7964 - mean_absolute_error: 44.4202 - val_loss: 3297.5798 - val_mean_absolute_error: 36.9383\n",
      "Epoch 43/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5699.8828 - mean_absolute_error: 44.3329 - val_loss: 3260.8757 - val_mean_absolute_error: 36.6459\n",
      "Epoch 44/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7005.4868 - mean_absolute_error: 45.9910 - val_loss: 3203.9463 - val_mean_absolute_error: 36.2767\n",
      "Epoch 45/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6988.9790 - mean_absolute_error: 43.9060 - val_loss: 3232.4990 - val_mean_absolute_error: 36.7653\n",
      "Epoch 46/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6095.5942 - mean_absolute_error: 44.9056 - val_loss: 3187.5540 - val_mean_absolute_error: 36.3555\n",
      "Epoch 47/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7430.3003 - mean_absolute_error: 46.2506 - val_loss: 3207.3357 - val_mean_absolute_error: 36.6085\n",
      "Epoch 48/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7206.7915 - mean_absolute_error: 45.4893 - val_loss: 3190.9141 - val_mean_absolute_error: 36.5920\n",
      "Epoch 49/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5104.6860 - mean_absolute_error: 42.4658 - val_loss: 3105.4563 - val_mean_absolute_error: 35.9064\n",
      "Epoch 50/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5967.3892 - mean_absolute_error: 44.2930 - val_loss: 3052.6238 - val_mean_absolute_error: 35.3722\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:54:58,109] Trial 18 finished with value: 35.49963660795093 and parameters: {'layer_1': 8, 'layer_2': 6, 'layer_3': 6, 'learning_rate': 0.0014686009469039923, 'dropout_rate': 0.04244467551929734, 'epoch': 50, 'batch_size': 72, 'optimizer': 'RMSprop'}. Best is trial 10 with value: 21.473532783144712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 50635.3242 - mean_absolute_error: 171.1543 - val_loss: 8331.5742 - val_mean_absolute_error: 70.4487\n",
      "Epoch 2/26\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19460.6133 - mean_absolute_error: 89.6706 - val_loss: 5394.1602 - val_mean_absolute_error: 51.7234\n",
      "Epoch 3/26\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 16031.0830 - mean_absolute_error: 80.2020 - val_loss: 3429.6230 - val_mean_absolute_error: 38.2947\n",
      "Epoch 4/26\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13339.6494 - mean_absolute_error: 72.3782 - val_loss: 2827.8716 - val_mean_absolute_error: 31.8550\n",
      "Epoch 5/26\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13182.8877 - mean_absolute_error: 68.6891 - val_loss: 3175.3450 - val_mean_absolute_error: 37.9688\n",
      "Epoch 6/26\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13554.1084 - mean_absolute_error: 70.9537 - val_loss: 3298.8633 - val_mean_absolute_error: 37.9526\n",
      "Epoch 7/26\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11623.9111 - mean_absolute_error: 68.7759 - val_loss: 3653.5435 - val_mean_absolute_error: 41.6990\n",
      "Epoch 8/26\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10670.4932 - mean_absolute_error: 66.9389 - val_loss: 3210.8726 - val_mean_absolute_error: 38.4575\n",
      "Epoch 9/26\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10078.2803 - mean_absolute_error: 66.5132 - val_loss: 2577.5676 - val_mean_absolute_error: 34.7507\n",
      "Epoch 10/26\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11154.3525 - mean_absolute_error: 67.6350 - val_loss: 4291.1548 - val_mean_absolute_error: 43.9389\n",
      "Epoch 11/26\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11559.6289 - mean_absolute_error: 67.4444 - val_loss: 3966.8269 - val_mean_absolute_error: 44.8691\n",
      "Epoch 12/26\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11306.5449 - mean_absolute_error: 66.7372 - val_loss: 3776.9067 - val_mean_absolute_error: 43.2630\n",
      "Epoch 13/26\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9866.7197 - mean_absolute_error: 65.3726 - val_loss: 3139.2080 - val_mean_absolute_error: 37.3780\n",
      "Epoch 14/26\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10509.0391 - mean_absolute_error: 65.2315 - val_loss: 6198.5693 - val_mean_absolute_error: 55.3158\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:55:00,334] Trial 19 finished with value: 35.45579083068371 and parameters: {'layer_1': 6, 'layer_2': 7, 'layer_3': 7, 'learning_rate': 0.018122688415507102, 'dropout_rate': 0.24638410931281057, 'epoch': 26, 'batch_size': 91, 'optimizer': 'RMSprop'}. Best is trial 10 with value: 21.473532783144712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 76784.1172 - mean_absolute_error: 220.6561 - val_loss: 69993.6953 - val_mean_absolute_error: 214.6300\n",
      "Epoch 2/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76583.3438 - mean_absolute_error: 219.7958 - val_loss: 69993.6797 - val_mean_absolute_error: 214.6300\n",
      "Epoch 3/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68915.6641 - mean_absolute_error: 211.0504 - val_loss: 69993.6719 - val_mean_absolute_error: 214.6299\n",
      "Epoch 4/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73710.3203 - mean_absolute_error: 217.3810 - val_loss: 69993.6562 - val_mean_absolute_error: 214.6299\n",
      "Epoch 5/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71101.0547 - mean_absolute_error: 213.8282 - val_loss: 69993.6406 - val_mean_absolute_error: 214.6299\n",
      "Epoch 6/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74570.0391 - mean_absolute_error: 219.3694 - val_loss: 69993.6250 - val_mean_absolute_error: 214.6298\n",
      "Epoch 7/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74195.4453 - mean_absolute_error: 216.6928 - val_loss: 69993.6094 - val_mean_absolute_error: 214.6297\n",
      "Epoch 8/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69821.8281 - mean_absolute_error: 213.7336 - val_loss: 69993.5938 - val_mean_absolute_error: 214.6297\n",
      "Epoch 9/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68131.2109 - mean_absolute_error: 211.8366 - val_loss: 69993.5703 - val_mean_absolute_error: 214.6297\n",
      "Epoch 10/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71754.9453 - mean_absolute_error: 213.0456 - val_loss: 69993.5547 - val_mean_absolute_error: 214.6296\n",
      "Epoch 11/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74969.3594 - mean_absolute_error: 217.3574 - val_loss: 69993.5547 - val_mean_absolute_error: 214.6295\n",
      "Epoch 12/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75197.9297 - mean_absolute_error: 218.9030 - val_loss: 69993.5391 - val_mean_absolute_error: 214.6295\n",
      "Epoch 13/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71947.0312 - mean_absolute_error: 215.2429 - val_loss: 69993.5234 - val_mean_absolute_error: 214.6295\n",
      "Epoch 14/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72665.3359 - mean_absolute_error: 217.5249 - val_loss: 69993.5000 - val_mean_absolute_error: 214.6294\n",
      "Epoch 15/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73035.5938 - mean_absolute_error: 216.5133 - val_loss: 69993.4922 - val_mean_absolute_error: 214.6294\n",
      "Epoch 16/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76430.2891 - mean_absolute_error: 218.4478 - val_loss: 69993.4766 - val_mean_absolute_error: 214.6293\n",
      "Epoch 17/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71994.3047 - mean_absolute_error: 215.4511 - val_loss: 69993.4688 - val_mean_absolute_error: 214.6293\n",
      "Epoch 18/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72396.1250 - mean_absolute_error: 216.9979 - val_loss: 69993.4531 - val_mean_absolute_error: 214.6293\n",
      "Epoch 19/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73044.4844 - mean_absolute_error: 214.1637 - val_loss: 69993.4453 - val_mean_absolute_error: 214.6292\n",
      "Epoch 20/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74434.6016 - mean_absolute_error: 216.5869 - val_loss: 69993.4297 - val_mean_absolute_error: 214.6292\n",
      "Epoch 21/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73700.3594 - mean_absolute_error: 217.5759 - val_loss: 69993.4141 - val_mean_absolute_error: 214.6291\n",
      "Epoch 22/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72938.5078 - mean_absolute_error: 215.5298 - val_loss: 69993.3984 - val_mean_absolute_error: 214.6291\n",
      "Epoch 23/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72359.7969 - mean_absolute_error: 216.6499 - val_loss: 69993.3906 - val_mean_absolute_error: 214.6290\n",
      "Epoch 24/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69473.9297 - mean_absolute_error: 212.2120 - val_loss: 69993.3672 - val_mean_absolute_error: 214.6290\n",
      "Epoch 25/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73845.2188 - mean_absolute_error: 216.1164 - val_loss: 69993.3594 - val_mean_absolute_error: 214.6289\n",
      "Epoch 26/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69721.9609 - mean_absolute_error: 212.6947 - val_loss: 69993.3438 - val_mean_absolute_error: 214.6289\n",
      "Epoch 27/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69957.4844 - mean_absolute_error: 213.4286 - val_loss: 69993.3281 - val_mean_absolute_error: 214.6288\n",
      "Epoch 28/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69068.3516 - mean_absolute_error: 211.3463 - val_loss: 69993.3125 - val_mean_absolute_error: 214.6288\n",
      "Epoch 29/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71875.5469 - mean_absolute_error: 215.6804 - val_loss: 69993.3047 - val_mean_absolute_error: 214.6288\n",
      "Epoch 30/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73010.0234 - mean_absolute_error: 217.1464 - val_loss: 69993.2812 - val_mean_absolute_error: 214.6287\n",
      "Epoch 31/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69538.3906 - mean_absolute_error: 211.4253 - val_loss: 69993.2734 - val_mean_absolute_error: 214.6286\n",
      "Epoch 32/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73461.5781 - mean_absolute_error: 216.5503 - val_loss: 69993.2500 - val_mean_absolute_error: 214.6286\n",
      "Epoch 33/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72669.9531 - mean_absolute_error: 214.8113 - val_loss: 69993.2344 - val_mean_absolute_error: 214.6286\n",
      "Epoch 34/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73469.5000 - mean_absolute_error: 216.0654 - val_loss: 69993.2109 - val_mean_absolute_error: 214.6285\n",
      "Epoch 35/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70734.3984 - mean_absolute_error: 212.9831 - val_loss: 69993.2031 - val_mean_absolute_error: 214.6284\n",
      "Epoch 36/36\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73119.1172 - mean_absolute_error: 217.7442 - val_loss: 69993.1875 - val_mean_absolute_error: 214.6284\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:55:04,985] Trial 20 finished with value: 215.40559042531922 and parameters: {'layer_1': 6, 'layer_2': 8, 'layer_3': 5, 'learning_rate': 0.00024353222200904616, 'dropout_rate': 0.234969655742929, 'epoch': 36, 'batch_size': 63, 'optimizer': 'Adadelta'}. Best is trial 10 with value: 21.473532783144712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 71918.6953 - mean_absolute_error: 211.8280 - val_loss: 67597.1328 - val_mean_absolute_error: 209.0529\n",
      "Epoch 2/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67219.3281 - mean_absolute_error: 204.1907 - val_loss: 57721.2695 - val_mean_absolute_error: 185.0750\n",
      "Epoch 3/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 54131.4727 - mean_absolute_error: 177.0112 - val_loss: 38556.8984 - val_mean_absolute_error: 148.6422\n",
      "Epoch 4/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34803.2773 - mean_absolute_error: 140.6897 - val_loss: 20037.5762 - val_mean_absolute_error: 111.9230\n",
      "Epoch 5/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20110.2363 - mean_absolute_error: 107.0691 - val_loss: 11383.6826 - val_mean_absolute_error: 83.3944\n",
      "Epoch 6/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11693.7422 - mean_absolute_error: 77.9833 - val_loss: 8926.2793 - val_mean_absolute_error: 70.3467\n",
      "Epoch 7/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12568.6377 - mean_absolute_error: 67.3387 - val_loss: 7315.0654 - val_mean_absolute_error: 60.3409\n",
      "Epoch 8/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9818.6406 - mean_absolute_error: 57.4695 - val_loss: 6123.9561 - val_mean_absolute_error: 55.1071\n",
      "Epoch 9/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6216.5850 - mean_absolute_error: 50.2483 - val_loss: 5009.9014 - val_mean_absolute_error: 48.1108\n",
      "Epoch 10/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7610.2085 - mean_absolute_error: 48.0079 - val_loss: 4250.4121 - val_mean_absolute_error: 43.6414\n",
      "Epoch 11/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5363.1475 - mean_absolute_error: 43.4428 - val_loss: 3702.8157 - val_mean_absolute_error: 40.4061\n",
      "Epoch 12/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4312.7666 - mean_absolute_error: 38.7913 - val_loss: 3357.0481 - val_mean_absolute_error: 38.8218\n",
      "Epoch 13/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5342.1587 - mean_absolute_error: 37.8004 - val_loss: 3020.6523 - val_mean_absolute_error: 36.0263\n",
      "Epoch 14/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4907.3418 - mean_absolute_error: 35.9987 - val_loss: 2785.2466 - val_mean_absolute_error: 33.3612\n",
      "Epoch 15/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4198.5015 - mean_absolute_error: 33.7632 - val_loss: 2674.1482 - val_mean_absolute_error: 33.9382\n",
      "Epoch 16/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4071.7979 - mean_absolute_error: 33.3426 - val_loss: 2401.6582 - val_mean_absolute_error: 31.0873\n",
      "Epoch 17/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3283.2100 - mean_absolute_error: 30.9879 - val_loss: 2227.0474 - val_mean_absolute_error: 29.4314\n",
      "Epoch 18/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2886.0620 - mean_absolute_error: 28.1011 - val_loss: 2092.9792 - val_mean_absolute_error: 28.1832\n",
      "Epoch 19/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3559.3738 - mean_absolute_error: 28.2285 - val_loss: 2121.4961 - val_mean_absolute_error: 28.4979\n",
      "Epoch 20/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3809.2148 - mean_absolute_error: 28.7810 - val_loss: 1925.5792 - val_mean_absolute_error: 25.2393\n",
      "Epoch 21/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2924.4705 - mean_absolute_error: 26.2030 - val_loss: 1826.3540 - val_mean_absolute_error: 24.1288\n",
      "Epoch 22/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2888.9966 - mean_absolute_error: 25.5287 - val_loss: 1747.8217 - val_mean_absolute_error: 23.7456\n",
      "Epoch 23/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3371.8318 - mean_absolute_error: 25.8407 - val_loss: 1695.1172 - val_mean_absolute_error: 23.0624\n",
      "Epoch 24/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2151.9775 - mean_absolute_error: 23.1131 - val_loss: 1674.0641 - val_mean_absolute_error: 23.1430\n",
      "Epoch 25/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2105.5842 - mean_absolute_error: 23.4146 - val_loss: 1643.2809 - val_mean_absolute_error: 22.4695\n",
      "Epoch 26/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3152.2256 - mean_absolute_error: 24.1173 - val_loss: 1603.7061 - val_mean_absolute_error: 21.9371\n",
      "Epoch 27/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1741.0021 - mean_absolute_error: 21.7449 - val_loss: 1605.9728 - val_mean_absolute_error: 22.1815\n",
      "Epoch 28/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2769.8801 - mean_absolute_error: 23.1149 - val_loss: 1590.7618 - val_mean_absolute_error: 21.9159\n",
      "Epoch 29/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3946.8779 - mean_absolute_error: 25.2443 - val_loss: 1583.8800 - val_mean_absolute_error: 21.5083\n",
      "Epoch 30/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2663.3245 - mean_absolute_error: 22.9111 - val_loss: 1644.7281 - val_mean_absolute_error: 22.4785\n",
      "Epoch 31/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2575.5645 - mean_absolute_error: 22.5281 - val_loss: 1571.6302 - val_mean_absolute_error: 21.1515\n",
      "Epoch 32/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2838.4551 - mean_absolute_error: 22.6694 - val_loss: 1599.9218 - val_mean_absolute_error: 21.8292\n",
      "Epoch 33/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2525.9521 - mean_absolute_error: 22.0655 - val_loss: 1565.5525 - val_mean_absolute_error: 20.9637\n",
      "Epoch 34/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2728.6340 - mean_absolute_error: 22.6921 - val_loss: 1580.2052 - val_mean_absolute_error: 21.5739\n",
      "Epoch 35/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1935.4033 - mean_absolute_error: 21.1828 - val_loss: 1567.7797 - val_mean_absolute_error: 21.5444\n",
      "Epoch 36/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1893.5930 - mean_absolute_error: 21.5661 - val_loss: 1559.6257 - val_mean_absolute_error: 21.1307\n",
      "Epoch 37/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2562.9607 - mean_absolute_error: 21.9827 - val_loss: 1583.9360 - val_mean_absolute_error: 21.2826\n",
      "Epoch 38/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4277.8491 - mean_absolute_error: 23.8419 - val_loss: 1584.1976 - val_mean_absolute_error: 21.2510\n",
      "Epoch 39/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2191.9263 - mean_absolute_error: 22.3921 - val_loss: 1570.7175 - val_mean_absolute_error: 21.5390\n",
      "Epoch 40/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1766.0426 - mean_absolute_error: 21.6238 - val_loss: 1564.4271 - val_mean_absolute_error: 21.1357\n",
      "Epoch 41/48\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1774.0515 - mean_absolute_error: 21.3377 - val_loss: 1563.6273 - val_mean_absolute_error: 20.8452\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:55:09,214] Trial 21 finished with value: 21.70959407940805 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 7, 'learning_rate': 0.003751345469486014, 'dropout_rate': 0.0010474514907634538, 'epoch': 48, 'batch_size': 99, 'optimizer': 'RMSprop'}. Best is trial 10 with value: 21.473532783144712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 75652.3828 - mean_absolute_error: 221.3431 - val_loss: 67179.2344 - val_mean_absolute_error: 208.7257\n",
      "Epoch 2/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67862.5312 - mean_absolute_error: 207.0497 - val_loss: 54674.1211 - val_mean_absolute_error: 186.1518\n",
      "Epoch 3/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52188.9805 - mean_absolute_error: 176.2172 - val_loss: 30858.0977 - val_mean_absolute_error: 139.2126\n",
      "Epoch 4/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26547.8652 - mean_absolute_error: 128.1940 - val_loss: 13463.7559 - val_mean_absolute_error: 93.5554\n",
      "Epoch 5/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15916.4375 - mean_absolute_error: 93.1927 - val_loss: 11019.7070 - val_mean_absolute_error: 82.3170\n",
      "Epoch 6/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14124.7588 - mean_absolute_error: 82.3388 - val_loss: 9496.4170 - val_mean_absolute_error: 75.1063\n",
      "Epoch 7/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12343.0430 - mean_absolute_error: 76.3111 - val_loss: 8091.7407 - val_mean_absolute_error: 67.2737\n",
      "Epoch 8/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13410.8652 - mean_absolute_error: 69.7116 - val_loss: 7078.1123 - val_mean_absolute_error: 61.6075\n",
      "Epoch 9/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9554.6143 - mean_absolute_error: 63.7994 - val_loss: 6190.7847 - val_mean_absolute_error: 56.0125\n",
      "Epoch 10/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8572.8535 - mean_absolute_error: 58.5637 - val_loss: 5399.5410 - val_mean_absolute_error: 50.6996\n",
      "Epoch 11/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7605.5020 - mean_absolute_error: 54.0310 - val_loss: 4887.3887 - val_mean_absolute_error: 45.9765\n",
      "Epoch 12/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7243.0981 - mean_absolute_error: 48.0834 - val_loss: 4445.4038 - val_mean_absolute_error: 44.1405\n",
      "Epoch 13/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6662.1421 - mean_absolute_error: 47.9782 - val_loss: 4132.9785 - val_mean_absolute_error: 41.6302\n",
      "Epoch 14/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5632.9253 - mean_absolute_error: 44.3817 - val_loss: 3842.1377 - val_mean_absolute_error: 40.0514\n",
      "Epoch 15/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6288.7603 - mean_absolute_error: 43.8497 - val_loss: 3615.9922 - val_mean_absolute_error: 38.7260\n",
      "Epoch 16/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4283.9048 - mean_absolute_error: 41.9901 - val_loss: 3447.8638 - val_mean_absolute_error: 37.6756\n",
      "Epoch 17/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5243.9473 - mean_absolute_error: 42.3879 - val_loss: 3315.8118 - val_mean_absolute_error: 37.1777\n",
      "Epoch 18/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6601.4097 - mean_absolute_error: 41.6318 - val_loss: 3228.8926 - val_mean_absolute_error: 36.8329\n",
      "Epoch 19/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4992.7900 - mean_absolute_error: 41.8082 - val_loss: 3025.0454 - val_mean_absolute_error: 34.8174\n",
      "Epoch 20/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4305.3579 - mean_absolute_error: 38.2472 - val_loss: 3057.1013 - val_mean_absolute_error: 35.6842\n",
      "Epoch 21/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4161.3125 - mean_absolute_error: 37.4663 - val_loss: 2823.0205 - val_mean_absolute_error: 33.2320\n",
      "Epoch 22/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4560.2036 - mean_absolute_error: 38.6352 - val_loss: 2751.9355 - val_mean_absolute_error: 32.6599\n",
      "Epoch 23/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6129.9795 - mean_absolute_error: 40.5514 - val_loss: 2625.5330 - val_mean_absolute_error: 31.4764\n",
      "Epoch 24/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5413.2612 - mean_absolute_error: 37.9811 - val_loss: 2553.7249 - val_mean_absolute_error: 30.7988\n",
      "Epoch 25/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3845.5679 - mean_absolute_error: 36.0297 - val_loss: 2497.8738 - val_mean_absolute_error: 30.9857\n",
      "Epoch 26/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4132.9116 - mean_absolute_error: 36.1663 - val_loss: 2400.5173 - val_mean_absolute_error: 30.3773\n",
      "Epoch 27/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5005.2290 - mean_absolute_error: 36.6863 - val_loss: 2295.3943 - val_mean_absolute_error: 29.4850\n",
      "Epoch 28/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5167.5293 - mean_absolute_error: 37.8902 - val_loss: 2228.0017 - val_mean_absolute_error: 28.4183\n",
      "Epoch 29/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3507.8132 - mean_absolute_error: 34.2791 - val_loss: 2175.0037 - val_mean_absolute_error: 28.3513\n",
      "Epoch 30/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4569.2407 - mean_absolute_error: 35.8906 - val_loss: 2131.7617 - val_mean_absolute_error: 27.9318\n",
      "Epoch 31/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4396.4624 - mean_absolute_error: 34.0190 - val_loss: 2239.0469 - val_mean_absolute_error: 27.8519\n",
      "Epoch 32/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3582.2185 - mean_absolute_error: 33.7446 - val_loss: 2027.8655 - val_mean_absolute_error: 26.8448\n",
      "Epoch 33/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4825.3613 - mean_absolute_error: 34.4668 - val_loss: 1987.1808 - val_mean_absolute_error: 25.9827\n",
      "Epoch 34/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3587.4336 - mean_absolute_error: 32.0592 - val_loss: 1927.0509 - val_mean_absolute_error: 25.4100\n",
      "Epoch 35/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3062.6123 - mean_absolute_error: 31.8124 - val_loss: 1895.7979 - val_mean_absolute_error: 25.3929\n",
      "Epoch 36/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3114.8967 - mean_absolute_error: 32.0807 - val_loss: 1851.0856 - val_mean_absolute_error: 24.9206\n",
      "Epoch 37/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3688.3052 - mean_absolute_error: 32.7900 - val_loss: 1858.7307 - val_mean_absolute_error: 25.1160\n",
      "Epoch 38/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3133.6074 - mean_absolute_error: 32.3584 - val_loss: 1784.7673 - val_mean_absolute_error: 24.4853\n",
      "Epoch 39/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2931.5466 - mean_absolute_error: 31.3547 - val_loss: 1859.8015 - val_mean_absolute_error: 25.2410\n",
      "Epoch 40/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4219.0537 - mean_absolute_error: 31.6925 - val_loss: 1729.1466 - val_mean_absolute_error: 23.2369\n",
      "Epoch 41/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4075.1074 - mean_absolute_error: 31.7924 - val_loss: 1735.8169 - val_mean_absolute_error: 23.0862\n",
      "Epoch 42/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2820.2534 - mean_absolute_error: 31.2440 - val_loss: 1735.2310 - val_mean_absolute_error: 23.5482\n",
      "Epoch 43/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3179.3135 - mean_absolute_error: 31.0003 - val_loss: 1764.1359 - val_mean_absolute_error: 23.7677\n",
      "Epoch 44/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2916.3965 - mean_absolute_error: 29.7699 - val_loss: 1756.0519 - val_mean_absolute_error: 24.2827\n",
      "Epoch 45/47\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2633.3110 - mean_absolute_error: 30.3835 - val_loss: 1730.0693 - val_mean_absolute_error: 23.5056\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:55:13,791] Trial 22 finished with value: 23.508948074966668 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 7, 'learning_rate': 0.002875313796032506, 'dropout_rate': 0.026292192328722666, 'epoch': 47, 'batch_size': 91, 'optimizer': 'RMSprop'}. Best is trial 10 with value: 21.473532783144712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 69930.9844 - mean_absolute_error: 210.4320 - val_loss: 31778.0430 - val_mean_absolute_error: 148.4656\n",
      "Epoch 2/41\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26831.2969 - mean_absolute_error: 126.4965 - val_loss: 9723.5391 - val_mean_absolute_error: 74.2458\n",
      "Epoch 3/41\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16505.8906 - mean_absolute_error: 81.2577 - val_loss: 6500.3257 - val_mean_absolute_error: 58.1200\n",
      "Epoch 4/41\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14380.7539 - mean_absolute_error: 74.2301 - val_loss: 5054.8945 - val_mean_absolute_error: 50.4554\n",
      "Epoch 5/41\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9154.2617 - mean_absolute_error: 62.4914 - val_loss: 4191.5708 - val_mean_absolute_error: 44.5699\n",
      "Epoch 6/41\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9022.5420 - mean_absolute_error: 58.4919 - val_loss: 3479.3186 - val_mean_absolute_error: 39.1497\n",
      "Epoch 7/41\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7822.3213 - mean_absolute_error: 54.5466 - val_loss: 3131.4604 - val_mean_absolute_error: 36.6032\n",
      "Epoch 8/41\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9471.9209 - mean_absolute_error: 54.4283 - val_loss: 3086.6965 - val_mean_absolute_error: 36.4010\n",
      "Epoch 9/41\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6551.0801 - mean_absolute_error: 51.6861 - val_loss: 2625.6389 - val_mean_absolute_error: 32.4016\n",
      "Epoch 10/41\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6348.0854 - mean_absolute_error: 49.6336 - val_loss: 3026.1226 - val_mean_absolute_error: 35.6026\n",
      "Epoch 11/41\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6897.0654 - mean_absolute_error: 51.0704 - val_loss: 2211.6753 - val_mean_absolute_error: 28.0438\n",
      "Epoch 12/41\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5628.0557 - mean_absolute_error: 47.1105 - val_loss: 2122.0747 - val_mean_absolute_error: 27.5448\n",
      "Epoch 13/41\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8732.6025 - mean_absolute_error: 51.7698 - val_loss: 2509.7915 - val_mean_absolute_error: 31.6853\n",
      "Epoch 14/41\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5596.6406 - mean_absolute_error: 46.4596 - val_loss: 2225.8113 - val_mean_absolute_error: 29.5132\n",
      "Epoch 15/41\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6631.0845 - mean_absolute_error: 47.2158 - val_loss: 2025.7970 - val_mean_absolute_error: 27.1545\n",
      "Epoch 16/41\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5406.7974 - mean_absolute_error: 46.8579 - val_loss: 1858.0001 - val_mean_absolute_error: 24.9637\n",
      "Epoch 17/41\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7207.6543 - mean_absolute_error: 49.5593 - val_loss: 1839.7441 - val_mean_absolute_error: 24.8986\n",
      "Epoch 18/41\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5594.9385 - mean_absolute_error: 46.1511 - val_loss: 2224.2463 - val_mean_absolute_error: 29.4408\n",
      "Epoch 19/41\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5349.9800 - mean_absolute_error: 45.2817 - val_loss: 2277.8169 - val_mean_absolute_error: 29.4615\n",
      "Epoch 20/41\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7923.6514 - mean_absolute_error: 47.8613 - val_loss: 1750.6331 - val_mean_absolute_error: 23.9282\n",
      "Epoch 21/41\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7183.3994 - mean_absolute_error: 48.8796 - val_loss: 2065.2307 - val_mean_absolute_error: 28.1359\n",
      "Epoch 22/41\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6757.6416 - mean_absolute_error: 45.7652 - val_loss: 1874.5762 - val_mean_absolute_error: 25.5741\n",
      "Epoch 23/41\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5578.7080 - mean_absolute_error: 45.4829 - val_loss: 2393.9307 - val_mean_absolute_error: 30.5015\n",
      "Epoch 24/41\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7048.8013 - mean_absolute_error: 45.5961 - val_loss: 3158.0620 - val_mean_absolute_error: 36.8239\n",
      "Epoch 25/41\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5341.4585 - mean_absolute_error: 44.5598 - val_loss: 2198.2263 - val_mean_absolute_error: 29.5538\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:55:16,713] Trial 23 finished with value: 24.61450035914183 and parameters: {'layer_1': 7, 'layer_2': 7, 'layer_3': 6, 'learning_rate': 0.008925055266782042, 'dropout_rate': 0.09150233876470117, 'epoch': 41, 'batch_size': 97, 'optimizer': 'RMSprop'}. Best is trial 10 with value: 21.473532783144712.\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 70344.3281 - mean_absolute_error: 213.8830 - val_loss: 69840.0625 - val_mean_absolute_error: 214.3781\n",
      "Epoch 2/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74365.2188 - mean_absolute_error: 217.5504 - val_loss: 69335.5781 - val_mean_absolute_error: 213.5613\n",
      "Epoch 3/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72700.1641 - mean_absolute_error: 217.0917 - val_loss: 68151.6250 - val_mean_absolute_error: 211.6672\n",
      "Epoch 4/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67297.8047 - mean_absolute_error: 208.0854 - val_loss: 65723.3828 - val_mean_absolute_error: 207.7583\n",
      "Epoch 5/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66640.0625 - mean_absolute_error: 205.7039 - val_loss: 60893.9648 - val_mean_absolute_error: 199.9611\n",
      "Epoch 6/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 60534.8477 - mean_absolute_error: 195.1694 - val_loss: 52017.9766 - val_mean_absolute_error: 185.0848\n",
      "Epoch 7/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 50801.5312 - mean_absolute_error: 180.4654 - val_loss: 38728.3711 - val_mean_absolute_error: 160.6233\n",
      "Epoch 8/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 36418.5273 - mean_absolute_error: 154.6448 - val_loss: 24604.6055 - val_mean_absolute_error: 128.3563\n",
      "Epoch 9/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25612.1719 - mean_absolute_error: 126.5519 - val_loss: 17462.8398 - val_mean_absolute_error: 107.5243\n",
      "Epoch 10/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22254.9141 - mean_absolute_error: 108.7698 - val_loss: 15019.5146 - val_mean_absolute_error: 99.1702\n",
      "Epoch 11/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 18333.8027 - mean_absolute_error: 102.3432 - val_loss: 13509.0430 - val_mean_absolute_error: 93.7494\n",
      "Epoch 12/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 16716.4551 - mean_absolute_error: 97.5459 - val_loss: 12636.3506 - val_mean_absolute_error: 90.8696\n",
      "Epoch 13/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15750.7402 - mean_absolute_error: 93.3074 - val_loss: 11718.9492 - val_mean_absolute_error: 87.2982\n",
      "Epoch 14/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15119.4355 - mean_absolute_error: 91.4726 - val_loss: 10967.8965 - val_mean_absolute_error: 84.1880\n",
      "Epoch 15/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14208.5557 - mean_absolute_error: 89.9426 - val_loss: 10221.0234 - val_mean_absolute_error: 80.8466\n",
      "Epoch 16/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14844.8633 - mean_absolute_error: 85.4610 - val_loss: 9679.6973 - val_mean_absolute_error: 78.5166\n",
      "Epoch 17/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14982.1055 - mean_absolute_error: 83.6892 - val_loss: 8912.9336 - val_mean_absolute_error: 73.9645\n",
      "Epoch 18/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12693.0303 - mean_absolute_error: 79.5039 - val_loss: 8418.5957 - val_mean_absolute_error: 71.5666\n",
      "Epoch 19/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12205.5986 - mean_absolute_error: 77.1472 - val_loss: 7966.9580 - val_mean_absolute_error: 69.2555\n",
      "Epoch 20/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12846.8242 - mean_absolute_error: 76.2877 - val_loss: 7473.6509 - val_mean_absolute_error: 66.2232\n",
      "Epoch 21/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11601.4463 - mean_absolute_error: 72.9009 - val_loss: 6993.5181 - val_mean_absolute_error: 62.9170\n",
      "Epoch 22/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8954.5537 - mean_absolute_error: 67.4825 - val_loss: 6655.7837 - val_mean_absolute_error: 60.7494\n",
      "Epoch 23/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11153.2959 - mean_absolute_error: 67.3664 - val_loss: 6340.9302 - val_mean_absolute_error: 58.6297\n",
      "Epoch 24/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10800.3311 - mean_absolute_error: 63.9801 - val_loss: 6006.6001 - val_mean_absolute_error: 55.7530\n",
      "Epoch 25/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7874.0483 - mean_absolute_error: 60.2923 - val_loss: 5801.5947 - val_mean_absolute_error: 54.8340\n",
      "Epoch 26/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9084.1729 - mean_absolute_error: 61.0854 - val_loss: 5546.8711 - val_mean_absolute_error: 53.0010\n",
      "Epoch 27/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8351.5098 - mean_absolute_error: 58.2344 - val_loss: 5301.2637 - val_mean_absolute_error: 51.0418\n",
      "Epoch 28/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7996.0752 - mean_absolute_error: 57.8803 - val_loss: 5109.3149 - val_mean_absolute_error: 49.6787\n",
      "Epoch 29/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8786.9980 - mean_absolute_error: 57.5153 - val_loss: 4887.0000 - val_mean_absolute_error: 47.8326\n",
      "Epoch 30/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10374.6387 - mean_absolute_error: 58.0656 - val_loss: 4715.6997 - val_mean_absolute_error: 46.7549\n",
      "Epoch 31/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7634.6992 - mean_absolute_error: 53.9396 - val_loss: 4506.6084 - val_mean_absolute_error: 44.8341\n",
      "Epoch 32/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9060.3643 - mean_absolute_error: 55.7086 - val_loss: 4407.5703 - val_mean_absolute_error: 44.4800\n",
      "Epoch 33/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7392.1851 - mean_absolute_error: 52.0616 - val_loss: 4289.8887 - val_mean_absolute_error: 43.3224\n",
      "Epoch 34/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7987.3525 - mean_absolute_error: 52.4912 - val_loss: 4198.1431 - val_mean_absolute_error: 42.6786\n",
      "Epoch 35/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7955.2485 - mean_absolute_error: 52.7670 - val_loss: 4102.9546 - val_mean_absolute_error: 41.8233\n",
      "Epoch 36/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6710.8315 - mean_absolute_error: 50.0185 - val_loss: 4022.7112 - val_mean_absolute_error: 41.4017\n",
      "Epoch 37/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6683.6860 - mean_absolute_error: 48.9222 - val_loss: 3954.5593 - val_mean_absolute_error: 41.0803\n",
      "Epoch 38/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6333.1772 - mean_absolute_error: 49.3932 - val_loss: 3854.7668 - val_mean_absolute_error: 40.1901\n",
      "Epoch 39/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7083.8013 - mean_absolute_error: 48.8786 - val_loss: 3806.3037 - val_mean_absolute_error: 40.0384\n",
      "Epoch 40/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6293.7905 - mean_absolute_error: 49.4440 - val_loss: 3743.7356 - val_mean_absolute_error: 39.5650\n",
      "Epoch 41/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6427.2720 - mean_absolute_error: 48.0846 - val_loss: 3678.5154 - val_mean_absolute_error: 39.1747\n",
      "Epoch 42/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6274.2456 - mean_absolute_error: 48.4019 - val_loss: 3611.7117 - val_mean_absolute_error: 38.7181\n",
      "Epoch 43/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6627.2080 - mean_absolute_error: 48.0165 - val_loss: 3560.8142 - val_mean_absolute_error: 38.5262\n",
      "Epoch 44/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5880.4316 - mean_absolute_error: 48.3063 - val_loss: 3520.7571 - val_mean_absolute_error: 38.3165\n",
      "Epoch 45/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6024.9121 - mean_absolute_error: 48.8986 - val_loss: 3491.5735 - val_mean_absolute_error: 38.2265\n",
      "Epoch 46/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5993.9897 - mean_absolute_error: 47.8141 - val_loss: 3411.2029 - val_mean_absolute_error: 37.3619\n",
      "Epoch 47/47\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6805.5591 - mean_absolute_error: 47.8338 - val_loss: 3375.9084 - val_mean_absolute_error: 37.2630\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:55:22,153] Trial 24 finished with value: 37.097756031006575 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 8, 'learning_rate': 0.0009958253409473945, 'dropout_rate': 0.043922769150381825, 'epoch': 47, 'batch_size': 85, 'optimizer': 'Adam'}. Best is trial 10 with value: 21.473532783144712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 67060.5391 - mean_absolute_error: 204.0793 - val_loss: 42056.4883 - val_mean_absolute_error: 152.6454\n",
      "Epoch 2/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33186.6523 - mean_absolute_error: 134.5777 - val_loss: 10899.5928 - val_mean_absolute_error: 83.3057\n",
      "Epoch 3/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21373.1543 - mean_absolute_error: 92.7957 - val_loss: 7486.2778 - val_mean_absolute_error: 66.4576\n",
      "Epoch 4/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12468.6914 - mean_absolute_error: 76.5314 - val_loss: 6960.8384 - val_mean_absolute_error: 63.2594\n",
      "Epoch 5/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13089.1484 - mean_absolute_error: 74.9741 - val_loss: 5738.9888 - val_mean_absolute_error: 55.4875\n",
      "Epoch 6/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12013.9248 - mean_absolute_error: 71.5394 - val_loss: 5532.9375 - val_mean_absolute_error: 54.3616\n",
      "Epoch 7/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15354.3008 - mean_absolute_error: 70.2277 - val_loss: 4971.7539 - val_mean_absolute_error: 50.5989\n",
      "Epoch 8/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10060.2725 - mean_absolute_error: 63.6415 - val_loss: 4727.3984 - val_mean_absolute_error: 49.0236\n",
      "Epoch 9/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11668.0371 - mean_absolute_error: 66.4188 - val_loss: 4607.3867 - val_mean_absolute_error: 48.1962\n",
      "Epoch 10/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9642.0000 - mean_absolute_error: 65.3918 - val_loss: 4386.3540 - val_mean_absolute_error: 46.8015\n",
      "Epoch 11/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10078.0098 - mean_absolute_error: 64.9250 - val_loss: 4255.6611 - val_mean_absolute_error: 45.9734\n",
      "Epoch 12/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9551.8975 - mean_absolute_error: 64.5751 - val_loss: 4389.5415 - val_mean_absolute_error: 47.0893\n",
      "Epoch 13/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15050.2188 - mean_absolute_error: 67.1324 - val_loss: 4014.4194 - val_mean_absolute_error: 44.1171\n",
      "Epoch 14/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9528.2686 - mean_absolute_error: 62.6690 - val_loss: 3888.3557 - val_mean_absolute_error: 43.2966\n",
      "Epoch 15/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10251.4932 - mean_absolute_error: 63.4197 - val_loss: 3815.2832 - val_mean_absolute_error: 42.9510\n",
      "Epoch 16/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9278.8125 - mean_absolute_error: 63.1958 - val_loss: 3651.7844 - val_mean_absolute_error: 41.7736\n",
      "Epoch 17/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9630.6416 - mean_absolute_error: 62.2534 - val_loss: 3895.0120 - val_mean_absolute_error: 43.8272\n",
      "Epoch 18/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11428.4736 - mean_absolute_error: 63.3705 - val_loss: 4137.4233 - val_mean_absolute_error: 45.4048\n",
      "Epoch 19/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9375.1777 - mean_absolute_error: 61.5267 - val_loss: 3691.9204 - val_mean_absolute_error: 42.1267\n",
      "Epoch 20/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8839.1924 - mean_absolute_error: 60.2140 - val_loss: 3514.8848 - val_mean_absolute_error: 40.7284\n",
      "Epoch 21/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10343.7344 - mean_absolute_error: 62.2078 - val_loss: 3447.1392 - val_mean_absolute_error: 40.2827\n",
      "Epoch 22/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8366.5371 - mean_absolute_error: 59.7039 - val_loss: 3525.3406 - val_mean_absolute_error: 41.0232\n",
      "Epoch 23/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9038.2764 - mean_absolute_error: 61.5657 - val_loss: 3251.1309 - val_mean_absolute_error: 38.5816\n",
      "Epoch 24/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8331.3262 - mean_absolute_error: 59.5307 - val_loss: 3382.1018 - val_mean_absolute_error: 39.9773\n",
      "Epoch 25/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9787.5254 - mean_absolute_error: 61.0851 - val_loss: 3295.5603 - val_mean_absolute_error: 39.3185\n",
      "Epoch 26/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8377.7559 - mean_absolute_error: 60.3640 - val_loss: 3838.7068 - val_mean_absolute_error: 43.2836\n",
      "Epoch 27/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8406.2207 - mean_absolute_error: 59.0682 - val_loss: 3220.0684 - val_mean_absolute_error: 38.5467\n",
      "Epoch 28/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7489.3096 - mean_absolute_error: 57.8428 - val_loss: 3291.9675 - val_mean_absolute_error: 39.2746\n",
      "Epoch 29/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9145.2637 - mean_absolute_error: 60.6739 - val_loss: 3321.4988 - val_mean_absolute_error: 39.6311\n",
      "Epoch 30/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9135.9111 - mean_absolute_error: 60.1164 - val_loss: 3357.3350 - val_mean_absolute_error: 39.8075\n",
      "Epoch 31/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8260.7910 - mean_absolute_error: 57.6175 - val_loss: 2997.4924 - val_mean_absolute_error: 36.7234\n",
      "Epoch 32/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9142.6143 - mean_absolute_error: 59.8510 - val_loss: 3110.9434 - val_mean_absolute_error: 37.8174\n",
      "Epoch 33/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10349.0967 - mean_absolute_error: 60.1541 - val_loss: 3163.5859 - val_mean_absolute_error: 38.2848\n",
      "Epoch 34/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10246.7314 - mean_absolute_error: 59.0267 - val_loss: 2932.2566 - val_mean_absolute_error: 36.2758\n",
      "Epoch 35/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9527.6094 - mean_absolute_error: 58.5198 - val_loss: 2904.4363 - val_mean_absolute_error: 36.0062\n",
      "Epoch 36/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9196.4814 - mean_absolute_error: 58.5915 - val_loss: 2995.8823 - val_mean_absolute_error: 36.9177\n",
      "Epoch 37/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7617.5874 - mean_absolute_error: 55.3409 - val_loss: 2849.0847 - val_mean_absolute_error: 35.4138\n",
      "Epoch 38/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7941.1934 - mean_absolute_error: 56.3318 - val_loss: 2803.0164 - val_mean_absolute_error: 34.9404\n",
      "Epoch 39/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9312.9482 - mean_absolute_error: 57.6115 - val_loss: 2905.8545 - val_mean_absolute_error: 35.9168\n",
      "Epoch 40/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7546.5435 - mean_absolute_error: 56.2648 - val_loss: 2905.9121 - val_mean_absolute_error: 35.9890\n",
      "Epoch 41/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8217.4102 - mean_absolute_error: 57.4940 - val_loss: 2805.8518 - val_mean_absolute_error: 35.1160\n",
      "Epoch 42/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7740.5020 - mean_absolute_error: 55.2497 - val_loss: 2814.3013 - val_mean_absolute_error: 35.2463\n",
      "Epoch 43/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8851.6768 - mean_absolute_error: 57.9192 - val_loss: 2692.2563 - val_mean_absolute_error: 34.0107\n",
      "Epoch 44/44\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7879.2793 - mean_absolute_error: 56.0389 - val_loss: 2885.2490 - val_mean_absolute_error: 35.8966\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:55:26,858] Trial 25 finished with value: 33.91816614255309 and parameters: {'layer_1': 7, 'layer_2': 6, 'layer_3': 7, 'learning_rate': 0.030392718788527003, 'dropout_rate': 0.12325587525065385, 'epoch': 44, 'batch_size': 73, 'optimizer': 'Adagrad'}. Best is trial 10 with value: 21.473532783144712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 78916.0312 - mean_absolute_error: 219.8967 - val_loss: 69865.6328 - val_mean_absolute_error: 214.4291\n",
      "Epoch 2/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69107.0078 - mean_absolute_error: 212.3261 - val_loss: 69862.1094 - val_mean_absolute_error: 214.4226\n",
      "Epoch 3/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74342.6328 - mean_absolute_error: 216.0206 - val_loss: 69858.8750 - val_mean_absolute_error: 214.4165\n",
      "Epoch 4/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70222.9922 - mean_absolute_error: 214.7447 - val_loss: 69855.4453 - val_mean_absolute_error: 214.4100\n",
      "Epoch 5/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70917.1719 - mean_absolute_error: 214.2819 - val_loss: 69852.1172 - val_mean_absolute_error: 214.4037\n",
      "Epoch 6/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75009.6250 - mean_absolute_error: 216.8175 - val_loss: 69848.7109 - val_mean_absolute_error: 214.3974\n",
      "Epoch 7/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68982.9766 - mean_absolute_error: 211.8037 - val_loss: 69845.1797 - val_mean_absolute_error: 214.3908\n",
      "Epoch 8/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76504.3516 - mean_absolute_error: 218.9551 - val_loss: 69841.7969 - val_mean_absolute_error: 214.3844\n",
      "Epoch 9/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70915.6406 - mean_absolute_error: 213.8735 - val_loss: 69838.3047 - val_mean_absolute_error: 214.3780\n",
      "Epoch 10/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72210.7109 - mean_absolute_error: 216.1580 - val_loss: 69834.8281 - val_mean_absolute_error: 214.3714\n",
      "Epoch 11/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72961.3750 - mean_absolute_error: 215.8721 - val_loss: 69831.2500 - val_mean_absolute_error: 214.3648\n",
      "Epoch 12/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67177.2031 - mean_absolute_error: 208.1772 - val_loss: 69827.7266 - val_mean_absolute_error: 214.3582\n",
      "Epoch 13/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70739.4062 - mean_absolute_error: 212.2328 - val_loss: 69824.2109 - val_mean_absolute_error: 214.3516\n",
      "Epoch 14/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70721.9141 - mean_absolute_error: 214.1059 - val_loss: 69820.7578 - val_mean_absolute_error: 214.3451\n",
      "Epoch 15/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70255.6094 - mean_absolute_error: 213.7774 - val_loss: 69817.1719 - val_mean_absolute_error: 214.3384\n",
      "Epoch 16/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73194.7188 - mean_absolute_error: 216.7681 - val_loss: 69813.5625 - val_mean_absolute_error: 214.3317\n",
      "Epoch 17/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76661.7812 - mean_absolute_error: 219.4836 - val_loss: 69809.9297 - val_mean_absolute_error: 214.3249\n",
      "Epoch 18/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70207.1562 - mean_absolute_error: 210.1240 - val_loss: 69806.3828 - val_mean_absolute_error: 214.3182\n",
      "Epoch 19/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71725.4922 - mean_absolute_error: 214.7399 - val_loss: 69802.7500 - val_mean_absolute_error: 214.3115\n",
      "Epoch 20/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68451.2734 - mean_absolute_error: 212.7132 - val_loss: 69799.0547 - val_mean_absolute_error: 214.3046\n",
      "Epoch 21/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67963.5938 - mean_absolute_error: 210.9926 - val_loss: 69795.3828 - val_mean_absolute_error: 214.2977\n",
      "Epoch 22/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73175.6094 - mean_absolute_error: 216.1962 - val_loss: 69791.8281 - val_mean_absolute_error: 214.2911\n",
      "Epoch 23/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71948.7109 - mean_absolute_error: 214.4945 - val_loss: 69788.1172 - val_mean_absolute_error: 214.2842\n",
      "Epoch 24/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71871.7266 - mean_absolute_error: 214.7138 - val_loss: 69784.4688 - val_mean_absolute_error: 214.2774\n",
      "Epoch 25/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73386.1484 - mean_absolute_error: 217.1661 - val_loss: 69780.7578 - val_mean_absolute_error: 214.2705\n",
      "Epoch 26/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77063.2344 - mean_absolute_error: 221.0592 - val_loss: 69777.0625 - val_mean_absolute_error: 214.2637\n",
      "Epoch 27/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74653.3047 - mean_absolute_error: 216.7265 - val_loss: 69773.3828 - val_mean_absolute_error: 214.2568\n",
      "Epoch 28/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72733.0781 - mean_absolute_error: 214.8339 - val_loss: 69769.5234 - val_mean_absolute_error: 214.2497\n",
      "Epoch 29/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72449.4844 - mean_absolute_error: 214.8401 - val_loss: 69765.7734 - val_mean_absolute_error: 214.2427\n",
      "Epoch 30/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72710.0469 - mean_absolute_error: 216.3692 - val_loss: 69761.9844 - val_mean_absolute_error: 214.2357\n",
      "Epoch 31/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72588.4922 - mean_absolute_error: 215.1895 - val_loss: 69758.1172 - val_mean_absolute_error: 214.2286\n",
      "Epoch 32/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71788.9453 - mean_absolute_error: 213.8950 - val_loss: 69754.2422 - val_mean_absolute_error: 214.2215\n",
      "Epoch 33/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70001.4062 - mean_absolute_error: 212.2030 - val_loss: 69750.2734 - val_mean_absolute_error: 214.2142\n",
      "Epoch 34/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71155.7031 - mean_absolute_error: 213.0073 - val_loss: 69746.4609 - val_mean_absolute_error: 214.2071\n",
      "Epoch 35/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74241.7031 - mean_absolute_error: 215.9321 - val_loss: 69742.6484 - val_mean_absolute_error: 214.2001\n",
      "Epoch 36/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73958.7109 - mean_absolute_error: 215.4821 - val_loss: 69738.7031 - val_mean_absolute_error: 214.1928\n",
      "Epoch 37/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73381.8984 - mean_absolute_error: 217.6714 - val_loss: 69734.6641 - val_mean_absolute_error: 214.1854\n",
      "Epoch 38/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70450.5391 - mean_absolute_error: 214.7448 - val_loss: 69730.7188 - val_mean_absolute_error: 214.1781\n",
      "Epoch 39/39\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70470.0156 - mean_absolute_error: 212.4021 - val_loss: 69726.7422 - val_mean_absolute_error: 214.1708\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:55:30,930] Trial 26 finished with value: 214.94444898941032 and parameters: {'layer_1': 8, 'layer_2': 7, 'layer_3': 6, 'learning_rate': 1.0814686918451428e-05, 'dropout_rate': 0.05846872762412413, 'epoch': 39, 'batch_size': 90, 'optimizer': 'RMSprop'}. Best is trial 10 with value: 21.473532783144712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71740.5391 - mean_absolute_error: 213.5926 - val_loss: 51688.8125 - val_mean_absolute_error: 188.9464\n",
      "Epoch 2/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 44102.7109 - mean_absolute_error: 174.5221 - val_loss: 17447.3789 - val_mean_absolute_error: 111.7543\n",
      "Epoch 3/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 17702.9648 - mean_absolute_error: 106.4367 - val_loss: 11971.1992 - val_mean_absolute_error: 89.6814\n",
      "Epoch 4/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12963.2539 - mean_absolute_error: 83.5278 - val_loss: 6977.0537 - val_mean_absolute_error: 57.8261\n",
      "Epoch 5/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7425.9238 - mean_absolute_error: 54.9671 - val_loss: 5170.4395 - val_mean_absolute_error: 46.1487\n",
      "Epoch 6/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5586.7129 - mean_absolute_error: 44.6531 - val_loss: 4266.8584 - val_mean_absolute_error: 42.7875\n",
      "Epoch 7/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6399.5479 - mean_absolute_error: 42.5510 - val_loss: 3723.4346 - val_mean_absolute_error: 38.5504\n",
      "Epoch 8/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4921.5000 - mean_absolute_error: 39.1701 - val_loss: 3334.7156 - val_mean_absolute_error: 37.2072\n",
      "Epoch 9/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6339.7876 - mean_absolute_error: 38.7049 - val_loss: 3039.5701 - val_mean_absolute_error: 35.3812\n",
      "Epoch 10/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3873.9915 - mean_absolute_error: 36.5633 - val_loss: 2754.5356 - val_mean_absolute_error: 33.3273\n",
      "Epoch 11/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4691.6387 - mean_absolute_error: 35.5337 - val_loss: 2663.6868 - val_mean_absolute_error: 32.7837\n",
      "Epoch 12/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4017.8572 - mean_absolute_error: 35.5871 - val_loss: 2483.2512 - val_mean_absolute_error: 31.0497\n",
      "Epoch 13/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3254.2273 - mean_absolute_error: 31.9450 - val_loss: 2281.7268 - val_mean_absolute_error: 29.6922\n",
      "Epoch 14/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 4120.7808 - mean_absolute_error: 32.3873 - val_loss: 2227.7031 - val_mean_absolute_error: 29.2134\n",
      "Epoch 15/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3826.0930 - mean_absolute_error: 31.1354 - val_loss: 2089.9258 - val_mean_absolute_error: 27.9660\n",
      "Epoch 16/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 4095.1501 - mean_absolute_error: 30.9914 - val_loss: 2075.6265 - val_mean_absolute_error: 27.7595\n",
      "Epoch 17/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2648.7898 - mean_absolute_error: 28.5282 - val_loss: 2118.7476 - val_mean_absolute_error: 28.2594\n",
      "Epoch 18/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 2862.5623 - mean_absolute_error: 28.9126 - val_loss: 1869.6837 - val_mean_absolute_error: 25.7512\n",
      "Epoch 19/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3486.4526 - mean_absolute_error: 28.3416 - val_loss: 1817.2892 - val_mean_absolute_error: 24.8320\n",
      "Epoch 20/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3469.0713 - mean_absolute_error: 28.9201 - val_loss: 1756.4058 - val_mean_absolute_error: 24.2153\n",
      "Epoch 21/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 3391.7175 - mean_absolute_error: 26.8886 - val_loss: 1704.4491 - val_mean_absolute_error: 23.2973\n",
      "Epoch 22/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3032.4033 - mean_absolute_error: 27.0238 - val_loss: 1735.3845 - val_mean_absolute_error: 23.5962\n",
      "Epoch 23/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 2407.9539 - mean_absolute_error: 24.7500 - val_loss: 1639.7581 - val_mean_absolute_error: 22.3156\n",
      "Epoch 24/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 3601.9973 - mean_absolute_error: 26.9034 - val_loss: 1797.3394 - val_mean_absolute_error: 23.8868\n",
      "Epoch 25/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2257.1655 - mean_absolute_error: 25.0362 - val_loss: 1672.0022 - val_mean_absolute_error: 22.2959\n",
      "Epoch 26/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2763.5562 - mean_absolute_error: 25.3144 - val_loss: 1610.4625 - val_mean_absolute_error: 21.5815\n",
      "Epoch 27/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2329.4543 - mean_absolute_error: 23.6591 - val_loss: 1622.3325 - val_mean_absolute_error: 21.2169\n",
      "Epoch 28/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2451.5679 - mean_absolute_error: 24.3585 - val_loss: 1608.6686 - val_mean_absolute_error: 21.3164\n",
      "Epoch 29/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2802.4424 - mean_absolute_error: 24.6671 - val_loss: 1633.5260 - val_mean_absolute_error: 21.8690\n",
      "Epoch 30/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2397.2205 - mean_absolute_error: 24.3654 - val_loss: 1770.4669 - val_mean_absolute_error: 22.7536\n",
      "Epoch 31/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 2847.7246 - mean_absolute_error: 24.9348 - val_loss: 1637.6960 - val_mean_absolute_error: 22.0605\n",
      "Epoch 32/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2620.5566 - mean_absolute_error: 24.4140 - val_loss: 1598.5520 - val_mean_absolute_error: 20.8909\n",
      "Epoch 33/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2321.7307 - mean_absolute_error: 24.4353 - val_loss: 1593.8242 - val_mean_absolute_error: 21.1471\n",
      "Epoch 34/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3204.4543 - mean_absolute_error: 25.0419 - val_loss: 1648.1918 - val_mean_absolute_error: 21.6712\n",
      "Epoch 35/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2317.0442 - mean_absolute_error: 24.4942 - val_loss: 1616.8193 - val_mean_absolute_error: 21.2845\n",
      "Epoch 36/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2410.3557 - mean_absolute_error: 23.8425 - val_loss: 1618.7949 - val_mean_absolute_error: 21.8192\n",
      "Epoch 37/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 2972.7043 - mean_absolute_error: 24.9298 - val_loss: 1756.6077 - val_mean_absolute_error: 23.0322\n",
      "Epoch 38/47\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - loss: 2477.1423 - mean_absolute_error: 24.4797 - val_loss: 1613.3730 - val_mean_absolute_error: 21.6925\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:55:35,576] Trial 27 finished with value: 21.49229580155872 and parameters: {'layer_1': 7, 'layer_2': 8, 'layer_3': 7, 'learning_rate': 0.004327359101156313, 'dropout_rate': 0.006431011920144669, 'epoch': 47, 'batch_size': 56, 'optimizer': 'RMSprop'}. Best is trial 10 with value: 21.473532783144712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69150.1719 - mean_absolute_error: 209.5973 - val_loss: 56144.4297 - val_mean_absolute_error: 194.1737\n",
      "Epoch 2/49\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 49886.3984 - mean_absolute_error: 182.1207 - val_loss: 23775.8301 - val_mean_absolute_error: 131.3103\n",
      "Epoch 3/49\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26288.5137 - mean_absolute_error: 125.5558 - val_loss: 14723.7344 - val_mean_absolute_error: 100.1404\n",
      "Epoch 4/49\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26900.3789 - mean_absolute_error: 106.7151 - val_loss: 10090.3008 - val_mean_absolute_error: 79.6279\n",
      "Epoch 5/49\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 16291.0283 - mean_absolute_error: 88.8300 - val_loss: 7220.6406 - val_mean_absolute_error: 65.1814\n",
      "Epoch 6/49\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12882.8496 - mean_absolute_error: 77.8916 - val_loss: 5522.7793 - val_mean_absolute_error: 53.9353\n",
      "Epoch 7/49\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 19478.6484 - mean_absolute_error: 73.5801 - val_loss: 5153.6807 - val_mean_absolute_error: 50.9070\n",
      "Epoch 8/49\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 21942.6953 - mean_absolute_error: 75.8049 - val_loss: 4916.9116 - val_mean_absolute_error: 48.4334\n",
      "Epoch 9/49\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 11333.9424 - mean_absolute_error: 68.0892 - val_loss: 5098.1523 - val_mean_absolute_error: 49.3987\n",
      "Epoch 10/49\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 10682.6348 - mean_absolute_error: 66.1124 - val_loss: 4582.6963 - val_mean_absolute_error: 45.8890\n",
      "Epoch 11/49\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 10538.6436 - mean_absolute_error: 62.5633 - val_loss: 4304.8608 - val_mean_absolute_error: 43.9762\n",
      "Epoch 12/49\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10431.0459 - mean_absolute_error: 62.6105 - val_loss: 4529.1660 - val_mean_absolute_error: 44.9743\n",
      "Epoch 13/49\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 9137.6377 - mean_absolute_error: 61.1996 - val_loss: 3879.3552 - val_mean_absolute_error: 40.5068\n",
      "Epoch 14/49\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8975.6992 - mean_absolute_error: 60.2800 - val_loss: 4309.3457 - val_mean_absolute_error: 44.2613\n",
      "Epoch 15/49\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9598.3447 - mean_absolute_error: 60.6063 - val_loss: 4146.0093 - val_mean_absolute_error: 42.6398\n",
      "Epoch 16/49\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11285.4570 - mean_absolute_error: 57.5927 - val_loss: 4231.8257 - val_mean_absolute_error: 43.0620\n",
      "Epoch 17/49\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 8927.1113 - mean_absolute_error: 58.1717 - val_loss: 3985.9915 - val_mean_absolute_error: 41.3761\n",
      "Epoch 18/49\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9076.1553 - mean_absolute_error: 57.4610 - val_loss: 3947.0603 - val_mean_absolute_error: 41.3424\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:55:38,349] Trial 28 finished with value: 40.949591964071985 and parameters: {'layer_1': 6, 'layer_2': 4, 'layer_3': 8, 'learning_rate': 0.0043111992591343936, 'dropout_rate': 0.11248517230981743, 'epoch': 49, 'batch_size': 52, 'optimizer': 'RMSprop'}. Best is trial 10 with value: 21.473532783144712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71420.6953 - mean_absolute_error: 213.5344 - val_loss: 69244.6875 - val_mean_absolute_error: 212.7974\n",
      "Epoch 2/23\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 71703.1328 - mean_absolute_error: 214.0693 - val_loss: 67839.6484 - val_mean_absolute_error: 209.1218\n",
      "Epoch 3/23\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 73310.3906 - mean_absolute_error: 210.8590 - val_loss: 65141.2422 - val_mean_absolute_error: 201.9385\n",
      "Epoch 4/23\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - loss: 65322.7500 - mean_absolute_error: 198.4398 - val_loss: 60268.1875 - val_mean_absolute_error: 188.8356\n",
      "Epoch 5/23\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 58957.6523 - mean_absolute_error: 186.2888 - val_loss: 52832.8086 - val_mean_absolute_error: 170.8637\n",
      "Epoch 6/23\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - loss: 54983.1719 - mean_absolute_error: 172.1660 - val_loss: 42725.8906 - val_mean_absolute_error: 152.2259\n",
      "Epoch 7/23\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - loss: 42618.4258 - mean_absolute_error: 150.0490 - val_loss: 30267.2812 - val_mean_absolute_error: 129.7944\n",
      "Epoch 8/23\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 29864.9688 - mean_absolute_error: 127.8397 - val_loss: 18101.1465 - val_mean_absolute_error: 102.4863\n",
      "Epoch 9/23\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - loss: 18938.3418 - mean_absolute_error: 100.3951 - val_loss: 10292.5957 - val_mean_absolute_error: 77.4265\n",
      "Epoch 10/23\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 17198.4316 - mean_absolute_error: 85.8891 - val_loss: 7098.5039 - val_mean_absolute_error: 62.3149\n",
      "Epoch 11/23\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - loss: 15211.4551 - mean_absolute_error: 74.6531 - val_loss: 5997.9038 - val_mean_absolute_error: 54.5943\n",
      "Epoch 12/23\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - loss: 11422.1035 - mean_absolute_error: 68.2406 - val_loss: 5397.0566 - val_mean_absolute_error: 50.1088\n",
      "Epoch 13/23\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 11929.1680 - mean_absolute_error: 64.2376 - val_loss: 4978.3052 - val_mean_absolute_error: 46.6311\n",
      "Epoch 14/23\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - loss: 11457.3604 - mean_absolute_error: 60.2579 - val_loss: 4673.7451 - val_mean_absolute_error: 44.3972\n",
      "Epoch 15/23\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - loss: 12725.0117 - mean_absolute_error: 60.0454 - val_loss: 4465.5620 - val_mean_absolute_error: 42.7888\n",
      "Epoch 16/23\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - loss: 14042.5176 - mean_absolute_error: 59.1288 - val_loss: 4454.8237 - val_mean_absolute_error: 42.6375\n",
      "Epoch 17/23\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 18972.8164 - mean_absolute_error: 61.6708 - val_loss: 4166.6465 - val_mean_absolute_error: 40.0873\n",
      "Epoch 18/23\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 12014.7451 - mean_absolute_error: 57.8055 - val_loss: 4021.0068 - val_mean_absolute_error: 39.1611\n",
      "Epoch 19/23\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - loss: 11656.3799 - mean_absolute_error: 57.4030 - val_loss: 3874.0046 - val_mean_absolute_error: 38.0100\n",
      "Epoch 20/23\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - loss: 10175.1777 - mean_absolute_error: 55.4542 - val_loss: 3835.8562 - val_mean_absolute_error: 38.0290\n",
      "Epoch 21/23\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - loss: 7674.2295 - mean_absolute_error: 53.8975 - val_loss: 3785.5120 - val_mean_absolute_error: 37.8047\n",
      "Epoch 22/23\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 8852.6670 - mean_absolute_error: 53.5624 - val_loss: 3634.6086 - val_mean_absolute_error: 36.7165\n",
      "Epoch 23/23\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - loss: 9964.1875 - mean_absolute_error: 53.5416 - val_loss: 3418.8103 - val_mean_absolute_error: 35.1446\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:55:42,239] Trial 29 finished with value: 35.53535974925161 and parameters: {'layer_1': 7, 'layer_2': 4, 'layer_3': 8, 'learning_rate': 0.0009962275935083075, 'dropout_rate': 0.0678087626688432, 'epoch': 23, 'batch_size': 34, 'optimizer': 'RMSprop'}. Best is trial 10 with value: 21.473532783144712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 74085.1875 - mean_absolute_error: 216.8123 - val_loss: 69911.2188 - val_mean_absolute_error: 214.4522\n",
      "Epoch 2/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 72738.8281 - mean_absolute_error: 217.5547 - val_loss: 69836.0078 - val_mean_absolute_error: 214.2968\n",
      "Epoch 3/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 74691.4922 - mean_absolute_error: 217.5235 - val_loss: 69758.7578 - val_mean_absolute_error: 214.1414\n",
      "Epoch 4/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 69192.6172 - mean_absolute_error: 210.5196 - val_loss: 69675.7031 - val_mean_absolute_error: 213.9784\n",
      "Epoch 5/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 69782.7578 - mean_absolute_error: 212.0375 - val_loss: 69586.6484 - val_mean_absolute_error: 213.8064\n",
      "Epoch 6/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 72949.4531 - mean_absolute_error: 214.9292 - val_loss: 69493.7422 - val_mean_absolute_error: 213.6288\n",
      "Epoch 7/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 72243.8672 - mean_absolute_error: 213.8028 - val_loss: 69388.3906 - val_mean_absolute_error: 213.4335\n",
      "Epoch 8/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 71616.2188 - mean_absolute_error: 213.3988 - val_loss: 69277.8438 - val_mean_absolute_error: 213.2316\n",
      "Epoch 9/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 68410.3438 - mean_absolute_error: 210.6541 - val_loss: 69159.1016 - val_mean_absolute_error: 213.0174\n",
      "Epoch 10/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - loss: 74048.1641 - mean_absolute_error: 215.2594 - val_loss: 69039.0078 - val_mean_absolute_error: 212.8004\n",
      "Epoch 11/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 69297.8750 - mean_absolute_error: 208.8712 - val_loss: 68909.5000 - val_mean_absolute_error: 212.5710\n",
      "Epoch 12/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 67897.7344 - mean_absolute_error: 211.2123 - val_loss: 68772.1250 - val_mean_absolute_error: 212.3295\n",
      "Epoch 13/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 74071.1250 - mean_absolute_error: 215.6525 - val_loss: 68617.4219 - val_mean_absolute_error: 212.0631\n",
      "Epoch 14/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 72378.5703 - mean_absolute_error: 213.1270 - val_loss: 68454.9453 - val_mean_absolute_error: 211.7839\n",
      "Epoch 15/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 68722.8281 - mean_absolute_error: 211.5160 - val_loss: 68277.6484 - val_mean_absolute_error: 211.4818\n",
      "Epoch 16/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 72054.1406 - mean_absolute_error: 215.7270 - val_loss: 68089.2109 - val_mean_absolute_error: 211.1614\n",
      "Epoch 17/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 69952.6875 - mean_absolute_error: 210.7645 - val_loss: 67897.0703 - val_mean_absolute_error: 210.8335\n",
      "Epoch 18/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 68353.3750 - mean_absolute_error: 208.9941 - val_loss: 67689.4922 - val_mean_absolute_error: 210.4823\n",
      "Epoch 19/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 71349.7734 - mean_absolute_error: 212.4351 - val_loss: 67471.8984 - val_mean_absolute_error: 210.1135\n",
      "Epoch 20/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 68496.1328 - mean_absolute_error: 209.4597 - val_loss: 67251.6016 - val_mean_absolute_error: 209.7381\n",
      "Epoch 21/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 75309.3438 - mean_absolute_error: 215.4514 - val_loss: 67013.6953 - val_mean_absolute_error: 209.3341\n",
      "Epoch 22/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 69402.7188 - mean_absolute_error: 212.4590 - val_loss: 66772.3438 - val_mean_absolute_error: 208.9200\n",
      "Epoch 23/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 69166.1250 - mean_absolute_error: 210.2148 - val_loss: 66517.9062 - val_mean_absolute_error: 208.4840\n",
      "Epoch 24/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 69096.1797 - mean_absolute_error: 208.2657 - val_loss: 66251.9844 - val_mean_absolute_error: 208.0241\n",
      "Epoch 25/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 70548.8281 - mean_absolute_error: 211.2893 - val_loss: 65962.9922 - val_mean_absolute_error: 207.5226\n",
      "Epoch 26/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 69681.6172 - mean_absolute_error: 210.6945 - val_loss: 65670.7812 - val_mean_absolute_error: 207.0087\n",
      "Epoch 27/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 69487.5312 - mean_absolute_error: 209.9323 - val_loss: 65371.1953 - val_mean_absolute_error: 206.4776\n",
      "Epoch 28/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 67195.4375 - mean_absolute_error: 207.8304 - val_loss: 65059.4961 - val_mean_absolute_error: 205.9241\n",
      "Epoch 29/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - loss: 65446.2695 - mean_absolute_error: 202.9896 - val_loss: 64729.2656 - val_mean_absolute_error: 205.3419\n",
      "Epoch 30/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 68689.6875 - mean_absolute_error: 207.8066 - val_loss: 64393.4570 - val_mean_absolute_error: 204.7460\n",
      "Epoch 31/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 68547.2734 - mean_absolute_error: 207.3303 - val_loss: 64058.9492 - val_mean_absolute_error: 204.1449\n",
      "Epoch 32/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 65175.8047 - mean_absolute_error: 205.0722 - val_loss: 63686.5898 - val_mean_absolute_error: 203.4849\n",
      "Epoch 33/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 62377.0547 - mean_absolute_error: 198.5186 - val_loss: 63330.7188 - val_mean_absolute_error: 202.8494\n",
      "Epoch 34/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 67177.2891 - mean_absolute_error: 206.6257 - val_loss: 62961.7969 - val_mean_absolute_error: 202.1900\n",
      "Epoch 35/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - loss: 63958.1953 - mean_absolute_error: 202.4036 - val_loss: 62585.8711 - val_mean_absolute_error: 201.5212\n",
      "Epoch 36/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 63520.5156 - mean_absolute_error: 199.8308 - val_loss: 62194.7422 - val_mean_absolute_error: 200.8246\n",
      "Epoch 37/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 63784.8516 - mean_absolute_error: 200.3331 - val_loss: 61804.6641 - val_mean_absolute_error: 200.1245\n",
      "Epoch 38/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 66379.6562 - mean_absolute_error: 202.1991 - val_loss: 61405.3750 - val_mean_absolute_error: 199.4007\n",
      "Epoch 39/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - loss: 65204.5938 - mean_absolute_error: 201.1865 - val_loss: 60989.1641 - val_mean_absolute_error: 198.6455\n",
      "Epoch 40/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 63061.6445 - mean_absolute_error: 199.7048 - val_loss: 60557.0742 - val_mean_absolute_error: 197.8574\n",
      "Epoch 41/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 62423.3398 - mean_absolute_error: 198.3718 - val_loss: 60114.4609 - val_mean_absolute_error: 197.0392\n",
      "Epoch 42/42\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 63111.9297 - mean_absolute_error: 198.4891 - val_loss: 59680.8242 - val_mean_absolute_error: 196.2285\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:55:50,006] Trial 30 finished with value: 197.05820340639428 and parameters: {'layer_1': 7, 'layer_2': 3, 'layer_3': 7, 'learning_rate': 0.002265245745064593, 'dropout_rate': 0.15371600422573337, 'epoch': 42, 'batch_size': 23, 'optimizer': 'Adagrad'}. Best is trial 10 with value: 21.473532783144712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 63325.6406 - mean_absolute_error: 189.6687 - val_loss: 9950.4951 - val_mean_absolute_error: 76.9990\n",
      "Epoch 2/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 17656.2559 - mean_absolute_error: 76.8984 - val_loss: 4797.6489 - val_mean_absolute_error: 48.5460\n",
      "Epoch 3/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7294.7568 - mean_absolute_error: 49.1099 - val_loss: 3415.5596 - val_mean_absolute_error: 39.4262\n",
      "Epoch 4/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6949.2080 - mean_absolute_error: 42.2113 - val_loss: 2984.5288 - val_mean_absolute_error: 33.6430\n",
      "Epoch 5/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5560.3037 - mean_absolute_error: 38.5820 - val_loss: 2351.7629 - val_mean_absolute_error: 30.5094\n",
      "Epoch 6/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5428.8115 - mean_absolute_error: 35.2858 - val_loss: 2230.1890 - val_mean_absolute_error: 29.4874\n",
      "Epoch 7/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5109.5884 - mean_absolute_error: 34.2300 - val_loss: 2078.6714 - val_mean_absolute_error: 26.2301\n",
      "Epoch 8/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5407.5278 - mean_absolute_error: 31.9441 - val_loss: 2377.4021 - val_mean_absolute_error: 29.9352\n",
      "Epoch 9/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3717.9114 - mean_absolute_error: 29.3376 - val_loss: 2152.4141 - val_mean_absolute_error: 27.2400\n",
      "Epoch 10/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3473.5156 - mean_absolute_error: 28.4820 - val_loss: 2849.2485 - val_mean_absolute_error: 33.6912\n",
      "Epoch 11/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2795.5144 - mean_absolute_error: 27.9458 - val_loss: 1632.9717 - val_mean_absolute_error: 22.1833\n",
      "Epoch 12/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2709.1865 - mean_absolute_error: 26.6099 - val_loss: 1657.0320 - val_mean_absolute_error: 22.4898\n",
      "Epoch 13/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3021.9880 - mean_absolute_error: 27.4897 - val_loss: 1595.6897 - val_mean_absolute_error: 22.4323\n",
      "Epoch 14/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4258.4619 - mean_absolute_error: 28.5672 - val_loss: 1635.3253 - val_mean_absolute_error: 21.7650\n",
      "Epoch 15/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2170.5178 - mean_absolute_error: 25.2043 - val_loss: 1895.1318 - val_mean_absolute_error: 24.3725\n",
      "Epoch 16/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3686.0437 - mean_absolute_error: 28.1789 - val_loss: 1577.5175 - val_mean_absolute_error: 21.2069\n",
      "Epoch 17/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2996.4219 - mean_absolute_error: 28.6588 - val_loss: 1592.6754 - val_mean_absolute_error: 21.9288\n",
      "Epoch 18/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3399.9695 - mean_absolute_error: 28.0848 - val_loss: 1669.1869 - val_mean_absolute_error: 22.1932\n",
      "Epoch 19/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2874.0342 - mean_absolute_error: 26.7526 - val_loss: 1573.2998 - val_mean_absolute_error: 21.7281\n",
      "Epoch 20/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3327.0830 - mean_absolute_error: 27.4506 - val_loss: 1604.6621 - val_mean_absolute_error: 21.9549\n",
      "Epoch 21/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3320.5674 - mean_absolute_error: 28.6502 - val_loss: 1557.9323 - val_mean_absolute_error: 20.7712\n",
      "Epoch 22/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2952.2632 - mean_absolute_error: 26.9725 - val_loss: 1688.5984 - val_mean_absolute_error: 22.5629\n",
      "Epoch 23/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2528.8877 - mean_absolute_error: 25.9041 - val_loss: 1594.9023 - val_mean_absolute_error: 21.4036\n",
      "Epoch 24/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2585.4402 - mean_absolute_error: 26.8225 - val_loss: 1872.7401 - val_mean_absolute_error: 24.4986\n",
      "Epoch 25/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2290.3442 - mean_absolute_error: 26.0112 - val_loss: 1767.7438 - val_mean_absolute_error: 23.9571\n",
      "Epoch 26/44\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2177.5696 - mean_absolute_error: 26.5236 - val_loss: 1665.7728 - val_mean_absolute_error: 22.1383\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:55:53,041] Trial 31 finished with value: 21.334652156585456 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 7, 'learning_rate': 0.013560165733160871, 'dropout_rate': 0.01130595861096613, 'epoch': 44, 'batch_size': 96, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 52462.0391 - mean_absolute_error: 175.7762 - val_loss: 9616.9268 - val_mean_absolute_error: 72.9897\n",
      "Epoch 2/46\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14350.8506 - mean_absolute_error: 66.7469 - val_loss: 4825.8447 - val_mean_absolute_error: 46.0590\n",
      "Epoch 3/46\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9771.5859 - mean_absolute_error: 50.2700 - val_loss: 3394.0681 - val_mean_absolute_error: 40.1711\n",
      "Epoch 4/46\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5406.9971 - mean_absolute_error: 42.6621 - val_loss: 2514.7126 - val_mean_absolute_error: 31.2620\n",
      "Epoch 5/46\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5300.7588 - mean_absolute_error: 37.5968 - val_loss: 2025.6782 - val_mean_absolute_error: 26.1747\n",
      "Epoch 6/46\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6792.0581 - mean_absolute_error: 38.5950 - val_loss: 1861.5115 - val_mean_absolute_error: 24.0408\n",
      "Epoch 7/46\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3486.1721 - mean_absolute_error: 33.0376 - val_loss: 1747.9066 - val_mean_absolute_error: 23.9001\n",
      "Epoch 8/46\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3817.1389 - mean_absolute_error: 33.8154 - val_loss: 1708.5518 - val_mean_absolute_error: 22.6281\n",
      "Epoch 9/46\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4822.4224 - mean_absolute_error: 34.7357 - val_loss: 1756.0009 - val_mean_absolute_error: 23.5181\n",
      "Epoch 10/46\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3672.9497 - mean_absolute_error: 32.3937 - val_loss: 2139.0376 - val_mean_absolute_error: 28.2581\n",
      "Epoch 11/46\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3113.5134 - mean_absolute_error: 31.5850 - val_loss: 2078.3147 - val_mean_absolute_error: 26.9387\n",
      "Epoch 12/46\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2854.6284 - mean_absolute_error: 31.8747 - val_loss: 1644.6439 - val_mean_absolute_error: 22.0055\n",
      "Epoch 13/46\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3829.3757 - mean_absolute_error: 33.3195 - val_loss: 1854.4480 - val_mean_absolute_error: 24.4775\n",
      "Epoch 14/46\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3441.4641 - mean_absolute_error: 31.3916 - val_loss: 2835.4297 - val_mean_absolute_error: 32.7726\n",
      "Epoch 15/46\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3127.6174 - mean_absolute_error: 32.4133 - val_loss: 1629.9100 - val_mean_absolute_error: 21.6832\n",
      "Epoch 16/46\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4774.6641 - mean_absolute_error: 33.5760 - val_loss: 2034.6508 - val_mean_absolute_error: 26.5024\n",
      "Epoch 17/46\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4928.0820 - mean_absolute_error: 34.4836 - val_loss: 1597.5364 - val_mean_absolute_error: 21.6548\n",
      "Epoch 18/46\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3323.2490 - mean_absolute_error: 31.6324 - val_loss: 1610.8885 - val_mean_absolute_error: 21.4910\n",
      "Epoch 19/46\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3967.1001 - mean_absolute_error: 33.2052 - val_loss: 2104.5923 - val_mean_absolute_error: 27.2967\n",
      "Epoch 20/46\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3392.2449 - mean_absolute_error: 32.5875 - val_loss: 1603.0614 - val_mean_absolute_error: 21.4796\n",
      "Epoch 21/46\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3396.0271 - mean_absolute_error: 31.6518 - val_loss: 1601.0376 - val_mean_absolute_error: 21.6440\n",
      "Epoch 22/46\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4725.7168 - mean_absolute_error: 33.8199 - val_loss: 2934.1685 - val_mean_absolute_error: 33.3029\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:55:55,895] Trial 32 finished with value: 22.55942159779668 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 7, 'learning_rate': 0.011856022872926824, 'dropout_rate': 0.028762279387628827, 'epoch': 46, 'batch_size': 78, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 71848.7266 - mean_absolute_error: 217.1188 - val_loss: 70001.1875 - val_mean_absolute_error: 214.6502\n",
      "Epoch 2/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74793.5078 - mean_absolute_error: 216.9221 - val_loss: 70001.0703 - val_mean_absolute_error: 214.6501\n",
      "Epoch 3/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69836.9219 - mean_absolute_error: 212.8271 - val_loss: 70000.9297 - val_mean_absolute_error: 214.6499\n",
      "Epoch 4/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75372.8906 - mean_absolute_error: 219.0390 - val_loss: 70000.7656 - val_mean_absolute_error: 214.6497\n",
      "Epoch 5/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71851.5625 - mean_absolute_error: 212.8281 - val_loss: 70000.5938 - val_mean_absolute_error: 214.6495\n",
      "Epoch 6/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74176.6406 - mean_absolute_error: 219.2714 - val_loss: 70000.4062 - val_mean_absolute_error: 214.6493\n",
      "Epoch 7/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75820.3594 - mean_absolute_error: 218.7044 - val_loss: 70000.1719 - val_mean_absolute_error: 214.6490\n",
      "Epoch 8/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74878.5859 - mean_absolute_error: 215.7610 - val_loss: 69999.9219 - val_mean_absolute_error: 214.6487\n",
      "Epoch 9/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72939.5234 - mean_absolute_error: 216.4504 - val_loss: 69999.6641 - val_mean_absolute_error: 214.6484\n",
      "Epoch 10/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74354.0625 - mean_absolute_error: 218.0154 - val_loss: 69999.3672 - val_mean_absolute_error: 214.6480\n",
      "Epoch 11/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70754.5469 - mean_absolute_error: 213.1106 - val_loss: 69999.0469 - val_mean_absolute_error: 214.6476\n",
      "Epoch 12/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73788.5391 - mean_absolute_error: 217.1438 - val_loss: 69998.6953 - val_mean_absolute_error: 214.6471\n",
      "Epoch 13/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73228.8438 - mean_absolute_error: 216.3340 - val_loss: 69998.2969 - val_mean_absolute_error: 214.6466\n",
      "Epoch 14/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73338.6328 - mean_absolute_error: 216.9482 - val_loss: 69997.8828 - val_mean_absolute_error: 214.6461\n",
      "Epoch 15/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69732.1484 - mean_absolute_error: 211.9261 - val_loss: 69997.4531 - val_mean_absolute_error: 214.6456\n",
      "Epoch 16/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73510.6406 - mean_absolute_error: 216.8428 - val_loss: 69997.0234 - val_mean_absolute_error: 214.6451\n",
      "Epoch 17/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70282.9531 - mean_absolute_error: 214.2829 - val_loss: 69996.5469 - val_mean_absolute_error: 214.6445\n",
      "Epoch 18/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72070.6641 - mean_absolute_error: 215.6694 - val_loss: 69996.0469 - val_mean_absolute_error: 214.6438\n",
      "Epoch 19/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71193.3750 - mean_absolute_error: 215.4714 - val_loss: 69995.5078 - val_mean_absolute_error: 214.6432\n",
      "Epoch 20/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70599.9453 - mean_absolute_error: 215.4575 - val_loss: 69994.9297 - val_mean_absolute_error: 214.6424\n",
      "Epoch 21/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67861.5781 - mean_absolute_error: 211.1441 - val_loss: 69994.2500 - val_mean_absolute_error: 214.6416\n",
      "Epoch 22/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73028.1094 - mean_absolute_error: 216.1735 - val_loss: 69993.6250 - val_mean_absolute_error: 214.6408\n",
      "Epoch 23/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69762.8594 - mean_absolute_error: 214.1716 - val_loss: 69992.9375 - val_mean_absolute_error: 214.6400\n",
      "Epoch 24/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71881.9219 - mean_absolute_error: 213.5148 - val_loss: 69992.1953 - val_mean_absolute_error: 214.6391\n",
      "Epoch 25/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71969.0234 - mean_absolute_error: 216.6570 - val_loss: 69991.3750 - val_mean_absolute_error: 214.6380\n",
      "Epoch 26/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71263.0859 - mean_absolute_error: 213.8419 - val_loss: 69990.5312 - val_mean_absolute_error: 214.6369\n",
      "Epoch 27/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72859.6562 - mean_absolute_error: 215.8143 - val_loss: 69989.6250 - val_mean_absolute_error: 214.6358\n",
      "Epoch 28/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70835.9375 - mean_absolute_error: 214.3216 - val_loss: 69988.6094 - val_mean_absolute_error: 214.6346\n",
      "Epoch 29/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72567.9844 - mean_absolute_error: 217.8632 - val_loss: 69987.5547 - val_mean_absolute_error: 214.6333\n",
      "Epoch 30/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70308.3047 - mean_absolute_error: 211.3554 - val_loss: 69986.4297 - val_mean_absolute_error: 214.6319\n",
      "Epoch 31/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74058.6562 - mean_absolute_error: 216.7033 - val_loss: 69985.2109 - val_mean_absolute_error: 214.6303\n",
      "Epoch 32/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71203.3359 - mean_absolute_error: 214.7139 - val_loss: 69983.9375 - val_mean_absolute_error: 214.6287\n",
      "Epoch 33/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72360.8906 - mean_absolute_error: 212.7451 - val_loss: 69982.6250 - val_mean_absolute_error: 214.6271\n",
      "Epoch 34/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73363.9766 - mean_absolute_error: 217.3705 - val_loss: 69981.2109 - val_mean_absolute_error: 214.6252\n",
      "Epoch 35/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74964.0547 - mean_absolute_error: 216.1879 - val_loss: 69979.7891 - val_mean_absolute_error: 214.6234\n",
      "Epoch 36/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70798.0547 - mean_absolute_error: 213.0463 - val_loss: 69978.3750 - val_mean_absolute_error: 214.6216\n",
      "Epoch 37/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73660.0938 - mean_absolute_error: 217.6236 - val_loss: 69976.9453 - val_mean_absolute_error: 214.6198\n",
      "Epoch 38/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70985.0156 - mean_absolute_error: 213.6470 - val_loss: 69975.5547 - val_mean_absolute_error: 214.6179\n",
      "Epoch 39/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73345.7734 - mean_absolute_error: 216.5464 - val_loss: 69974.0703 - val_mean_absolute_error: 214.6160\n",
      "Epoch 40/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75446.4219 - mean_absolute_error: 217.5026 - val_loss: 69972.5312 - val_mean_absolute_error: 214.6140\n",
      "Epoch 41/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73808.9375 - mean_absolute_error: 217.5639 - val_loss: 69970.9375 - val_mean_absolute_error: 214.6118\n",
      "Epoch 42/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71313.8984 - mean_absolute_error: 214.8089 - val_loss: 69969.2500 - val_mean_absolute_error: 214.6096\n",
      "Epoch 43/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71793.8125 - mean_absolute_error: 216.0241 - val_loss: 69967.5312 - val_mean_absolute_error: 214.6073\n",
      "Epoch 44/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71348.4453 - mean_absolute_error: 214.6608 - val_loss: 69965.6875 - val_mean_absolute_error: 214.6048\n",
      "Epoch 45/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70276.1250 - mean_absolute_error: 214.7476 - val_loss: 69963.8047 - val_mean_absolute_error: 214.6023\n",
      "Epoch 46/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69508.4688 - mean_absolute_error: 212.6331 - val_loss: 69961.9062 - val_mean_absolute_error: 214.5997\n",
      "Epoch 47/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73840.7891 - mean_absolute_error: 215.2187 - val_loss: 69959.8984 - val_mean_absolute_error: 214.5969\n",
      "Epoch 48/48\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68578.6875 - mean_absolute_error: 211.4527 - val_loss: 69957.8203 - val_mean_absolute_error: 214.5940\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:56:01,629] Trial 33 finished with value: 215.37047692618867 and parameters: {'layer_1': 8, 'layer_2': 7, 'layer_3': 8, 'learning_rate': 0.00631680697948625, 'dropout_rate': 0.0010297070084318884, 'epoch': 48, 'batch_size': 67, 'optimizer': 'Adadelta'}. Best is trial 31 with value: 21.334652156585456.\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66741.6484 - mean_absolute_error: 209.2543 - val_loss: 53814.8867 - val_mean_absolute_error: 184.5125\n",
      "Epoch 2/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 40455.4766 - mean_absolute_error: 153.2097 - val_loss: 11568.0166 - val_mean_absolute_error: 84.4913\n",
      "Epoch 3/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15021.5508 - mean_absolute_error: 85.1220 - val_loss: 7389.9575 - val_mean_absolute_error: 62.6444\n",
      "Epoch 4/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11606.5918 - mean_absolute_error: 67.4399 - val_loss: 5256.4453 - val_mean_absolute_error: 49.6949\n",
      "Epoch 5/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8576.3857 - mean_absolute_error: 54.5062 - val_loss: 4254.1294 - val_mean_absolute_error: 43.8149\n",
      "Epoch 6/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6952.6177 - mean_absolute_error: 50.4051 - val_loss: 3504.7305 - val_mean_absolute_error: 37.0558\n",
      "Epoch 7/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5307.6509 - mean_absolute_error: 45.7706 - val_loss: 3262.6025 - val_mean_absolute_error: 37.5004\n",
      "Epoch 8/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5351.0698 - mean_absolute_error: 44.5395 - val_loss: 2822.5605 - val_mean_absolute_error: 32.2434\n",
      "Epoch 9/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5701.7095 - mean_absolute_error: 43.9368 - val_loss: 2714.6724 - val_mean_absolute_error: 33.1859\n",
      "Epoch 10/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4699.5508 - mean_absolute_error: 42.8197 - val_loss: 2581.3948 - val_mean_absolute_error: 31.9002\n",
      "Epoch 11/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4258.5444 - mean_absolute_error: 41.4180 - val_loss: 2306.7708 - val_mean_absolute_error: 28.8050\n",
      "Epoch 12/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4624.6904 - mean_absolute_error: 40.8810 - val_loss: 2196.1309 - val_mean_absolute_error: 27.3561\n",
      "Epoch 13/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4899.7681 - mean_absolute_error: 40.7353 - val_loss: 2177.7417 - val_mean_absolute_error: 27.9225\n",
      "Epoch 14/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5052.0112 - mean_absolute_error: 39.3920 - val_loss: 2100.7537 - val_mean_absolute_error: 27.3537\n",
      "Epoch 15/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5344.1309 - mean_absolute_error: 39.5095 - val_loss: 2097.8162 - val_mean_absolute_error: 27.1623\n",
      "Epoch 16/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4451.6836 - mean_absolute_error: 39.1027 - val_loss: 2001.3024 - val_mean_absolute_error: 26.3665\n",
      "Epoch 17/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4130.1870 - mean_absolute_error: 38.6396 - val_loss: 1837.7130 - val_mean_absolute_error: 24.5296\n",
      "Epoch 18/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3973.5024 - mean_absolute_error: 36.9666 - val_loss: 1789.5430 - val_mean_absolute_error: 23.8386\n",
      "Epoch 19/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3563.7510 - mean_absolute_error: 36.6565 - val_loss: 1959.3171 - val_mean_absolute_error: 26.1778\n",
      "Epoch 20/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3830.5120 - mean_absolute_error: 37.0406 - val_loss: 1755.3394 - val_mean_absolute_error: 23.7287\n",
      "Epoch 21/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3768.2378 - mean_absolute_error: 37.0956 - val_loss: 1773.0847 - val_mean_absolute_error: 23.9895\n",
      "Epoch 22/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4600.6880 - mean_absolute_error: 38.5705 - val_loss: 1755.0814 - val_mean_absolute_error: 23.7442\n",
      "Epoch 23/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3664.8223 - mean_absolute_error: 36.8996 - val_loss: 1674.7159 - val_mean_absolute_error: 22.6841\n",
      "Epoch 24/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5153.5073 - mean_absolute_error: 38.4752 - val_loss: 1655.9429 - val_mean_absolute_error: 22.8475\n",
      "Epoch 25/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3874.9399 - mean_absolute_error: 36.3037 - val_loss: 1646.8341 - val_mean_absolute_error: 22.6841\n",
      "Epoch 26/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3822.8455 - mean_absolute_error: 36.0327 - val_loss: 1864.9036 - val_mean_absolute_error: 24.9187\n",
      "Epoch 27/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4126.5425 - mean_absolute_error: 36.9235 - val_loss: 1671.5282 - val_mean_absolute_error: 23.0955\n",
      "Epoch 28/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5278.2793 - mean_absolute_error: 38.8271 - val_loss: 1801.0997 - val_mean_absolute_error: 24.3290\n",
      "Epoch 29/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3686.6169 - mean_absolute_error: 37.0065 - val_loss: 1627.7460 - val_mean_absolute_error: 22.6171\n",
      "Epoch 30/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4331.5278 - mean_absolute_error: 36.6038 - val_loss: 1768.7681 - val_mean_absolute_error: 24.0384\n",
      "Epoch 31/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4587.3828 - mean_absolute_error: 36.2938 - val_loss: 1628.4779 - val_mean_absolute_error: 22.4066\n",
      "Epoch 32/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4125.5063 - mean_absolute_error: 36.9982 - val_loss: 1637.8341 - val_mean_absolute_error: 22.6463\n",
      "Epoch 33/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5137.2729 - mean_absolute_error: 37.2701 - val_loss: 1756.3486 - val_mean_absolute_error: 23.8931\n",
      "Epoch 34/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5124.3823 - mean_absolute_error: 38.4137 - val_loss: 1606.1208 - val_mean_absolute_error: 22.2949\n",
      "Epoch 35/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3848.8564 - mean_absolute_error: 37.3422 - val_loss: 1625.0773 - val_mean_absolute_error: 22.4106\n",
      "Epoch 36/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4245.0757 - mean_absolute_error: 37.1377 - val_loss: 1718.8130 - val_mean_absolute_error: 23.6209\n",
      "Epoch 37/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3692.3477 - mean_absolute_error: 36.9523 - val_loss: 1841.5924 - val_mean_absolute_error: 24.8068\n",
      "Epoch 38/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4425.9800 - mean_absolute_error: 37.3287 - val_loss: 1621.3955 - val_mean_absolute_error: 22.9341\n",
      "Epoch 39/43\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3518.8174 - mean_absolute_error: 36.6843 - val_loss: 1675.1589 - val_mean_absolute_error: 22.9129\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:56:07,233] Trial 34 finished with value: 23.212896014136074 and parameters: {'layer_1': 7, 'layer_2': 8, 'layer_3': 7, 'learning_rate': 0.004408739171899024, 'dropout_rate': 0.041416060832973944, 'epoch': 43, 'batch_size': 57, 'optimizer': 'Adam'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 50397.8008 - mean_absolute_error: 169.7754 - val_loss: 6402.9917 - val_mean_absolute_error: 59.5921\n",
      "Epoch 2/36\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 18619.7695 - mean_absolute_error: 67.5500 - val_loss: 3455.4797 - val_mean_absolute_error: 38.7287\n",
      "Epoch 3/36\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9486.1924 - mean_absolute_error: 58.8798 - val_loss: 3110.4075 - val_mean_absolute_error: 35.7350\n",
      "Epoch 4/36\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9286.2109 - mean_absolute_error: 53.1600 - val_loss: 2481.6506 - val_mean_absolute_error: 30.4087\n",
      "Epoch 5/36\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7538.1484 - mean_absolute_error: 50.1886 - val_loss: 2037.9609 - val_mean_absolute_error: 26.9614\n",
      "Epoch 6/36\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7610.9990 - mean_absolute_error: 52.6511 - val_loss: 1911.9620 - val_mean_absolute_error: 26.0606\n",
      "Epoch 7/36\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8362.0830 - mean_absolute_error: 49.3134 - val_loss: 1676.4991 - val_mean_absolute_error: 22.8378\n",
      "Epoch 8/36\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6758.0815 - mean_absolute_error: 48.8154 - val_loss: 1758.8904 - val_mean_absolute_error: 24.1585\n",
      "Epoch 9/36\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7391.7183 - mean_absolute_error: 49.9699 - val_loss: 2523.2705 - val_mean_absolute_error: 31.2746\n",
      "Epoch 10/36\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5988.4795 - mean_absolute_error: 46.3543 - val_loss: 2384.2307 - val_mean_absolute_error: 30.7969\n",
      "Epoch 11/36\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8184.7480 - mean_absolute_error: 47.5612 - val_loss: 1827.7499 - val_mean_absolute_error: 24.7586\n",
      "Epoch 12/36\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6753.6050 - mean_absolute_error: 47.2146 - val_loss: 2471.7158 - val_mean_absolute_error: 30.7767\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:56:09,231] Trial 35 finished with value: 23.438729997420314 and parameters: {'layer_1': 8, 'layer_2': 7, 'layer_3': 5, 'learning_rate': 0.017351384214557064, 'dropout_rate': 0.07579125626692475, 'epoch': 36, 'batch_size': 82, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71738.2031 - mean_absolute_error: 216.1929 - val_loss: 69992.7578 - val_mean_absolute_error: 214.6296\n",
      "Epoch 2/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71235.0312 - mean_absolute_error: 215.1575 - val_loss: 69992.6875 - val_mean_absolute_error: 214.6294\n",
      "Epoch 3/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69881.8281 - mean_absolute_error: 213.8847 - val_loss: 69992.6172 - val_mean_absolute_error: 214.6293\n",
      "Epoch 4/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70229.2578 - mean_absolute_error: 212.4031 - val_loss: 69992.5391 - val_mean_absolute_error: 214.6291\n",
      "Epoch 5/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72487.1484 - mean_absolute_error: 213.6539 - val_loss: 69992.4688 - val_mean_absolute_error: 214.6289\n",
      "Epoch 6/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74447.1328 - mean_absolute_error: 217.3219 - val_loss: 69992.3906 - val_mean_absolute_error: 214.6287\n",
      "Epoch 7/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73268.0000 - mean_absolute_error: 216.8603 - val_loss: 69992.3047 - val_mean_absolute_error: 214.6286\n",
      "Epoch 8/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69080.4844 - mean_absolute_error: 212.7209 - val_loss: 69992.2344 - val_mean_absolute_error: 214.6284\n",
      "Epoch 9/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71747.5312 - mean_absolute_error: 214.8417 - val_loss: 69992.1484 - val_mean_absolute_error: 214.6282\n",
      "Epoch 10/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70650.4766 - mean_absolute_error: 211.6481 - val_loss: 69992.0625 - val_mean_absolute_error: 214.6280\n",
      "Epoch 11/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74430.5234 - mean_absolute_error: 220.0344 - val_loss: 69991.9609 - val_mean_absolute_error: 214.6278\n",
      "Epoch 12/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72499.9141 - mean_absolute_error: 215.7995 - val_loss: 69991.8750 - val_mean_absolute_error: 214.6276\n",
      "Epoch 13/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 78453.1641 - mean_absolute_error: 218.5627 - val_loss: 69991.7812 - val_mean_absolute_error: 214.6274\n",
      "Epoch 14/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71679.9453 - mean_absolute_error: 216.2428 - val_loss: 69991.6875 - val_mean_absolute_error: 214.6272\n",
      "Epoch 15/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75347.4297 - mean_absolute_error: 217.9535 - val_loss: 69991.6094 - val_mean_absolute_error: 214.6270\n",
      "Epoch 16/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74861.4141 - mean_absolute_error: 219.0592 - val_loss: 69991.5234 - val_mean_absolute_error: 214.6268\n",
      "Epoch 17/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69777.6094 - mean_absolute_error: 213.2565 - val_loss: 69991.4297 - val_mean_absolute_error: 214.6266\n",
      "Epoch 18/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70946.0547 - mean_absolute_error: 213.9288 - val_loss: 69991.3359 - val_mean_absolute_error: 214.6265\n",
      "Epoch 19/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 74412.9844 - mean_absolute_error: 218.6288 - val_loss: 69991.2500 - val_mean_absolute_error: 214.6262\n",
      "Epoch 20/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73812.5625 - mean_absolute_error: 217.7675 - val_loss: 69991.1562 - val_mean_absolute_error: 214.6261\n",
      "Epoch 21/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71560.5391 - mean_absolute_error: 214.8773 - val_loss: 69991.0547 - val_mean_absolute_error: 214.6258\n",
      "Epoch 22/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73487.6094 - mean_absolute_error: 216.3071 - val_loss: 69990.9609 - val_mean_absolute_error: 214.6256\n",
      "Epoch 23/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 72676.5781 - mean_absolute_error: 217.3034 - val_loss: 69990.8672 - val_mean_absolute_error: 214.6254\n",
      "Epoch 24/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 69696.7500 - mean_absolute_error: 212.5760 - val_loss: 69990.7734 - val_mean_absolute_error: 214.6252\n",
      "Epoch 25/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - loss: 73084.2578 - mean_absolute_error: 218.5641 - val_loss: 69990.6719 - val_mean_absolute_error: 214.6250\n",
      "Epoch 26/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 74382.5781 - mean_absolute_error: 215.6583 - val_loss: 69990.5781 - val_mean_absolute_error: 214.6248\n",
      "Epoch 27/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73426.9766 - mean_absolute_error: 216.7783 - val_loss: 69990.4844 - val_mean_absolute_error: 214.6246\n",
      "Epoch 28/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69935.2734 - mean_absolute_error: 211.8586 - val_loss: 69990.3906 - val_mean_absolute_error: 214.6243\n",
      "Epoch 29/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 66878.2422 - mean_absolute_error: 210.3781 - val_loss: 69990.2969 - val_mean_absolute_error: 214.6241\n",
      "Epoch 30/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73019.8672 - mean_absolute_error: 217.4682 - val_loss: 69990.1953 - val_mean_absolute_error: 214.6239\n",
      "Epoch 31/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71426.0312 - mean_absolute_error: 215.0932 - val_loss: 69990.1016 - val_mean_absolute_error: 214.6237\n",
      "Epoch 32/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77616.8828 - mean_absolute_error: 221.3710 - val_loss: 69990.0078 - val_mean_absolute_error: 214.6235\n",
      "Epoch 33/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69201.2656 - mean_absolute_error: 211.8571 - val_loss: 69989.9141 - val_mean_absolute_error: 214.6233\n",
      "Epoch 34/34\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74335.8281 - mean_absolute_error: 216.3582 - val_loss: 69989.8125 - val_mean_absolute_error: 214.6231\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:56:14,324] Trial 36 finished with value: 215.39961720516038 and parameters: {'layer_1': 4, 'layer_2': 8, 'layer_3': 4, 'learning_rate': 0.0005247231871938977, 'dropout_rate': 0.37806493987406564, 'epoch': 34, 'batch_size': 46, 'optimizer': 'Adadelta'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 288867.0625 - mean_absolute_error: 211.9020 - val_loss: 27893.7070 - val_mean_absolute_error: 137.8304\n",
      "Epoch 2/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35169.2305 - mean_absolute_error: 132.7166 - val_loss: 24391.3105 - val_mean_absolute_error: 111.3002\n",
      "Epoch 3/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 31617.6816 - mean_absolute_error: 131.4674 - val_loss: 24023.9727 - val_mean_absolute_error: 113.0384\n",
      "Epoch 4/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 31381.3711 - mean_absolute_error: 128.2764 - val_loss: 30414.9414 - val_mean_absolute_error: 146.8318\n",
      "Epoch 5/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32415.5488 - mean_absolute_error: 131.4600 - val_loss: 24003.5957 - val_mean_absolute_error: 113.0492\n",
      "Epoch 6/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32275.3203 - mean_absolute_error: 129.3731 - val_loss: 26887.2109 - val_mean_absolute_error: 111.7105\n",
      "Epoch 7/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33082.1680 - mean_absolute_error: 129.3847 - val_loss: 25095.9160 - val_mean_absolute_error: 125.2856\n",
      "Epoch 8/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32581.1602 - mean_absolute_error: 127.1349 - val_loss: 24035.1973 - val_mean_absolute_error: 117.6207\n",
      "Epoch 9/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30789.0684 - mean_absolute_error: 124.3289 - val_loss: 24907.3770 - val_mean_absolute_error: 124.2650\n",
      "Epoch 10/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31112.9590 - mean_absolute_error: 127.3480 - val_loss: 24693.9785 - val_mean_absolute_error: 111.0204\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:56:15,913] Trial 37 finished with value: 114.1681653815031 and parameters: {'layer_1': 6, 'layer_2': 6, 'layer_3': 8, 'learning_rate': 0.0013027597992592134, 'dropout_rate': 0.2926250070714216, 'epoch': 48, 'batch_size': 95, 'optimizer': 'SGD'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 69647.3281 - mean_absolute_error: 211.9203 - val_loss: 40779.6641 - val_mean_absolute_error: 166.2708\n",
      "Epoch 2/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25216.6504 - mean_absolute_error: 122.0884 - val_loss: 10321.4766 - val_mean_absolute_error: 82.5723\n",
      "Epoch 3/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12738.7910 - mean_absolute_error: 78.9407 - val_loss: 6528.8374 - val_mean_absolute_error: 61.5881\n",
      "Epoch 4/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8376.4326 - mean_absolute_error: 56.7412 - val_loss: 4976.7349 - val_mean_absolute_error: 50.1718\n",
      "Epoch 5/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5953.3535 - mean_absolute_error: 46.8747 - val_loss: 3468.6492 - val_mean_absolute_error: 38.8662\n",
      "Epoch 6/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4727.2363 - mean_absolute_error: 42.7105 - val_loss: 3263.4375 - val_mean_absolute_error: 38.0350\n",
      "Epoch 7/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5651.0039 - mean_absolute_error: 42.9317 - val_loss: 3077.7578 - val_mean_absolute_error: 35.5023\n",
      "Epoch 8/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6540.5391 - mean_absolute_error: 42.0660 - val_loss: 3018.7988 - val_mean_absolute_error: 35.8052\n",
      "Epoch 9/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4872.4976 - mean_absolute_error: 41.1021 - val_loss: 2809.2617 - val_mean_absolute_error: 33.7886\n",
      "Epoch 10/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5860.5522 - mean_absolute_error: 40.5721 - val_loss: 2722.9211 - val_mean_absolute_error: 34.0897\n",
      "Epoch 11/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4023.0474 - mean_absolute_error: 39.6529 - val_loss: 2599.0178 - val_mean_absolute_error: 31.2345\n",
      "Epoch 12/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3988.4136 - mean_absolute_error: 39.3031 - val_loss: 2497.3420 - val_mean_absolute_error: 31.6658\n",
      "Epoch 13/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4210.5220 - mean_absolute_error: 38.0041 - val_loss: 2390.1782 - val_mean_absolute_error: 30.0181\n",
      "Epoch 14/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4212.7500 - mean_absolute_error: 37.3708 - val_loss: 2298.9731 - val_mean_absolute_error: 30.1400\n",
      "Epoch 15/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3546.2468 - mean_absolute_error: 36.2672 - val_loss: 2152.6121 - val_mean_absolute_error: 28.2708\n",
      "Epoch 16/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3949.9558 - mean_absolute_error: 35.7222 - val_loss: 2300.1960 - val_mean_absolute_error: 29.9347\n",
      "Epoch 17/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3811.9229 - mean_absolute_error: 34.4326 - val_loss: 2047.7366 - val_mean_absolute_error: 27.0701\n",
      "Epoch 18/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3813.2622 - mean_absolute_error: 34.3195 - val_loss: 2231.5955 - val_mean_absolute_error: 29.8099\n",
      "Epoch 19/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3677.0237 - mean_absolute_error: 32.9527 - val_loss: 1962.2480 - val_mean_absolute_error: 26.8973\n",
      "Epoch 20/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5341.1372 - mean_absolute_error: 34.1597 - val_loss: 1835.9635 - val_mean_absolute_error: 24.8535\n",
      "Epoch 21/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4332.8774 - mean_absolute_error: 32.9555 - val_loss: 1785.8000 - val_mean_absolute_error: 24.4174\n",
      "Epoch 22/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2954.1514 - mean_absolute_error: 32.2021 - val_loss: 1880.1431 - val_mean_absolute_error: 25.9009\n",
      "Epoch 23/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3489.4507 - mean_absolute_error: 31.4255 - val_loss: 1874.5552 - val_mean_absolute_error: 25.7996\n",
      "Epoch 24/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3295.6443 - mean_absolute_error: 33.3780 - val_loss: 1698.8198 - val_mean_absolute_error: 23.7206\n",
      "Epoch 25/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2816.5708 - mean_absolute_error: 31.9855 - val_loss: 1790.6843 - val_mean_absolute_error: 24.0003\n",
      "Epoch 26/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4568.8921 - mean_absolute_error: 32.3745 - val_loss: 1787.1213 - val_mean_absolute_error: 24.0470\n",
      "Epoch 27/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4023.8154 - mean_absolute_error: 32.2285 - val_loss: 1705.5771 - val_mean_absolute_error: 23.0509\n",
      "Epoch 28/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3323.5881 - mean_absolute_error: 32.5470 - val_loss: 1656.9503 - val_mean_absolute_error: 22.3470\n",
      "Epoch 29/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3127.7417 - mean_absolute_error: 30.2857 - val_loss: 1662.4927 - val_mean_absolute_error: 22.8786\n",
      "Epoch 30/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2788.7769 - mean_absolute_error: 30.7567 - val_loss: 1708.9308 - val_mean_absolute_error: 23.2393\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:56:19,632] Trial 38 finished with value: 23.12744823155403 and parameters: {'layer_1': 7, 'layer_2': 7, 'layer_3': 7, 'learning_rate': 0.009277718862082547, 'dropout_rate': 0.024784655751431198, 'epoch': 30, 'batch_size': 86, 'optimizer': 'Adam'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 25610.0859 - mean_absolute_error: 108.3249 - val_loss: 5017.6030 - val_mean_absolute_error: 48.2020\n",
      "Epoch 2/38\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9008.3545 - mean_absolute_error: 54.9329 - val_loss: 4997.2163 - val_mean_absolute_error: 47.7411\n",
      "Epoch 3/38\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7620.8960 - mean_absolute_error: 50.6329 - val_loss: 3966.8062 - val_mean_absolute_error: 43.2175\n",
      "Epoch 4/38\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7114.9414 - mean_absolute_error: 50.2078 - val_loss: 2103.3562 - val_mean_absolute_error: 27.2905\n",
      "Epoch 5/38\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9287.1074 - mean_absolute_error: 50.5377 - val_loss: 1961.5017 - val_mean_absolute_error: 26.0635\n",
      "Epoch 6/38\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6233.5513 - mean_absolute_error: 44.7972 - val_loss: 37931.5586 - val_mean_absolute_error: 126.4273\n",
      "Epoch 7/38\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15007.2471 - mean_absolute_error: 55.4501 - val_loss: 2388.0178 - val_mean_absolute_error: 29.2682\n",
      "Epoch 8/38\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4752.7666 - mean_absolute_error: 39.9116 - val_loss: 27600.3203 - val_mean_absolute_error: 104.2941\n",
      "Epoch 9/38\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7546.8286 - mean_absolute_error: 48.4372 - val_loss: 2790.6523 - val_mean_absolute_error: 37.4380\n",
      "Epoch 10/38\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6499.9199 - mean_absolute_error: 45.1586 - val_loss: 9828.6992 - val_mean_absolute_error: 67.9318\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:56:21,466] Trial 39 finished with value: 26.21513225194216 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 6, 'learning_rate': 0.0687701584086838, 'dropout_rate': 0.053504389865222435, 'epoch': 38, 'batch_size': 77, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 75679.5469 - mean_absolute_error: 218.8244 - val_loss: 69954.9688 - val_mean_absolute_error: 214.5497\n",
      "Epoch 2/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - loss: 72540.3516 - mean_absolute_error: 218.5787 - val_loss: 69896.2031 - val_mean_absolute_error: 214.4202\n",
      "Epoch 3/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 73590.3750 - mean_absolute_error: 216.6111 - val_loss: 69823.5625 - val_mean_absolute_error: 214.2630\n",
      "Epoch 4/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 74058.0781 - mean_absolute_error: 217.1825 - val_loss: 69731.5156 - val_mean_absolute_error: 214.0695\n",
      "Epoch 5/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 76136.6797 - mean_absolute_error: 218.8364 - val_loss: 69621.4219 - val_mean_absolute_error: 213.8412\n",
      "Epoch 6/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - loss: 71629.2812 - mean_absolute_error: 214.1251 - val_loss: 69486.3672 - val_mean_absolute_error: 213.5672\n",
      "Epoch 7/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 68746.0391 - mean_absolute_error: 210.4603 - val_loss: 69322.3203 - val_mean_absolute_error: 213.2408\n",
      "Epoch 8/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 71557.6641 - mean_absolute_error: 213.5078 - val_loss: 69129.3516 - val_mean_absolute_error: 212.8603\n",
      "Epoch 9/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - loss: 69720.4688 - mean_absolute_error: 212.3831 - val_loss: 68899.0078 - val_mean_absolute_error: 212.4122\n",
      "Epoch 10/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - loss: 70939.5391 - mean_absolute_error: 213.0192 - val_loss: 68619.4219 - val_mean_absolute_error: 211.8731\n",
      "Epoch 11/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 67961.3750 - mean_absolute_error: 208.3497 - val_loss: 68276.8359 - val_mean_absolute_error: 211.2207\n",
      "Epoch 12/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 67397.8672 - mean_absolute_error: 207.9754 - val_loss: 67872.5156 - val_mean_absolute_error: 210.4534\n",
      "Epoch 13/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 65941.8906 - mean_absolute_error: 205.8955 - val_loss: 67397.5469 - val_mean_absolute_error: 209.5550\n",
      "Epoch 14/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 72416.4062 - mean_absolute_error: 212.5566 - val_loss: 66834.2500 - val_mean_absolute_error: 208.5044\n",
      "Epoch 15/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - loss: 67420.5234 - mean_absolute_error: 207.6430 - val_loss: 66200.7969 - val_mean_absolute_error: 207.3102\n",
      "Epoch 16/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 67486.2578 - mean_absolute_error: 206.5362 - val_loss: 65463.9492 - val_mean_absolute_error: 205.9246\n",
      "Epoch 17/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 65798.9141 - mean_absolute_error: 203.0099 - val_loss: 64617.6758 - val_mean_absolute_error: 204.3247\n",
      "Epoch 18/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 66459.2734 - mean_absolute_error: 204.0296 - val_loss: 63660.5391 - val_mean_absolute_error: 202.4618\n",
      "Epoch 19/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 66693.6797 - mean_absolute_error: 203.0791 - val_loss: 62551.2773 - val_mean_absolute_error: 200.2252\n",
      "Epoch 20/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 67751.3281 - mean_absolute_error: 203.6288 - val_loss: 61300.3398 - val_mean_absolute_error: 197.6602\n",
      "Epoch 21/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 62954.1055 - mean_absolute_error: 197.2411 - val_loss: 59874.1367 - val_mean_absolute_error: 194.7215\n",
      "Epoch 22/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 58774.4180 - mean_absolute_error: 191.9559 - val_loss: 58319.3477 - val_mean_absolute_error: 191.4732\n",
      "Epoch 23/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 60521.0703 - mean_absolute_error: 193.5502 - val_loss: 56674.0664 - val_mean_absolute_error: 187.9843\n",
      "Epoch 24/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - loss: 58403.6523 - mean_absolute_error: 189.1745 - val_loss: 54830.5312 - val_mean_absolute_error: 184.0603\n",
      "Epoch 25/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - loss: 58614.3633 - mean_absolute_error: 186.2506 - val_loss: 52853.2695 - val_mean_absolute_error: 179.8060\n",
      "Epoch 26/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 54558.6680 - mean_absolute_error: 181.6163 - val_loss: 50702.5000 - val_mean_absolute_error: 175.1708\n",
      "Epoch 27/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - loss: 50471.4336 - mean_absolute_error: 172.6197 - val_loss: 48462.1250 - val_mean_absolute_error: 170.2601\n",
      "Epoch 28/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 53328.2109 - mean_absolute_error: 172.8709 - val_loss: 45992.3008 - val_mean_absolute_error: 164.9472\n",
      "Epoch 29/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 50053.6602 - mean_absolute_error: 169.1148 - val_loss: 43462.1758 - val_mean_absolute_error: 159.5575\n",
      "Epoch 30/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 47201.7188 - mean_absolute_error: 165.0589 - val_loss: 40815.6836 - val_mean_absolute_error: 154.1082\n",
      "Epoch 31/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - loss: 43275.8828 - mean_absolute_error: 155.7519 - val_loss: 38255.6250 - val_mean_absolute_error: 148.9888\n",
      "Epoch 32/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 39113.5625 - mean_absolute_error: 152.1710 - val_loss: 35661.3008 - val_mean_absolute_error: 143.9700\n",
      "Epoch 33/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - loss: 40641.2539 - mean_absolute_error: 150.4827 - val_loss: 33102.2383 - val_mean_absolute_error: 139.1140\n",
      "Epoch 34/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 38064.0117 - mean_absolute_error: 146.5387 - val_loss: 30622.4414 - val_mean_absolute_error: 134.3258\n",
      "Epoch 35/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 33769.7422 - mean_absolute_error: 140.0812 - val_loss: 28255.7734 - val_mean_absolute_error: 129.6672\n",
      "Epoch 36/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 31206.6016 - mean_absolute_error: 132.0365 - val_loss: 25971.5996 - val_mean_absolute_error: 125.0505\n",
      "Epoch 37/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - loss: 31749.6660 - mean_absolute_error: 132.5983 - val_loss: 23601.8184 - val_mean_absolute_error: 120.0033\n",
      "Epoch 38/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 26796.2949 - mean_absolute_error: 125.5389 - val_loss: 21297.3535 - val_mean_absolute_error: 114.7346\n",
      "Epoch 39/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - loss: 26645.2637 - mean_absolute_error: 121.3295 - val_loss: 19456.9551 - val_mean_absolute_error: 110.3002\n",
      "Epoch 40/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 24706.5410 - mean_absolute_error: 116.7213 - val_loss: 17672.5605 - val_mean_absolute_error: 105.7126\n",
      "Epoch 41/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 24845.8906 - mean_absolute_error: 117.2532 - val_loss: 16388.8398 - val_mean_absolute_error: 102.1223\n",
      "Epoch 42/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - loss: 24860.3164 - mean_absolute_error: 112.5959 - val_loss: 15384.3047 - val_mean_absolute_error: 99.1152\n",
      "Epoch 43/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - loss: 20787.8633 - mean_absolute_error: 108.0240 - val_loss: 14308.6836 - val_mean_absolute_error: 95.7087\n",
      "Epoch 44/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 22753.9941 - mean_absolute_error: 107.5460 - val_loss: 13530.6025 - val_mean_absolute_error: 93.0401\n",
      "Epoch 45/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 21650.7520 - mean_absolute_error: 105.2999 - val_loss: 12831.4590 - val_mean_absolute_error: 90.4850\n",
      "Epoch 46/46\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 23576.0938 - mean_absolute_error: 102.9562 - val_loss: 12196.6494 - val_mean_absolute_error: 88.0082\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:56:29,132] Trial 40 finished with value: 88.27413830763699 and parameters: {'layer_1': 3, 'layer_2': 5, 'layer_3': 4, 'learning_rate': 0.00027702868111055545, 'dropout_rate': 0.09467393490182738, 'epoch': 46, 'batch_size': 27, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 35314.1016 - mean_absolute_error: 123.8392 - val_loss: 3256.7935 - val_mean_absolute_error: 35.3845\n",
      "Epoch 2/44\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7899.9473 - mean_absolute_error: 44.6623 - val_loss: 2147.1069 - val_mean_absolute_error: 26.2251\n",
      "Epoch 3/44\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5260.0439 - mean_absolute_error: 40.0275 - val_loss: 2503.6079 - val_mean_absolute_error: 34.6141\n",
      "Epoch 4/44\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4255.9824 - mean_absolute_error: 36.0061 - val_loss: 2718.3462 - val_mean_absolute_error: 37.3144\n",
      "Epoch 5/44\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3961.5747 - mean_absolute_error: 34.2223 - val_loss: 2386.6741 - val_mean_absolute_error: 31.3303\n",
      "Epoch 6/44\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4533.8032 - mean_absolute_error: 36.9211 - val_loss: 3047.2068 - val_mean_absolute_error: 33.5882\n",
      "Epoch 7/44\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4307.8223 - mean_absolute_error: 34.6898 - val_loss: 2190.6086 - val_mean_absolute_error: 30.3866\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:56:30,665] Trial 41 finished with value: 26.673069183188677 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 6, 'learning_rate': 0.059136070648713436, 'dropout_rate': 0.014313521741073146, 'epoch': 44, 'batch_size': 93, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 39542.9023 - mean_absolute_error: 134.3020 - val_loss: 3668.2024 - val_mean_absolute_error: 41.8989\n",
      "Epoch 2/48\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4961.4570 - mean_absolute_error: 43.0095 - val_loss: 6129.1240 - val_mean_absolute_error: 56.8008\n",
      "Epoch 3/48\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5278.8564 - mean_absolute_error: 38.9857 - val_loss: 6655.2363 - val_mean_absolute_error: 58.3506\n",
      "Epoch 4/48\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6497.9150 - mean_absolute_error: 42.0392 - val_loss: 1751.0721 - val_mean_absolute_error: 23.1548\n",
      "Epoch 5/48\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4181.8374 - mean_absolute_error: 37.0478 - val_loss: 1720.0509 - val_mean_absolute_error: 23.1461\n",
      "Epoch 6/48\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4078.5725 - mean_absolute_error: 36.2566 - val_loss: 1929.0397 - val_mean_absolute_error: 26.3217\n",
      "Epoch 7/48\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4237.1445 - mean_absolute_error: 37.1826 - val_loss: 1828.6284 - val_mean_absolute_error: 24.8279\n",
      "Epoch 8/48\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3499.8833 - mean_absolute_error: 34.5580 - val_loss: 1657.1302 - val_mean_absolute_error: 22.2792\n",
      "Epoch 9/48\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3435.0083 - mean_absolute_error: 34.0749 - val_loss: 1913.3137 - val_mean_absolute_error: 27.0803\n",
      "Epoch 10/48\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3843.5681 - mean_absolute_error: 34.1623 - val_loss: 1736.6224 - val_mean_absolute_error: 23.6642\n",
      "Epoch 11/48\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4999.0142 - mean_absolute_error: 38.2274 - val_loss: 2076.7627 - val_mean_absolute_error: 27.1219\n",
      "Epoch 12/48\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4618.9150 - mean_absolute_error: 36.7143 - val_loss: 1982.1047 - val_mean_absolute_error: 26.3664\n",
      "Epoch 13/48\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3741.1389 - mean_absolute_error: 35.9839 - val_loss: 2115.6172 - val_mean_absolute_error: 26.4263\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:56:32,684] Trial 42 finished with value: 22.94313094578981 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 7, 'learning_rate': 0.0368648761922578, 'dropout_rate': 0.028764805544682626, 'epoch': 48, 'batch_size': 100, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 53117.1523 - mean_absolute_error: 180.5421 - val_loss: 8980.4775 - val_mean_absolute_error: 72.3379\n",
      "Epoch 2/45\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11737.8369 - mean_absolute_error: 67.2315 - val_loss: 4902.1909 - val_mean_absolute_error: 50.4015\n",
      "Epoch 3/45\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9845.0801 - mean_absolute_error: 47.4327 - val_loss: 3325.5662 - val_mean_absolute_error: 36.8318\n",
      "Epoch 4/45\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5026.0688 - mean_absolute_error: 35.6940 - val_loss: 2784.6121 - val_mean_absolute_error: 31.8397\n",
      "Epoch 5/45\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3569.6382 - mean_absolute_error: 33.4141 - val_loss: 2502.3337 - val_mean_absolute_error: 30.7245\n",
      "Epoch 6/45\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3686.5613 - mean_absolute_error: 29.1402 - val_loss: 2191.8779 - val_mean_absolute_error: 28.0692\n",
      "Epoch 7/45\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5623.8706 - mean_absolute_error: 30.3602 - val_loss: 1978.3363 - val_mean_absolute_error: 26.0719\n",
      "Epoch 8/45\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2647.5837 - mean_absolute_error: 25.8692 - val_loss: 1781.2266 - val_mean_absolute_error: 23.8957\n",
      "Epoch 9/45\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2157.5413 - mean_absolute_error: 25.1728 - val_loss: 1740.9677 - val_mean_absolute_error: 23.8753\n",
      "Epoch 10/45\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2352.5073 - mean_absolute_error: 24.3405 - val_loss: 1702.0018 - val_mean_absolute_error: 22.9419\n",
      "Epoch 11/45\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2708.4001 - mean_absolute_error: 24.4070 - val_loss: 1717.4352 - val_mean_absolute_error: 23.0216\n",
      "Epoch 12/45\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2420.9624 - mean_absolute_error: 23.2603 - val_loss: 2726.3406 - val_mean_absolute_error: 32.3286\n",
      "Epoch 13/45\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2480.1733 - mean_absolute_error: 24.7220 - val_loss: 1840.9310 - val_mean_absolute_error: 24.9734\n",
      "Epoch 14/45\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2995.4597 - mean_absolute_error: 23.9829 - val_loss: 1705.0526 - val_mean_absolute_error: 22.8371\n",
      "Epoch 15/45\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2443.4324 - mean_absolute_error: 23.9969 - val_loss: 1598.6761 - val_mean_absolute_error: 21.4958\n",
      "Epoch 16/45\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2383.0439 - mean_absolute_error: 23.6409 - val_loss: 2362.5425 - val_mean_absolute_error: 30.8010\n",
      "Epoch 17/45\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3185.5513 - mean_absolute_error: 24.5302 - val_loss: 1809.2529 - val_mean_absolute_error: 23.4682\n",
      "Epoch 18/45\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3572.7708 - mean_absolute_error: 25.1719 - val_loss: 1637.5636 - val_mean_absolute_error: 21.7655\n",
      "Epoch 19/45\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2516.1621 - mean_absolute_error: 24.4638 - val_loss: 1556.2041 - val_mean_absolute_error: 21.0122\n",
      "Epoch 20/45\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2283.9910 - mean_absolute_error: 23.1347 - val_loss: 1862.4301 - val_mean_absolute_error: 24.0068\n",
      "Epoch 21/45\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2741.0935 - mean_absolute_error: 23.5466 - val_loss: 1595.1501 - val_mean_absolute_error: 21.2169\n",
      "Epoch 22/45\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2732.9678 - mean_absolute_error: 23.2148 - val_loss: 1580.4154 - val_mean_absolute_error: 20.8432\n",
      "Epoch 23/45\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2335.8569 - mean_absolute_error: 22.4778 - val_loss: 2052.6218 - val_mean_absolute_error: 25.8898\n",
      "Epoch 24/45\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2153.5608 - mean_absolute_error: 23.8954 - val_loss: 1626.4221 - val_mean_absolute_error: 21.6575\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:56:35,610] Trial 43 finished with value: 21.583044349777698 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 6, 'learning_rate': 0.015568730230626432, 'dropout_rate': 0.0012724994100308494, 'epoch': 45, 'batch_size': 94, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 157091807232.0000 - mean_absolute_error: 18176.2422 - val_loss: 70001.7891 - val_mean_absolute_error: 214.6510\n",
      "Epoch 2/41\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73560.3281 - mean_absolute_error: 218.2076 - val_loss: 70001.7891 - val_mean_absolute_error: 214.6510\n",
      "Epoch 3/41\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71618.4609 - mean_absolute_error: 214.1340 - val_loss: 70001.7891 - val_mean_absolute_error: 214.6510\n",
      "Epoch 4/41\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72622.8984 - mean_absolute_error: 213.2469 - val_loss: 70001.7891 - val_mean_absolute_error: 214.6510\n",
      "Epoch 5/41\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 69035.1328 - mean_absolute_error: 210.1879 - val_loss: 70001.7891 - val_mean_absolute_error: 214.6510\n",
      "Epoch 6/41\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73025.8047 - mean_absolute_error: 216.9955 - val_loss: 70001.7891 - val_mean_absolute_error: 214.6510\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:56:36,973] Trial 44 finished with value: 215.42847832031254 and parameters: {'layer_1': 7, 'layer_2': 7, 'layer_3': 5, 'learning_rate': 0.013160043840585448, 'dropout_rate': 0.07567383131965547, 'epoch': 41, 'batch_size': 87, 'optimizer': 'SGD'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 70436.0391 - mean_absolute_error: 209.1932 - val_loss: 31196.1484 - val_mean_absolute_error: 145.6978\n",
      "Epoch 2/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34739.7852 - mean_absolute_error: 135.4163 - val_loss: 12225.8320 - val_mean_absolute_error: 87.3894\n",
      "Epoch 3/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26035.3926 - mean_absolute_error: 85.8694 - val_loss: 9051.4648 - val_mean_absolute_error: 72.5472\n",
      "Epoch 4/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11210.3008 - mean_absolute_error: 69.8937 - val_loss: 7026.7754 - val_mean_absolute_error: 62.9496\n",
      "Epoch 5/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9775.9971 - mean_absolute_error: 58.4312 - val_loss: 5564.1484 - val_mean_absolute_error: 50.2472\n",
      "Epoch 6/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9458.1895 - mean_absolute_error: 50.9229 - val_loss: 4557.9072 - val_mean_absolute_error: 45.3201\n",
      "Epoch 7/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8902.4951 - mean_absolute_error: 45.4703 - val_loss: 4005.8801 - val_mean_absolute_error: 41.9482\n",
      "Epoch 8/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11765.1514 - mean_absolute_error: 45.5573 - val_loss: 3647.9524 - val_mean_absolute_error: 39.6639\n",
      "Epoch 9/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5806.0132 - mean_absolute_error: 40.4774 - val_loss: 3440.7922 - val_mean_absolute_error: 38.5236\n",
      "Epoch 10/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5754.5200 - mean_absolute_error: 39.2762 - val_loss: 3138.5801 - val_mean_absolute_error: 35.5660\n",
      "Epoch 11/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9044.2646 - mean_absolute_error: 38.4729 - val_loss: 2940.0422 - val_mean_absolute_error: 34.2786\n",
      "Epoch 12/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4252.3647 - mean_absolute_error: 35.5129 - val_loss: 2917.2527 - val_mean_absolute_error: 34.6412\n",
      "Epoch 13/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3728.1919 - mean_absolute_error: 33.4947 - val_loss: 2542.9204 - val_mean_absolute_error: 30.6051\n",
      "Epoch 14/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3246.4785 - mean_absolute_error: 30.9307 - val_loss: 2588.1194 - val_mean_absolute_error: 31.9998\n",
      "Epoch 15/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2897.5767 - mean_absolute_error: 30.3735 - val_loss: 2131.1265 - val_mean_absolute_error: 27.4746\n",
      "Epoch 16/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3454.8909 - mean_absolute_error: 29.9947 - val_loss: 1994.1851 - val_mean_absolute_error: 25.8098\n",
      "Epoch 17/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4995.7319 - mean_absolute_error: 29.1081 - val_loss: 1904.8816 - val_mean_absolute_error: 25.7757\n",
      "Epoch 18/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2376.6013 - mean_absolute_error: 25.7745 - val_loss: 2910.5347 - val_mean_absolute_error: 33.9048\n",
      "Epoch 19/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2572.3953 - mean_absolute_error: 26.7810 - val_loss: 2068.2200 - val_mean_absolute_error: 27.1027\n",
      "Epoch 20/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2909.8481 - mean_absolute_error: 24.9321 - val_loss: 1736.0754 - val_mean_absolute_error: 23.2708\n",
      "Epoch 21/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3088.0071 - mean_absolute_error: 24.2404 - val_loss: 1688.0566 - val_mean_absolute_error: 22.8858\n",
      "Epoch 22/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2479.7878 - mean_absolute_error: 24.1901 - val_loss: 1736.3086 - val_mean_absolute_error: 23.6021\n",
      "Epoch 23/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3293.8359 - mean_absolute_error: 25.0460 - val_loss: 1655.0892 - val_mean_absolute_error: 22.3124\n",
      "Epoch 24/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3694.8594 - mean_absolute_error: 25.7683 - val_loss: 1596.6847 - val_mean_absolute_error: 21.6364\n",
      "Epoch 25/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2473.0769 - mean_absolute_error: 23.9507 - val_loss: 2066.7305 - val_mean_absolute_error: 27.1540\n",
      "Epoch 26/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3304.6707 - mean_absolute_error: 25.3793 - val_loss: 1609.5139 - val_mean_absolute_error: 21.8514\n",
      "Epoch 27/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2319.2930 - mean_absolute_error: 23.4498 - val_loss: 1768.9363 - val_mean_absolute_error: 23.8265\n",
      "Epoch 28/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2609.3271 - mean_absolute_error: 24.1941 - val_loss: 2166.7488 - val_mean_absolute_error: 27.2970\n",
      "Epoch 29/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2530.9973 - mean_absolute_error: 23.6725 - val_loss: 1581.7380 - val_mean_absolute_error: 21.3755\n",
      "Epoch 30/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2479.5344 - mean_absolute_error: 23.4594 - val_loss: 1720.8079 - val_mean_absolute_error: 23.1152\n",
      "Epoch 31/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2514.3948 - mean_absolute_error: 23.2352 - val_loss: 1677.8506 - val_mean_absolute_error: 22.3512\n",
      "Epoch 32/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2295.9922 - mean_absolute_error: 23.7626 - val_loss: 1599.4946 - val_mean_absolute_error: 21.4593\n",
      "Epoch 33/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2165.0769 - mean_absolute_error: 23.5266 - val_loss: 1602.0889 - val_mean_absolute_error: 21.2358\n",
      "Epoch 34/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2238.9221 - mean_absolute_error: 23.0825 - val_loss: 2050.2083 - val_mean_absolute_error: 26.0305\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:56:41,648] Trial 45 finished with value: 21.79807482444048 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 8, 'learning_rate': 0.006772423926117093, 'dropout_rate': 0.0032155718845226083, 'epoch': 50, 'batch_size': 95, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 69573.4609 - mean_absolute_error: 213.5569 - val_loss: 64826.5977 - val_mean_absolute_error: 207.2367\n",
      "Epoch 2/16\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65516.6836 - mean_absolute_error: 204.0988 - val_loss: 49134.1406 - val_mean_absolute_error: 184.7813\n",
      "Epoch 3/16\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 47361.2266 - mean_absolute_error: 179.6657 - val_loss: 27145.7930 - val_mean_absolute_error: 144.0811\n",
      "Epoch 4/16\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27987.8516 - mean_absolute_error: 137.3131 - val_loss: 17416.1328 - val_mean_absolute_error: 113.2168\n",
      "Epoch 5/16\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18057.2090 - mean_absolute_error: 109.7833 - val_loss: 14302.4600 - val_mean_absolute_error: 100.3933\n",
      "Epoch 6/16\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17180.2168 - mean_absolute_error: 99.7027 - val_loss: 11064.8496 - val_mean_absolute_error: 83.1157\n",
      "Epoch 7/16\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13151.0439 - mean_absolute_error: 83.0160 - val_loss: 8361.8857 - val_mean_absolute_error: 67.0432\n",
      "Epoch 8/16\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17597.8438 - mean_absolute_error: 74.5947 - val_loss: 6788.5586 - val_mean_absolute_error: 58.6171\n",
      "Epoch 9/16\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10930.7148 - mean_absolute_error: 64.2122 - val_loss: 5689.7280 - val_mean_absolute_error: 52.3521\n",
      "Epoch 10/16\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8800.6309 - mean_absolute_error: 58.5390 - val_loss: 5006.4502 - val_mean_absolute_error: 47.0785\n",
      "Epoch 11/16\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9394.3398 - mean_absolute_error: 55.0499 - val_loss: 4482.5757 - val_mean_absolute_error: 44.1952\n",
      "Epoch 12/16\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7319.1284 - mean_absolute_error: 51.7523 - val_loss: 4119.0659 - val_mean_absolute_error: 41.9964\n",
      "Epoch 13/16\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8461.2744 - mean_absolute_error: 49.0592 - val_loss: 3842.2053 - val_mean_absolute_error: 39.8521\n",
      "Epoch 14/16\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5892.5928 - mean_absolute_error: 47.0747 - val_loss: 3663.7720 - val_mean_absolute_error: 38.8679\n",
      "Epoch 15/16\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8001.7886 - mean_absolute_error: 48.0580 - val_loss: 3536.9290 - val_mean_absolute_error: 38.2057\n",
      "Epoch 16/16\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6799.7417 - mean_absolute_error: 45.6918 - val_loss: 3368.9133 - val_mean_absolute_error: 36.7888\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:56:44,186] Trial 46 finished with value: 37.216887804615496 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 7, 'learning_rate': 0.003627305554284961, 'dropout_rate': 0.03488208252709922, 'epoch': 16, 'batch_size': 100, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 69589.1016 - mean_absolute_error: 212.5686 - val_loss: 67788.1797 - val_mean_absolute_error: 210.2854\n",
      "Epoch 2/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66500.2031 - mean_absolute_error: 205.1358 - val_loss: 59099.7148 - val_mean_absolute_error: 194.5914\n",
      "Epoch 3/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57000.7383 - mean_absolute_error: 187.6302 - val_loss: 41118.0781 - val_mean_absolute_error: 159.6965\n",
      "Epoch 4/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38493.8125 - mean_absolute_error: 150.2163 - val_loss: 21123.8223 - val_mean_absolute_error: 115.6875\n",
      "Epoch 5/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22408.9023 - mean_absolute_error: 111.5110 - val_loss: 12027.0234 - val_mean_absolute_error: 87.8052\n",
      "Epoch 6/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 17468.2656 - mean_absolute_error: 91.7077 - val_loss: 10053.4688 - val_mean_absolute_error: 78.0657\n",
      "Epoch 7/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 16089.5000 - mean_absolute_error: 85.0376 - val_loss: 8597.6885 - val_mean_absolute_error: 69.8367\n",
      "Epoch 8/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 16841.0176 - mean_absolute_error: 76.9124 - val_loss: 7491.6245 - val_mean_absolute_error: 63.7791\n",
      "Epoch 9/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13569.2207 - mean_absolute_error: 68.7322 - val_loss: 6649.6587 - val_mean_absolute_error: 59.4410\n",
      "Epoch 10/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9958.4521 - mean_absolute_error: 63.7128 - val_loss: 5684.8911 - val_mean_absolute_error: 52.7066\n",
      "Epoch 11/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8374.7461 - mean_absolute_error: 58.7801 - val_loss: 4884.7432 - val_mean_absolute_error: 46.5995\n",
      "Epoch 12/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9292.1738 - mean_absolute_error: 55.1627 - val_loss: 4324.8687 - val_mean_absolute_error: 42.1773\n",
      "Epoch 13/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10951.9814 - mean_absolute_error: 55.0994 - val_loss: 3934.5701 - val_mean_absolute_error: 38.9255\n",
      "Epoch 14/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7890.0132 - mean_absolute_error: 50.4140 - val_loss: 3686.7241 - val_mean_absolute_error: 37.3918\n",
      "Epoch 15/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7276.7632 - mean_absolute_error: 50.2204 - val_loss: 3481.7012 - val_mean_absolute_error: 35.8150\n",
      "Epoch 16/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6977.6758 - mean_absolute_error: 48.7393 - val_loss: 3507.3491 - val_mean_absolute_error: 36.5233\n",
      "Epoch 17/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7451.1689 - mean_absolute_error: 49.4999 - val_loss: 3257.0291 - val_mean_absolute_error: 34.4764\n",
      "Epoch 18/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6327.2607 - mean_absolute_error: 47.6223 - val_loss: 3241.8430 - val_mean_absolute_error: 35.0439\n",
      "Epoch 19/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7564.1011 - mean_absolute_error: 46.6150 - val_loss: 3094.7061 - val_mean_absolute_error: 34.0051\n",
      "Epoch 20/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6345.7090 - mean_absolute_error: 47.3220 - val_loss: 2966.1814 - val_mean_absolute_error: 33.0879\n",
      "Epoch 21/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5504.6675 - mean_absolute_error: 45.9078 - val_loss: 2938.4680 - val_mean_absolute_error: 33.0620\n",
      "Epoch 22/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5980.8970 - mean_absolute_error: 46.2839 - val_loss: 2875.2134 - val_mean_absolute_error: 32.7948\n",
      "Epoch 23/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5327.8394 - mean_absolute_error: 44.8914 - val_loss: 3028.4541 - val_mean_absolute_error: 33.8203\n",
      "Epoch 24/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7914.5791 - mean_absolute_error: 46.9670 - val_loss: 2686.9749 - val_mean_absolute_error: 31.2704\n",
      "Epoch 25/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6624.8296 - mean_absolute_error: 46.3017 - val_loss: 2630.9983 - val_mean_absolute_error: 30.9674\n",
      "Epoch 26/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5871.6577 - mean_absolute_error: 44.9845 - val_loss: 2544.0430 - val_mean_absolute_error: 30.2051\n",
      "Epoch 27/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5871.2861 - mean_absolute_error: 42.8664 - val_loss: 2641.0278 - val_mean_absolute_error: 31.2481\n",
      "Epoch 28/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5850.9482 - mean_absolute_error: 44.1549 - val_loss: 2557.5957 - val_mean_absolute_error: 30.6113\n",
      "Epoch 29/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5098.6284 - mean_absolute_error: 41.9834 - val_loss: 2513.2458 - val_mean_absolute_error: 30.3495\n",
      "Epoch 30/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5570.8579 - mean_absolute_error: 43.9148 - val_loss: 2350.1211 - val_mean_absolute_error: 28.9228\n",
      "Epoch 31/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5826.3608 - mean_absolute_error: 44.2518 - val_loss: 2288.6130 - val_mean_absolute_error: 28.3537\n",
      "Epoch 32/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5208.8008 - mean_absolute_error: 42.2789 - val_loss: 2404.4507 - val_mean_absolute_error: 29.4902\n",
      "Epoch 33/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5071.1421 - mean_absolute_error: 42.1861 - val_loss: 2447.5503 - val_mean_absolute_error: 30.0785\n",
      "Epoch 34/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4633.6089 - mean_absolute_error: 42.3599 - val_loss: 2371.6196 - val_mean_absolute_error: 29.3700\n",
      "Epoch 35/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6807.2368 - mean_absolute_error: 42.4258 - val_loss: 2048.1123 - val_mean_absolute_error: 26.2779\n",
      "Epoch 36/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4471.7959 - mean_absolute_error: 39.1808 - val_loss: 2018.4156 - val_mean_absolute_error: 26.0922\n",
      "Epoch 37/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5560.6812 - mean_absolute_error: 41.4167 - val_loss: 2018.5073 - val_mean_absolute_error: 26.0060\n",
      "Epoch 38/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5971.0400 - mean_absolute_error: 42.4839 - val_loss: 2045.9263 - val_mean_absolute_error: 26.3143\n",
      "Epoch 39/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4517.8931 - mean_absolute_error: 39.4649 - val_loss: 2057.0239 - val_mean_absolute_error: 26.4820\n",
      "Epoch 40/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4770.0376 - mean_absolute_error: 39.8272 - val_loss: 1913.5647 - val_mean_absolute_error: 24.9140\n",
      "Epoch 41/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4409.3643 - mean_absolute_error: 40.0050 - val_loss: 2003.1044 - val_mean_absolute_error: 26.2626\n",
      "Epoch 42/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3572.8679 - mean_absolute_error: 37.9335 - val_loss: 1974.1964 - val_mean_absolute_error: 25.8279\n",
      "Epoch 43/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4714.4902 - mean_absolute_error: 39.8151 - val_loss: 1848.3124 - val_mean_absolute_error: 24.3904\n",
      "Epoch 44/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4516.8081 - mean_absolute_error: 40.2936 - val_loss: 1919.8790 - val_mean_absolute_error: 25.1607\n",
      "Epoch 45/45\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4903.3823 - mean_absolute_error: 40.8994 - val_loss: 2063.0498 - val_mean_absolute_error: 27.0970\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:56:49,632] Trial 47 finished with value: 24.526479165685178 and parameters: {'layer_1': 7, 'layer_2': 7, 'layer_3': 6, 'learning_rate': 0.002842147953166265, 'dropout_rate': 0.0516880769339002, 'epoch': 45, 'batch_size': 78, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 55001.5820 - mean_absolute_error: 175.7752 - val_loss: 8277.5469 - val_mean_absolute_error: 70.7468\n",
      "Epoch 2/33\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21230.0176 - mean_absolute_error: 96.1126 - val_loss: 4659.2168 - val_mean_absolute_error: 49.9857\n",
      "Epoch 3/33\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 16014.8867 - mean_absolute_error: 79.9643 - val_loss: 4956.3755 - val_mean_absolute_error: 50.3130\n",
      "Epoch 4/33\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12634.7471 - mean_absolute_error: 74.0763 - val_loss: 9735.1748 - val_mean_absolute_error: 70.1289\n",
      "Epoch 5/33\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14034.1611 - mean_absolute_error: 73.5041 - val_loss: 3759.9016 - val_mean_absolute_error: 43.3278\n",
      "Epoch 6/33\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11289.7969 - mean_absolute_error: 68.1973 - val_loss: 7027.5986 - val_mean_absolute_error: 59.3643\n",
      "Epoch 7/33\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11537.4453 - mean_absolute_error: 67.3139 - val_loss: 5549.5010 - val_mean_absolute_error: 51.7344\n",
      "Epoch 8/33\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10915.2920 - mean_absolute_error: 67.7094 - val_loss: 4247.2998 - val_mean_absolute_error: 45.9830\n",
      "Epoch 9/33\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9602.6602 - mean_absolute_error: 64.8101 - val_loss: 2822.3179 - val_mean_absolute_error: 37.3746\n",
      "Epoch 10/33\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8718.7891 - mean_absolute_error: 62.0147 - val_loss: 5237.7910 - val_mean_absolute_error: 50.8377\n",
      "Epoch 11/33\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10529.4355 - mean_absolute_error: 64.3766 - val_loss: 3319.4714 - val_mean_absolute_error: 41.5105\n",
      "Epoch 12/33\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10449.8184 - mean_absolute_error: 64.3412 - val_loss: 3632.5369 - val_mean_absolute_error: 43.4101\n",
      "Epoch 13/33\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10204.4619 - mean_absolute_error: 64.2404 - val_loss: 3649.8257 - val_mean_absolute_error: 44.2258\n",
      "Epoch 14/33\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8973.2451 - mean_absolute_error: 61.7217 - val_loss: 5449.2642 - val_mean_absolute_error: 51.3789\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:56:52,109] Trial 48 finished with value: 37.68274364722968 and parameters: {'layer_1': 5, 'layer_2': 5, 'layer_3': 7, 'learning_rate': 0.02017343080436266, 'dropout_rate': 0.21745001304567507, 'epoch': 33, 'batch_size': 69, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1682580992.0000 - mean_absolute_error: 3497.9434 - val_loss: 70001.7734 - val_mean_absolute_error: 214.6510\n",
      "Epoch 2/48\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 71727.3828 - mean_absolute_error: 215.1708 - val_loss: 70001.7734 - val_mean_absolute_error: 214.6510\n",
      "Epoch 3/48\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 68922.8750 - mean_absolute_error: 212.0175 - val_loss: 70001.7734 - val_mean_absolute_error: 214.6510\n",
      "Epoch 4/48\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - loss: 70164.8125 - mean_absolute_error: 212.8170 - val_loss: 70001.7734 - val_mean_absolute_error: 214.6510\n",
      "Epoch 5/48\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - loss: 70952.6797 - mean_absolute_error: 212.7305 - val_loss: 70001.7734 - val_mean_absolute_error: 214.6510\n",
      "Epoch 6/48\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 71103.6172 - mean_absolute_error: 211.9887 - val_loss: 70001.7734 - val_mean_absolute_error: 214.6510\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:56:53,773] Trial 49 finished with value: 215.42847832031254 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 6, 'learning_rate': 0.0057567107847183155, 'dropout_rate': 0.35157806789025275, 'epoch': 48, 'batch_size': 36, 'optimizer': 'SGD'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 72178.5625 - mean_absolute_error: 214.1742 - val_loss: 69880.1406 - val_mean_absolute_error: 214.4946\n",
      "Epoch 2/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73637.8906 - mean_absolute_error: 216.5248 - val_loss: 69879.8672 - val_mean_absolute_error: 214.4940\n",
      "Epoch 3/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72788.4375 - mean_absolute_error: 215.5568 - val_loss: 69879.5781 - val_mean_absolute_error: 214.4935\n",
      "Epoch 4/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72078.9453 - mean_absolute_error: 214.5211 - val_loss: 69879.3047 - val_mean_absolute_error: 214.4930\n",
      "Epoch 5/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71717.6094 - mean_absolute_error: 214.4440 - val_loss: 69879.0391 - val_mean_absolute_error: 214.4924\n",
      "Epoch 6/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74690.1406 - mean_absolute_error: 217.9019 - val_loss: 69878.8125 - val_mean_absolute_error: 214.4919\n",
      "Epoch 7/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74713.2422 - mean_absolute_error: 215.7984 - val_loss: 69878.5703 - val_mean_absolute_error: 214.4914\n",
      "Epoch 8/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 69381.6641 - mean_absolute_error: 214.5426 - val_loss: 69878.3203 - val_mean_absolute_error: 214.4909\n",
      "Epoch 9/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 74353.1016 - mean_absolute_error: 218.1570 - val_loss: 69878.0625 - val_mean_absolute_error: 214.4904\n",
      "Epoch 10/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70415.0781 - mean_absolute_error: 212.5560 - val_loss: 69877.8281 - val_mean_absolute_error: 214.4899\n",
      "Epoch 11/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73150.2188 - mean_absolute_error: 216.2420 - val_loss: 69877.5938 - val_mean_absolute_error: 214.4894\n",
      "Epoch 12/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72088.4609 - mean_absolute_error: 216.0031 - val_loss: 69877.3438 - val_mean_absolute_error: 214.4888\n",
      "Epoch 13/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70619.4844 - mean_absolute_error: 212.4981 - val_loss: 69877.1406 - val_mean_absolute_error: 214.4884\n",
      "Epoch 14/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68894.6172 - mean_absolute_error: 210.7469 - val_loss: 69876.9141 - val_mean_absolute_error: 214.4879\n",
      "Epoch 15/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67639.5078 - mean_absolute_error: 210.5323 - val_loss: 69876.6719 - val_mean_absolute_error: 214.4874\n",
      "Epoch 16/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69898.2891 - mean_absolute_error: 213.2046 - val_loss: 69876.4453 - val_mean_absolute_error: 214.4869\n",
      "Epoch 17/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73386.3750 - mean_absolute_error: 215.1490 - val_loss: 69876.2188 - val_mean_absolute_error: 214.4864\n",
      "Epoch 18/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73933.3359 - mean_absolute_error: 217.1627 - val_loss: 69875.9922 - val_mean_absolute_error: 214.4859\n",
      "Epoch 19/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68345.2969 - mean_absolute_error: 212.5559 - val_loss: 69875.7422 - val_mean_absolute_error: 214.4853\n",
      "Epoch 20/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71368.1641 - mean_absolute_error: 213.4534 - val_loss: 69875.4766 - val_mean_absolute_error: 214.4847\n",
      "Epoch 21/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73088.0547 - mean_absolute_error: 216.3282 - val_loss: 69875.2422 - val_mean_absolute_error: 214.4842\n",
      "Epoch 22/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73523.5000 - mean_absolute_error: 215.8322 - val_loss: 69874.9922 - val_mean_absolute_error: 214.4837\n",
      "Epoch 23/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72668.7344 - mean_absolute_error: 216.2521 - val_loss: 69874.7422 - val_mean_absolute_error: 214.4832\n",
      "Epoch 24/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70672.4375 - mean_absolute_error: 215.6675 - val_loss: 69874.4844 - val_mean_absolute_error: 214.4826\n",
      "Epoch 25/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73808.3203 - mean_absolute_error: 216.6799 - val_loss: 69874.2266 - val_mean_absolute_error: 214.4821\n",
      "Epoch 26/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70066.0156 - mean_absolute_error: 213.2203 - val_loss: 69873.9453 - val_mean_absolute_error: 214.4815\n",
      "Epoch 27/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73670.4609 - mean_absolute_error: 215.5496 - val_loss: 69873.6875 - val_mean_absolute_error: 214.4809\n",
      "Epoch 28/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73111.8828 - mean_absolute_error: 216.8582 - val_loss: 69873.4141 - val_mean_absolute_error: 214.4803\n",
      "Epoch 29/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72135.8516 - mean_absolute_error: 216.9676 - val_loss: 69873.1484 - val_mean_absolute_error: 214.4798\n",
      "Epoch 30/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72539.6094 - mean_absolute_error: 217.0654 - val_loss: 69872.8750 - val_mean_absolute_error: 214.4792\n",
      "Epoch 31/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71680.4219 - mean_absolute_error: 213.2829 - val_loss: 69872.6094 - val_mean_absolute_error: 214.4786\n",
      "Epoch 32/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 76732.7734 - mean_absolute_error: 218.7397 - val_loss: 69872.3359 - val_mean_absolute_error: 214.4780\n",
      "Epoch 33/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71857.2422 - mean_absolute_error: 213.0454 - val_loss: 69872.0625 - val_mean_absolute_error: 214.4774\n",
      "Epoch 34/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70524.8203 - mean_absolute_error: 213.2209 - val_loss: 69871.7812 - val_mean_absolute_error: 214.4768\n",
      "Epoch 35/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74792.6016 - mean_absolute_error: 218.1340 - val_loss: 69871.4688 - val_mean_absolute_error: 214.4762\n",
      "Epoch 36/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73962.9453 - mean_absolute_error: 216.7156 - val_loss: 69871.1875 - val_mean_absolute_error: 214.4756\n",
      "Epoch 37/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 74606.1328 - mean_absolute_error: 219.0189 - val_loss: 69870.9219 - val_mean_absolute_error: 214.4750\n",
      "Epoch 38/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 69433.1250 - mean_absolute_error: 211.8900 - val_loss: 69870.6484 - val_mean_absolute_error: 214.4744\n",
      "Epoch 39/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 74650.6562 - mean_absolute_error: 217.1849 - val_loss: 69870.3828 - val_mean_absolute_error: 214.4738\n",
      "Epoch 40/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75414.1719 - mean_absolute_error: 216.5846 - val_loss: 69870.1016 - val_mean_absolute_error: 214.4732\n",
      "Epoch 41/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71301.3047 - mean_absolute_error: 215.2065 - val_loss: 69869.8125 - val_mean_absolute_error: 214.4726\n",
      "Epoch 42/42\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72144.7188 - mean_absolute_error: 215.4297 - val_loss: 69869.5312 - val_mean_absolute_error: 214.4720\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:56:59,052] Trial 50 finished with value: 215.23529371428518 and parameters: {'layer_1': 7, 'layer_2': 7, 'layer_3': 3, 'learning_rate': 0.001643593467521958, 'dropout_rate': 0.43690163193457626, 'epoch': 42, 'batch_size': 88, 'optimizer': 'Adadelta'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 26443.0645 - mean_absolute_error: 106.1136 - val_loss: 4635.0806 - val_mean_absolute_error: 49.2358\n",
      "Epoch 2/45\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6303.9688 - mean_absolute_error: 47.0391 - val_loss: 2007.6384 - val_mean_absolute_error: 26.1392\n",
      "Epoch 3/45\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4621.2095 - mean_absolute_error: 36.4687 - val_loss: 3166.7314 - val_mean_absolute_error: 35.9627\n",
      "Epoch 4/45\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6023.4863 - mean_absolute_error: 44.3232 - val_loss: 2141.7051 - val_mean_absolute_error: 26.1910\n",
      "Epoch 5/45\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5580.4541 - mean_absolute_error: 43.9987 - val_loss: 1801.8541 - val_mean_absolute_error: 24.2613\n",
      "Epoch 6/45\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4633.6616 - mean_absolute_error: 38.3930 - val_loss: 1759.8032 - val_mean_absolute_error: 23.7178\n",
      "Epoch 7/45\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5462.8823 - mean_absolute_error: 33.7130 - val_loss: 2173.0251 - val_mean_absolute_error: 27.1163\n",
      "Epoch 8/45\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3967.5110 - mean_absolute_error: 33.3621 - val_loss: 1803.2433 - val_mean_absolute_error: 23.0721\n",
      "Epoch 9/45\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4098.0327 - mean_absolute_error: 34.7754 - val_loss: 2094.6760 - val_mean_absolute_error: 27.2695\n",
      "Epoch 10/45\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4243.4258 - mean_absolute_error: 34.7377 - val_loss: 3305.1389 - val_mean_absolute_error: 37.7043\n",
      "Epoch 11/45\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3629.5432 - mean_absolute_error: 34.3573 - val_loss: 10879.5850 - val_mean_absolute_error: 69.5500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:57:01,231] Trial 51 finished with value: 24.632444705960154 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 6, 'learning_rate': 0.09865246321447399, 'dropout_rate': 0.003668277383521386, 'epoch': 45, 'batch_size': 96, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 37932.4531 - mean_absolute_error: 141.9638 - val_loss: 5299.9609 - val_mean_absolute_error: 54.0269\n",
      "Epoch 2/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13127.6270 - mean_absolute_error: 49.7657 - val_loss: 2513.2720 - val_mean_absolute_error: 30.8766\n",
      "Epoch 3/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4657.4834 - mean_absolute_error: 37.6676 - val_loss: 1974.1737 - val_mean_absolute_error: 25.3489\n",
      "Epoch 4/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5756.9326 - mean_absolute_error: 35.8819 - val_loss: 2323.8586 - val_mean_absolute_error: 27.7499\n",
      "Epoch 5/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3591.8062 - mean_absolute_error: 32.6920 - val_loss: 2124.7366 - val_mean_absolute_error: 30.4487\n",
      "Epoch 6/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3435.6648 - mean_absolute_error: 32.2314 - val_loss: 1797.7584 - val_mean_absolute_error: 23.7388\n",
      "Epoch 7/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5430.5957 - mean_absolute_error: 33.5992 - val_loss: 4064.7881 - val_mean_absolute_error: 40.4357\n",
      "Epoch 8/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3426.9387 - mean_absolute_error: 33.8088 - val_loss: 2188.4543 - val_mean_absolute_error: 28.4236\n",
      "Epoch 9/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4262.4482 - mean_absolute_error: 32.9703 - val_loss: 1694.4224 - val_mean_absolute_error: 22.4782\n",
      "Epoch 10/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4948.1372 - mean_absolute_error: 32.4095 - val_loss: 1628.4224 - val_mean_absolute_error: 21.4473\n",
      "Epoch 11/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3484.2214 - mean_absolute_error: 30.7924 - val_loss: 1647.8392 - val_mean_absolute_error: 22.1609\n",
      "Epoch 12/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4759.5674 - mean_absolute_error: 33.6283 - val_loss: 2055.3149 - val_mean_absolute_error: 25.5506\n",
      "Epoch 13/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4740.9673 - mean_absolute_error: 32.9016 - val_loss: 1709.7139 - val_mean_absolute_error: 22.1034\n",
      "Epoch 14/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3627.3757 - mean_absolute_error: 31.3990 - val_loss: 2806.6792 - val_mean_absolute_error: 33.6151\n",
      "Epoch 15/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3503.2942 - mean_absolute_error: 31.7975 - val_loss: 2722.1260 - val_mean_absolute_error: 32.6111\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:57:03,777] Trial 52 finished with value: 21.96745421690941 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 5, 'learning_rate': 0.027365619639353345, 'dropout_rate': 0.02040011053921895, 'epoch': 50, 'batch_size': 82, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 34382.8516 - mean_absolute_error: 125.8521 - val_loss: 4287.7681 - val_mean_absolute_error: 40.1624\n",
      "Epoch 2/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8409.3018 - mean_absolute_error: 54.6426 - val_loss: 2859.1255 - val_mean_absolute_error: 36.8559\n",
      "Epoch 3/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6810.5288 - mean_absolute_error: 48.9148 - val_loss: 1990.6735 - val_mean_absolute_error: 24.8033\n",
      "Epoch 4/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6847.6187 - mean_absolute_error: 48.8524 - val_loss: 3744.6765 - val_mean_absolute_error: 36.6749\n",
      "Epoch 5/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5964.2891 - mean_absolute_error: 45.1117 - val_loss: 1910.9462 - val_mean_absolute_error: 24.5976\n",
      "Epoch 6/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5735.7729 - mean_absolute_error: 46.9557 - val_loss: 3569.4792 - val_mean_absolute_error: 39.4031\n",
      "Epoch 7/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4966.5342 - mean_absolute_error: 43.5256 - val_loss: 5950.0728 - val_mean_absolute_error: 47.8428\n",
      "Epoch 8/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5999.6133 - mean_absolute_error: 45.3987 - val_loss: 1733.6547 - val_mean_absolute_error: 23.3690\n",
      "Epoch 9/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5372.1143 - mean_absolute_error: 44.0930 - val_loss: 3637.3779 - val_mean_absolute_error: 40.5291\n",
      "Epoch 10/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4586.4307 - mean_absolute_error: 42.2543 - val_loss: 2627.9695 - val_mean_absolute_error: 30.9644\n",
      "Epoch 11/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6717.8584 - mean_absolute_error: 47.1361 - val_loss: 2015.9006 - val_mean_absolute_error: 27.5807\n",
      "Epoch 12/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5675.2495 - mean_absolute_error: 44.0148 - val_loss: 1640.5226 - val_mean_absolute_error: 23.4918\n",
      "Epoch 13/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5438.1348 - mean_absolute_error: 43.1746 - val_loss: 8544.7373 - val_mean_absolute_error: 62.9756\n",
      "Epoch 14/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5939.7822 - mean_absolute_error: 44.8540 - val_loss: 1872.9001 - val_mean_absolute_error: 28.9445\n",
      "Epoch 15/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8110.8550 - mean_absolute_error: 46.6962 - val_loss: 7629.7837 - val_mean_absolute_error: 54.7027\n",
      "Epoch 16/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5508.1016 - mean_absolute_error: 43.7649 - val_loss: 1815.9459 - val_mean_absolute_error: 25.4002\n",
      "Epoch 17/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5837.5967 - mean_absolute_error: 41.1743 - val_loss: 2332.0698 - val_mean_absolute_error: 29.7778\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:57:06,364] Trial 53 finished with value: 24.442138447540998 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 7, 'learning_rate': 0.04541322155264712, 'dropout_rate': 0.06624973582407657, 'epoch': 46, 'batch_size': 93, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 63646.3242 - mean_absolute_error: 199.9181 - val_loss: 12869.3535 - val_mean_absolute_error: 92.0897\n",
      "Epoch 2/43\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15951.8164 - mean_absolute_error: 85.5946 - val_loss: 6562.0010 - val_mean_absolute_error: 60.7587\n",
      "Epoch 3/43\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10345.2959 - mean_absolute_error: 58.5522 - val_loss: 4294.1914 - val_mean_absolute_error: 42.5917\n",
      "Epoch 4/43\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9597.2959 - mean_absolute_error: 44.5959 - val_loss: 3172.4390 - val_mean_absolute_error: 36.1206\n",
      "Epoch 5/43\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7223.7466 - mean_absolute_error: 42.2950 - val_loss: 2757.3953 - val_mean_absolute_error: 33.0464\n",
      "Epoch 6/43\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7366.4390 - mean_absolute_error: 40.5929 - val_loss: 2470.4707 - val_mean_absolute_error: 30.3184\n",
      "Epoch 7/43\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4705.3530 - mean_absolute_error: 35.6581 - val_loss: 2884.9585 - val_mean_absolute_error: 34.0743\n",
      "Epoch 8/43\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4961.0942 - mean_absolute_error: 34.5629 - val_loss: 2114.0354 - val_mean_absolute_error: 27.5618\n",
      "Epoch 9/43\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5642.1177 - mean_absolute_error: 35.3601 - val_loss: 2011.3124 - val_mean_absolute_error: 26.3016\n",
      "Epoch 10/43\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2580.0645 - mean_absolute_error: 29.6342 - val_loss: 1849.0867 - val_mean_absolute_error: 25.1521\n",
      "Epoch 11/43\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3690.0264 - mean_absolute_error: 30.0779 - val_loss: 1768.5597 - val_mean_absolute_error: 23.8130\n",
      "Epoch 12/43\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3807.3828 - mean_absolute_error: 29.9284 - val_loss: 1740.4956 - val_mean_absolute_error: 23.7101\n",
      "Epoch 13/43\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3778.2334 - mean_absolute_error: 28.9958 - val_loss: 1649.9194 - val_mean_absolute_error: 22.0839\n",
      "Epoch 14/43\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3724.3862 - mean_absolute_error: 29.0946 - val_loss: 1616.2366 - val_mean_absolute_error: 21.9666\n",
      "Epoch 15/43\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2710.8501 - mean_absolute_error: 27.9801 - val_loss: 1867.5414 - val_mean_absolute_error: 25.3430\n",
      "Epoch 16/43\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3233.7141 - mean_absolute_error: 28.9602 - val_loss: 1628.3109 - val_mean_absolute_error: 22.1171\n",
      "Epoch 17/43\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2522.7400 - mean_absolute_error: 27.1480 - val_loss: 1746.2467 - val_mean_absolute_error: 23.3261\n",
      "Epoch 18/43\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4109.0981 - mean_absolute_error: 29.8822 - val_loss: 1622.9017 - val_mean_absolute_error: 21.8263\n",
      "Epoch 19/43\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3679.3325 - mean_absolute_error: 29.5404 - val_loss: 1614.9358 - val_mean_absolute_error: 21.9712\n",
      "Epoch 20/43\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2705.3464 - mean_absolute_error: 28.0568 - val_loss: 1784.2592 - val_mean_absolute_error: 24.3031\n",
      "Epoch 21/43\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2830.3352 - mean_absolute_error: 27.2995 - val_loss: 3188.4958 - val_mean_absolute_error: 37.9487\n",
      "Epoch 22/43\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2794.3970 - mean_absolute_error: 28.1535 - val_loss: 1805.0343 - val_mean_absolute_error: 23.8893\n",
      "Epoch 23/43\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2414.6741 - mean_absolute_error: 26.8682 - val_loss: 1616.6525 - val_mean_absolute_error: 21.7837\n",
      "Epoch 24/43\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2689.8167 - mean_absolute_error: 27.6469 - val_loss: 2056.7815 - val_mean_absolute_error: 26.2098\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:57:09,727] Trial 54 finished with value: 22.46885710977316 and parameters: {'layer_1': 8, 'layer_2': 7, 'layer_3': 6, 'learning_rate': 0.013641225313866103, 'dropout_rate': 0.013688473876476225, 'epoch': 43, 'batch_size': 96, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4096/4096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 660us/step - loss: 35919.2539 - mean_absolute_error: 72.0720 - val_loss: 1662.9943 - val_mean_absolute_error: 22.5793\n",
      "Epoch 2/38\n",
      "\u001b[1m4096/4096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 617us/step - loss: 6410.5278 - mean_absolute_error: 38.0115 - val_loss: 2124.6848 - val_mean_absolute_error: 26.8331\n",
      "Epoch 3/38\n",
      "\u001b[1m4096/4096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 620us/step - loss: 17081.7695 - mean_absolute_error: 36.5166 - val_loss: 2060.3679 - val_mean_absolute_error: 25.1996\n",
      "Epoch 4/38\n",
      "\u001b[1m4096/4096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 631us/step - loss: 5513.8164 - mean_absolute_error: 36.6866 - val_loss: 1799.8411 - val_mean_absolute_error: 23.7484\n",
      "Epoch 5/38\n",
      "\u001b[1m4096/4096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 635us/step - loss: 5472.0493 - mean_absolute_error: 36.7177 - val_loss: 1692.6554 - val_mean_absolute_error: 22.7586\n",
      "Epoch 6/38\n",
      "\u001b[1m4096/4096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 622us/step - loss: 3283.4519 - mean_absolute_error: 34.1667 - val_loss: 2026.5146 - val_mean_absolute_error: 26.0941\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:57:26,276] Trial 55 finished with value: 24.614098074468973 and parameters: {'layer_1': 7, 'layer_2': 8, 'layer_3': 7, 'learning_rate': 0.010283126845798641, 'dropout_rate': 0.03986888836003874, 'epoch': 38, 'batch_size': 1, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 72387.4609 - mean_absolute_error: 215.1385 - val_loss: 69775.6484 - val_mean_absolute_error: 214.3279\n",
      "Epoch 2/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71961.8125 - mean_absolute_error: 213.4663 - val_loss: 69734.5234 - val_mean_absolute_error: 214.2671\n",
      "Epoch 3/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73587.0391 - mean_absolute_error: 217.4066 - val_loss: 69702.6953 - val_mean_absolute_error: 214.2200\n",
      "Epoch 4/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67578.3594 - mean_absolute_error: 209.1475 - val_loss: 69674.5000 - val_mean_absolute_error: 214.1783\n",
      "Epoch 5/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71406.3125 - mean_absolute_error: 214.6666 - val_loss: 69649.1797 - val_mean_absolute_error: 214.1410\n",
      "Epoch 6/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72952.7656 - mean_absolute_error: 216.6877 - val_loss: 69626.1406 - val_mean_absolute_error: 214.1070\n",
      "Epoch 7/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70640.6328 - mean_absolute_error: 212.4574 - val_loss: 69605.7422 - val_mean_absolute_error: 214.0765\n",
      "Epoch 8/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69509.1328 - mean_absolute_error: 210.8925 - val_loss: 69585.7891 - val_mean_absolute_error: 214.0469\n",
      "Epoch 9/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72827.1875 - mean_absolute_error: 217.5739 - val_loss: 69566.6641 - val_mean_absolute_error: 214.0186\n",
      "Epoch 10/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71796.7812 - mean_absolute_error: 215.2841 - val_loss: 69548.6953 - val_mean_absolute_error: 213.9917\n",
      "Epoch 11/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70859.7812 - mean_absolute_error: 214.0156 - val_loss: 69531.2344 - val_mean_absolute_error: 213.9657\n",
      "Epoch 12/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71510.6172 - mean_absolute_error: 214.0733 - val_loss: 69513.8984 - val_mean_absolute_error: 213.9400\n",
      "Epoch 13/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73437.9688 - mean_absolute_error: 215.6620 - val_loss: 69497.4453 - val_mean_absolute_error: 213.9154\n",
      "Epoch 14/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68698.5703 - mean_absolute_error: 212.5941 - val_loss: 69480.7891 - val_mean_absolute_error: 213.8907\n",
      "Epoch 15/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72043.3672 - mean_absolute_error: 214.7984 - val_loss: 69464.9609 - val_mean_absolute_error: 213.8671\n",
      "Epoch 16/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69510.4688 - mean_absolute_error: 213.1236 - val_loss: 69449.3984 - val_mean_absolute_error: 213.8439\n",
      "Epoch 17/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72248.5156 - mean_absolute_error: 215.3985 - val_loss: 69434.0938 - val_mean_absolute_error: 213.8212\n",
      "Epoch 18/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73000.7109 - mean_absolute_error: 213.4745 - val_loss: 69419.0625 - val_mean_absolute_error: 213.7990\n",
      "Epoch 19/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72028.4141 - mean_absolute_error: 215.0080 - val_loss: 69404.2500 - val_mean_absolute_error: 213.7769\n",
      "Epoch 20/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73168.6797 - mean_absolute_error: 214.8895 - val_loss: 69389.4375 - val_mean_absolute_error: 213.7549\n",
      "Epoch 21/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71963.9531 - mean_absolute_error: 215.8569 - val_loss: 69374.8047 - val_mean_absolute_error: 213.7332\n",
      "Epoch 22/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70219.6250 - mean_absolute_error: 211.7308 - val_loss: 69360.1484 - val_mean_absolute_error: 213.7116\n",
      "Epoch 23/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74508.5078 - mean_absolute_error: 218.5506 - val_loss: 69345.6094 - val_mean_absolute_error: 213.6901\n",
      "Epoch 24/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70702.1875 - mean_absolute_error: 212.3604 - val_loss: 69331.0312 - val_mean_absolute_error: 213.6686\n",
      "Epoch 25/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72820.8516 - mean_absolute_error: 214.6962 - val_loss: 69316.9844 - val_mean_absolute_error: 213.6478\n",
      "Epoch 26/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73925.8828 - mean_absolute_error: 216.2157 - val_loss: 69303.3047 - val_mean_absolute_error: 213.6274\n",
      "Epoch 27/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71057.2422 - mean_absolute_error: 214.6170 - val_loss: 69289.2031 - val_mean_absolute_error: 213.6066\n",
      "Epoch 28/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71143.1328 - mean_absolute_error: 214.3244 - val_loss: 69275.4766 - val_mean_absolute_error: 213.5861\n",
      "Epoch 29/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71302.5938 - mean_absolute_error: 213.7155 - val_loss: 69261.7031 - val_mean_absolute_error: 213.5657\n",
      "Epoch 30/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71011.6953 - mean_absolute_error: 214.1182 - val_loss: 69247.5781 - val_mean_absolute_error: 213.5449\n",
      "Epoch 31/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70304.2188 - mean_absolute_error: 212.8801 - val_loss: 69233.7344 - val_mean_absolute_error: 213.5244\n",
      "Epoch 32/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71630.1016 - mean_absolute_error: 211.4125 - val_loss: 69220.0547 - val_mean_absolute_error: 213.5041\n",
      "Epoch 33/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69930.4219 - mean_absolute_error: 214.7534 - val_loss: 69205.8203 - val_mean_absolute_error: 213.4833\n",
      "Epoch 34/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71161.3438 - mean_absolute_error: 212.2935 - val_loss: 69191.6250 - val_mean_absolute_error: 213.4625\n",
      "Epoch 35/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71313.7969 - mean_absolute_error: 213.5885 - val_loss: 69178.0000 - val_mean_absolute_error: 213.4424\n",
      "Epoch 36/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71384.4141 - mean_absolute_error: 215.4228 - val_loss: 69164.1250 - val_mean_absolute_error: 213.4221\n",
      "Epoch 37/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74561.3359 - mean_absolute_error: 216.4718 - val_loss: 69150.0703 - val_mean_absolute_error: 213.4015\n",
      "Epoch 38/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70826.1484 - mean_absolute_error: 212.6604 - val_loss: 69135.9219 - val_mean_absolute_error: 213.3810\n",
      "Epoch 39/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72605.3359 - mean_absolute_error: 214.5276 - val_loss: 69121.8906 - val_mean_absolute_error: 213.3604\n",
      "Epoch 40/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72367.8047 - mean_absolute_error: 215.7604 - val_loss: 69107.6875 - val_mean_absolute_error: 213.3398\n",
      "Epoch 41/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72733.6406 - mean_absolute_error: 216.0627 - val_loss: 69093.3125 - val_mean_absolute_error: 213.3190\n",
      "Epoch 42/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70022.9375 - mean_absolute_error: 211.8982 - val_loss: 69079.0156 - val_mean_absolute_error: 213.2983\n",
      "Epoch 43/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72229.9688 - mean_absolute_error: 216.2446 - val_loss: 69065.2109 - val_mean_absolute_error: 213.2782\n",
      "Epoch 44/44\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 69702.2812 - mean_absolute_error: 211.8826 - val_loss: 69050.8516 - val_mean_absolute_error: 213.2575\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:57:31,499] Trial 56 finished with value: 214.0438019387569 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 5, 'learning_rate': 0.0007761212053683241, 'dropout_rate': 0.10518146181352406, 'epoch': 44, 'batch_size': 83, 'optimizer': 'Adagrad'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 72757.2422 - mean_absolute_error: 215.5359 - val_loss: 68963.4688 - val_mean_absolute_error: 212.8531\n",
      "Epoch 2/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73292.9375 - mean_absolute_error: 216.3516 - val_loss: 65493.7266 - val_mean_absolute_error: 207.7018\n",
      "Epoch 3/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66989.2031 - mean_absolute_error: 205.6692 - val_loss: 57674.3516 - val_mean_absolute_error: 196.3808\n",
      "Epoch 4/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57650.5859 - mean_absolute_error: 193.2618 - val_loss: 44951.0781 - val_mean_absolute_error: 176.9469\n",
      "Epoch 5/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 43187.2734 - mean_absolute_error: 171.0964 - val_loss: 30560.5762 - val_mean_absolute_error: 149.7859\n",
      "Epoch 6/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 29673.6582 - mean_absolute_error: 143.9442 - val_loss: 19915.3594 - val_mean_absolute_error: 121.6102\n",
      "Epoch 7/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22274.9863 - mean_absolute_error: 121.9332 - val_loss: 16113.4922 - val_mean_absolute_error: 107.4115\n",
      "Epoch 8/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22564.4727 - mean_absolute_error: 113.5968 - val_loss: 14411.2314 - val_mean_absolute_error: 101.2717\n",
      "Epoch 9/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19800.9902 - mean_absolute_error: 103.5945 - val_loss: 12083.9443 - val_mean_absolute_error: 90.8346\n",
      "Epoch 10/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17786.8086 - mean_absolute_error: 95.7563 - val_loss: 10033.7695 - val_mean_absolute_error: 80.6785\n",
      "Epoch 11/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14967.5049 - mean_absolute_error: 84.9373 - val_loss: 8242.8574 - val_mean_absolute_error: 70.5217\n",
      "Epoch 12/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12500.4453 - mean_absolute_error: 74.6888 - val_loss: 6715.3770 - val_mean_absolute_error: 60.6099\n",
      "Epoch 13/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11025.4512 - mean_absolute_error: 68.4122 - val_loss: 6089.8750 - val_mean_absolute_error: 56.9683\n",
      "Epoch 14/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10328.3535 - mean_absolute_error: 64.7197 - val_loss: 5515.0430 - val_mean_absolute_error: 52.5777\n",
      "Epoch 15/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11591.2715 - mean_absolute_error: 65.7941 - val_loss: 5250.1196 - val_mean_absolute_error: 50.4851\n",
      "Epoch 16/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9271.9443 - mean_absolute_error: 60.8310 - val_loss: 5066.3560 - val_mean_absolute_error: 49.1159\n",
      "Epoch 17/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10925.7041 - mean_absolute_error: 61.5764 - val_loss: 4805.8896 - val_mean_absolute_error: 47.1834\n",
      "Epoch 18/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11602.0020 - mean_absolute_error: 61.9967 - val_loss: 4607.6660 - val_mean_absolute_error: 45.4435\n",
      "Epoch 19/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10773.7871 - mean_absolute_error: 60.1197 - val_loss: 4656.3120 - val_mean_absolute_error: 45.9939\n",
      "Epoch 20/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11094.4854 - mean_absolute_error: 60.6069 - val_loss: 4739.1055 - val_mean_absolute_error: 46.6477\n",
      "Epoch 21/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9865.5586 - mean_absolute_error: 58.7195 - val_loss: 4556.1538 - val_mean_absolute_error: 45.4587\n",
      "Epoch 22/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8488.3975 - mean_absolute_error: 59.0196 - val_loss: 4613.0640 - val_mean_absolute_error: 45.8463\n",
      "Epoch 23/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8292.5029 - mean_absolute_error: 56.8866 - val_loss: 4549.9863 - val_mean_absolute_error: 45.4292\n",
      "Epoch 24/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10433.3047 - mean_absolute_error: 59.5381 - val_loss: 4397.5845 - val_mean_absolute_error: 44.3645\n",
      "Epoch 25/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9378.0898 - mean_absolute_error: 58.8676 - val_loss: 4380.6826 - val_mean_absolute_error: 44.2804\n",
      "Epoch 26/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7334.6846 - mean_absolute_error: 55.6383 - val_loss: 4583.5459 - val_mean_absolute_error: 45.5783\n",
      "Epoch 27/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9049.1797 - mean_absolute_error: 57.0558 - val_loss: 4425.3169 - val_mean_absolute_error: 44.6754\n",
      "Epoch 28/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10072.8984 - mean_absolute_error: 60.6522 - val_loss: 4527.4165 - val_mean_absolute_error: 45.3508\n",
      "Epoch 29/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9015.8223 - mean_absolute_error: 57.6215 - val_loss: 4452.8457 - val_mean_absolute_error: 44.8909\n",
      "Epoch 30/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7725.2964 - mean_absolute_error: 55.6434 - val_loss: 4101.6597 - val_mean_absolute_error: 42.1281\n",
      "Epoch 31/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8490.9160 - mean_absolute_error: 55.8089 - val_loss: 4346.5200 - val_mean_absolute_error: 44.0561\n",
      "Epoch 32/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8067.1860 - mean_absolute_error: 54.7731 - val_loss: 4184.2695 - val_mean_absolute_error: 43.0858\n",
      "Epoch 33/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9120.5195 - mean_absolute_error: 57.6163 - val_loss: 4297.7402 - val_mean_absolute_error: 44.0465\n",
      "Epoch 34/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8697.6621 - mean_absolute_error: 57.0756 - val_loss: 4117.0083 - val_mean_absolute_error: 42.8190\n",
      "Epoch 35/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9866.5693 - mean_absolute_error: 58.2066 - val_loss: 4101.1958 - val_mean_absolute_error: 42.8749\n",
      "Epoch 36/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9035.8281 - mean_absolute_error: 56.1905 - val_loss: 4267.3218 - val_mean_absolute_error: 44.1604\n",
      "Epoch 37/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8962.9307 - mean_absolute_error: 56.7654 - val_loss: 4037.7188 - val_mean_absolute_error: 42.5489\n",
      "Epoch 38/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7673.0405 - mean_absolute_error: 55.2387 - val_loss: 3907.8025 - val_mean_absolute_error: 41.4494\n",
      "Epoch 39/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7114.7812 - mean_absolute_error: 54.4616 - val_loss: 4216.0630 - val_mean_absolute_error: 43.9034\n",
      "Epoch 40/40\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9431.9463 - mean_absolute_error: 56.7536 - val_loss: 4111.1699 - val_mean_absolute_error: 43.1151\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:57:35,916] Trial 57 finished with value: 41.32306341443062 and parameters: {'layer_1': 4, 'layer_2': 7, 'layer_3': 7, 'learning_rate': 0.002687033040701287, 'dropout_rate': 0.08289045192758274, 'epoch': 40, 'batch_size': 90, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 31069.5176 - mean_absolute_error: 114.2537 - val_loss: 2497.1497 - val_mean_absolute_error: 30.9118\n",
      "Epoch 2/47\n",
      "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - loss: 7035.2583 - mean_absolute_error: 41.5638 - val_loss: 9671.6484 - val_mean_absolute_error: 78.0787\n",
      "Epoch 3/47\n",
      "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 5048.1577 - mean_absolute_error: 41.5578 - val_loss: 2424.1326 - val_mean_absolute_error: 30.4597\n",
      "Epoch 4/47\n",
      "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 3935.4141 - mean_absolute_error: 36.1366 - val_loss: 2133.0386 - val_mean_absolute_error: 27.5040\n",
      "Epoch 5/47\n",
      "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 3935.1206 - mean_absolute_error: 34.1742 - val_loss: 2970.9192 - val_mean_absolute_error: 33.8608\n",
      "Epoch 6/47\n",
      "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 4670.6982 - mean_absolute_error: 36.1273 - val_loss: 1893.0408 - val_mean_absolute_error: 27.2823\n",
      "Epoch 7/47\n",
      "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 3144.8030 - mean_absolute_error: 32.9150 - val_loss: 1861.7454 - val_mean_absolute_error: 26.7451\n",
      "Epoch 8/47\n",
      "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 4630.6436 - mean_absolute_error: 35.0498 - val_loss: 1825.7286 - val_mean_absolute_error: 24.8278\n",
      "Epoch 9/47\n",
      "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 3926.5068 - mean_absolute_error: 32.9468 - val_loss: 1802.1554 - val_mean_absolute_error: 24.3363\n",
      "Epoch 10/47\n",
      "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 4325.0151 - mean_absolute_error: 35.9704 - val_loss: 1737.3564 - val_mean_absolute_error: 24.3274\n",
      "Epoch 11/47\n",
      "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 3872.4165 - mean_absolute_error: 33.8465 - val_loss: 2168.8347 - val_mean_absolute_error: 27.4824\n",
      "Epoch 12/47\n",
      "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 4343.5713 - mean_absolute_error: 34.3838 - val_loss: 2667.4343 - val_mean_absolute_error: 33.6328\n",
      "Epoch 13/47\n",
      "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 3505.9033 - mean_absolute_error: 33.6730 - val_loss: 2052.7366 - val_mean_absolute_error: 26.5173\n",
      "Epoch 14/47\n",
      "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 3483.1807 - mean_absolute_error: 33.7318 - val_loss: 1658.4906 - val_mean_absolute_error: 23.2739\n",
      "Epoch 15/47\n",
      "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 3310.2798 - mean_absolute_error: 32.2000 - val_loss: 2476.5786 - val_mean_absolute_error: 30.9117\n",
      "Epoch 16/47\n",
      "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 2835.7942 - mean_absolute_error: 31.5446 - val_loss: 1647.2102 - val_mean_absolute_error: 22.6012\n",
      "Epoch 17/47\n",
      "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 3298.7778 - mean_absolute_error: 31.2765 - val_loss: 2349.3931 - val_mean_absolute_error: 29.9314\n",
      "Epoch 18/47\n",
      "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 3994.6848 - mean_absolute_error: 34.7716 - val_loss: 2770.1333 - val_mean_absolute_error: 32.8956\n",
      "Epoch 19/47\n",
      "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 3465.8870 - mean_absolute_error: 33.9545 - val_loss: 1673.7301 - val_mean_absolute_error: 23.6129\n",
      "Epoch 20/47\n",
      "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 3098.0212 - mean_absolute_error: 32.1206 - val_loss: 1907.3333 - val_mean_absolute_error: 26.5499\n",
      "Epoch 21/47\n",
      "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 3574.0376 - mean_absolute_error: 33.8082 - val_loss: 2049.7617 - val_mean_absolute_error: 26.6011\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:57:43,048] Trial 58 finished with value: 23.727919556254147 and parameters: {'layer_1': 6, 'layer_2': 6, 'layer_3': 6, 'learning_rate': 0.017055783145226846, 'dropout_rate': 0.0206022724007438, 'epoch': 47, 'batch_size': 12, 'optimizer': 'Adam'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 72865.1719 - mean_absolute_error: 213.9445 - val_loss: 37071.8633 - val_mean_absolute_error: 151.9938\n",
      "Epoch 2/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 47355.4844 - mean_absolute_error: 152.0104 - val_loss: 19455.7363 - val_mean_absolute_error: 111.0707\n",
      "Epoch 3/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32193.1465 - mean_absolute_error: 128.6476 - val_loss: 15473.0137 - val_mean_absolute_error: 95.0188\n",
      "Epoch 4/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28607.8691 - mean_absolute_error: 114.8238 - val_loss: 12804.8994 - val_mean_absolute_error: 83.2248\n",
      "Epoch 5/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26810.4883 - mean_absolute_error: 112.1311 - val_loss: 12215.6982 - val_mean_absolute_error: 82.0068\n",
      "Epoch 6/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 29830.7949 - mean_absolute_error: 116.6384 - val_loss: 9185.7227 - val_mean_absolute_error: 69.8020\n",
      "Epoch 7/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30517.6387 - mean_absolute_error: 109.5729 - val_loss: 10627.1445 - val_mean_absolute_error: 74.4661\n",
      "Epoch 8/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25530.4805 - mean_absolute_error: 104.9987 - val_loss: 11610.6143 - val_mean_absolute_error: 77.8978\n",
      "Epoch 9/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24744.8066 - mean_absolute_error: 108.1506 - val_loss: 8787.7500 - val_mean_absolute_error: 67.4813\n",
      "Epoch 10/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26715.1777 - mean_absolute_error: 105.5634 - val_loss: 10186.5059 - val_mean_absolute_error: 71.9621\n",
      "Epoch 11/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23500.0996 - mean_absolute_error: 103.1042 - val_loss: 8906.1855 - val_mean_absolute_error: 67.1286\n",
      "Epoch 12/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22899.1250 - mean_absolute_error: 102.7179 - val_loss: 10436.6104 - val_mean_absolute_error: 74.2246\n",
      "Epoch 13/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23236.2266 - mean_absolute_error: 104.2317 - val_loss: 9487.5791 - val_mean_absolute_error: 70.5604\n",
      "Epoch 14/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23891.0820 - mean_absolute_error: 103.7307 - val_loss: 9147.3369 - val_mean_absolute_error: 69.5346\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:57:45,750] Trial 59 finished with value: 68.77636137737036 and parameters: {'layer_1': 7, 'layer_2': 8, 'layer_3': 8, 'learning_rate': 0.008258671245298181, 'dropout_rate': 0.49465569183665675, 'epoch': 49, 'batch_size': 98, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 59418.6914 - mean_absolute_error: 190.8530 - val_loss: 11802.5830 - val_mean_absolute_error: 84.2124\n",
      "Epoch 2/27\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 21749.5215 - mean_absolute_error: 92.1794 - val_loss: 5370.2510 - val_mean_absolute_error: 51.0152\n",
      "Epoch 3/27\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 15558.0020 - mean_absolute_error: 77.9772 - val_loss: 4304.5391 - val_mean_absolute_error: 45.7321\n",
      "Epoch 4/27\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - loss: 14993.9746 - mean_absolute_error: 75.1574 - val_loss: 3573.0732 - val_mean_absolute_error: 40.6693\n",
      "Epoch 5/27\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 15027.0146 - mean_absolute_error: 71.1885 - val_loss: 3411.5298 - val_mean_absolute_error: 40.7689\n",
      "Epoch 6/27\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 15284.4258 - mean_absolute_error: 71.7940 - val_loss: 3351.0664 - val_mean_absolute_error: 39.7504\n",
      "Epoch 7/27\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 11164.5508 - mean_absolute_error: 67.3746 - val_loss: 3459.7256 - val_mean_absolute_error: 39.0091\n",
      "Epoch 8/27\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 17384.1719 - mean_absolute_error: 69.8349 - val_loss: 2759.2102 - val_mean_absolute_error: 34.4620\n",
      "Epoch 9/27\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 11626.7061 - mean_absolute_error: 65.1421 - val_loss: 3600.2803 - val_mean_absolute_error: 40.1560\n",
      "Epoch 10/27\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 14702.4277 - mean_absolute_error: 68.0309 - val_loss: 3330.4634 - val_mean_absolute_error: 38.4706\n",
      "Epoch 11/27\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 12804.6230 - mean_absolute_error: 68.2084 - val_loss: 3506.9146 - val_mean_absolute_error: 38.8015\n",
      "Epoch 12/27\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 10579.8926 - mean_absolute_error: 63.2710 - val_loss: 3109.7883 - val_mean_absolute_error: 37.7483\n",
      "Epoch 13/27\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - loss: 10836.8936 - mean_absolute_error: 63.0396 - val_loss: 3179.7234 - val_mean_absolute_error: 37.6312\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:57:49,229] Trial 60 finished with value: 34.7420947384119 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 2, 'learning_rate': 0.005130586136519822, 'dropout_rate': 0.15253106608515338, 'epoch': 27, 'batch_size': 19, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 72957.2266 - mean_absolute_error: 215.2197 - val_loss: 63422.0508 - val_mean_absolute_error: 198.4293\n",
      "Epoch 2/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 60285.6562 - mean_absolute_error: 186.8957 - val_loss: 32616.6250 - val_mean_absolute_error: 139.2698\n",
      "Epoch 3/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28646.4824 - mean_absolute_error: 125.4381 - val_loss: 12341.7012 - val_mean_absolute_error: 88.2673\n",
      "Epoch 4/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19634.8691 - mean_absolute_error: 86.5406 - val_loss: 7867.7773 - val_mean_absolute_error: 67.5452\n",
      "Epoch 5/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11654.3359 - mean_absolute_error: 64.4378 - val_loss: 5269.5127 - val_mean_absolute_error: 50.6798\n",
      "Epoch 6/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12052.4883 - mean_absolute_error: 51.0657 - val_loss: 3964.7041 - val_mean_absolute_error: 42.3782\n",
      "Epoch 7/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5886.9468 - mean_absolute_error: 41.6709 - val_loss: 3239.5427 - val_mean_absolute_error: 37.1465\n",
      "Epoch 8/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5303.1128 - mean_absolute_error: 37.5463 - val_loss: 2913.1697 - val_mean_absolute_error: 35.5407\n",
      "Epoch 9/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5664.7378 - mean_absolute_error: 34.9736 - val_loss: 2470.7612 - val_mean_absolute_error: 31.4559\n",
      "Epoch 10/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5224.9263 - mean_absolute_error: 33.1953 - val_loss: 2273.2266 - val_mean_absolute_error: 28.4679\n",
      "Epoch 11/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4553.2324 - mean_absolute_error: 30.4932 - val_loss: 2091.5925 - val_mean_absolute_error: 27.2559\n",
      "Epoch 12/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4412.0400 - mean_absolute_error: 30.1959 - val_loss: 1995.6234 - val_mean_absolute_error: 26.0932\n",
      "Epoch 13/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2946.3071 - mean_absolute_error: 27.4418 - val_loss: 1850.8431 - val_mean_absolute_error: 24.1881\n",
      "Epoch 14/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2900.8328 - mean_absolute_error: 25.7467 - val_loss: 1747.1211 - val_mean_absolute_error: 23.1267\n",
      "Epoch 15/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2359.5750 - mean_absolute_error: 24.6703 - val_loss: 1699.6637 - val_mean_absolute_error: 22.9488\n",
      "Epoch 16/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4083.7671 - mean_absolute_error: 26.4893 - val_loss: 1638.4515 - val_mean_absolute_error: 21.9980\n",
      "Epoch 17/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3704.7529 - mean_absolute_error: 25.9872 - val_loss: 1702.5980 - val_mean_absolute_error: 22.5097\n",
      "Epoch 18/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2304.8157 - mean_absolute_error: 22.5372 - val_loss: 1727.8901 - val_mean_absolute_error: 22.5792\n",
      "Epoch 19/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3119.0054 - mean_absolute_error: 24.0060 - val_loss: 1611.0453 - val_mean_absolute_error: 21.3119\n",
      "Epoch 20/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2721.5332 - mean_absolute_error: 24.0510 - val_loss: 1665.3153 - val_mean_absolute_error: 21.9413\n",
      "Epoch 21/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2115.9346 - mean_absolute_error: 22.8382 - val_loss: 1617.5872 - val_mean_absolute_error: 21.5473\n",
      "Epoch 22/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2820.5063 - mean_absolute_error: 23.6611 - val_loss: 1653.4124 - val_mean_absolute_error: 21.7066\n",
      "Epoch 23/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3343.1697 - mean_absolute_error: 23.9558 - val_loss: 1574.5504 - val_mean_absolute_error: 20.8272\n",
      "Epoch 24/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2205.9673 - mean_absolute_error: 22.6456 - val_loss: 1570.7836 - val_mean_absolute_error: 20.8971\n",
      "Epoch 25/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2470.9688 - mean_absolute_error: 22.2773 - val_loss: 1625.7589 - val_mean_absolute_error: 21.9768\n",
      "Epoch 26/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2876.1289 - mean_absolute_error: 23.7467 - val_loss: 1649.2180 - val_mean_absolute_error: 21.4575\n",
      "Epoch 27/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2107.0493 - mean_absolute_error: 22.8452 - val_loss: 1660.9246 - val_mean_absolute_error: 21.8182\n",
      "Epoch 28/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2399.8401 - mean_absolute_error: 22.9296 - val_loss: 1608.0040 - val_mean_absolute_error: 20.9812\n",
      "Epoch 29/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2800.5928 - mean_absolute_error: 22.9382 - val_loss: 1585.5306 - val_mean_absolute_error: 20.9499\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:57:52,927] Trial 61 finished with value: 21.377252429035305 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 8, 'learning_rate': 0.006458612312021911, 'dropout_rate': 0.003007715173194505, 'epoch': 50, 'batch_size': 94, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 72135.2656 - mean_absolute_error: 216.0384 - val_loss: 67919.1797 - val_mean_absolute_error: 211.7764\n",
      "Epoch 2/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67278.4062 - mean_absolute_error: 208.1077 - val_loss: 58489.8828 - val_mean_absolute_error: 199.3504\n",
      "Epoch 3/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56041.1094 - mean_absolute_error: 195.7512 - val_loss: 37888.7344 - val_mean_absolute_error: 167.8199\n",
      "Epoch 4/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 35236.5859 - mean_absolute_error: 160.4753 - val_loss: 21259.3945 - val_mean_absolute_error: 128.7090\n",
      "Epoch 5/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22882.8691 - mean_absolute_error: 125.5149 - val_loss: 17698.7871 - val_mean_absolute_error: 113.0585\n",
      "Epoch 6/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20719.0664 - mean_absolute_error: 113.7354 - val_loss: 15434.4902 - val_mean_absolute_error: 105.5640\n",
      "Epoch 7/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18953.4590 - mean_absolute_error: 105.3471 - val_loss: 12987.2393 - val_mean_absolute_error: 95.4764\n",
      "Epoch 8/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12824.5059 - mean_absolute_error: 89.5923 - val_loss: 10328.4248 - val_mean_absolute_error: 82.4084\n",
      "Epoch 9/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11351.4355 - mean_absolute_error: 78.6978 - val_loss: 7865.4502 - val_mean_absolute_error: 65.7271\n",
      "Epoch 10/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8145.1816 - mean_absolute_error: 59.8083 - val_loss: 5821.2598 - val_mean_absolute_error: 51.5914\n",
      "Epoch 11/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6740.0493 - mean_absolute_error: 48.8867 - val_loss: 5021.6211 - val_mean_absolute_error: 46.4740\n",
      "Epoch 12/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6385.4517 - mean_absolute_error: 45.3963 - val_loss: 4561.6772 - val_mean_absolute_error: 44.6157\n",
      "Epoch 13/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6154.9492 - mean_absolute_error: 42.4110 - val_loss: 4267.3799 - val_mean_absolute_error: 42.6781\n",
      "Epoch 14/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9545.9502 - mean_absolute_error: 43.7033 - val_loss: 4063.0596 - val_mean_absolute_error: 41.4625\n",
      "Epoch 15/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6184.9121 - mean_absolute_error: 41.3369 - val_loss: 3952.5537 - val_mean_absolute_error: 39.9431\n",
      "Epoch 16/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4737.5044 - mean_absolute_error: 39.1553 - val_loss: 3698.7380 - val_mean_absolute_error: 39.4098\n",
      "Epoch 17/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6285.2510 - mean_absolute_error: 39.9498 - val_loss: 3588.2419 - val_mean_absolute_error: 38.2343\n",
      "Epoch 18/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7629.1938 - mean_absolute_error: 39.8212 - val_loss: 3466.8645 - val_mean_absolute_error: 37.4793\n",
      "Epoch 19/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4150.4258 - mean_absolute_error: 36.9766 - val_loss: 3446.6331 - val_mean_absolute_error: 38.1154\n",
      "Epoch 20/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4738.6660 - mean_absolute_error: 37.9095 - val_loss: 3311.3616 - val_mean_absolute_error: 36.5544\n",
      "Epoch 21/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4580.1289 - mean_absolute_error: 36.8327 - val_loss: 3230.7476 - val_mean_absolute_error: 36.2515\n",
      "Epoch 22/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4075.6067 - mean_absolute_error: 35.3881 - val_loss: 3165.7114 - val_mean_absolute_error: 35.2347\n",
      "Epoch 23/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4261.8008 - mean_absolute_error: 35.6640 - val_loss: 3140.8936 - val_mean_absolute_error: 35.9652\n",
      "Epoch 24/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4566.8267 - mean_absolute_error: 35.2500 - val_loss: 2977.3813 - val_mean_absolute_error: 34.5573\n",
      "Epoch 25/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4154.7480 - mean_absolute_error: 33.5648 - val_loss: 2918.0908 - val_mean_absolute_error: 34.3154\n",
      "Epoch 26/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3520.8220 - mean_absolute_error: 33.4011 - val_loss: 2841.7031 - val_mean_absolute_error: 33.7183\n",
      "Epoch 27/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3283.2698 - mean_absolute_error: 32.8235 - val_loss: 2763.9868 - val_mean_absolute_error: 33.3654\n",
      "Epoch 28/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4096.8169 - mean_absolute_error: 33.7442 - val_loss: 2685.4253 - val_mean_absolute_error: 32.4339\n",
      "Epoch 29/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4387.8462 - mean_absolute_error: 32.9935 - val_loss: 2617.9207 - val_mean_absolute_error: 31.6786\n",
      "Epoch 30/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3710.5483 - mean_absolute_error: 31.2577 - val_loss: 2538.7273 - val_mean_absolute_error: 31.5323\n",
      "Epoch 31/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3612.3662 - mean_absolute_error: 32.2043 - val_loss: 2499.6155 - val_mean_absolute_error: 30.1172\n",
      "Epoch 32/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2958.6316 - mean_absolute_error: 30.0308 - val_loss: 2419.7302 - val_mean_absolute_error: 30.4481\n",
      "Epoch 33/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3263.0964 - mean_absolute_error: 30.2378 - val_loss: 2302.8958 - val_mean_absolute_error: 29.2595\n",
      "Epoch 34/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2717.0864 - mean_absolute_error: 28.8257 - val_loss: 2248.1147 - val_mean_absolute_error: 29.1353\n",
      "Epoch 35/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2683.7732 - mean_absolute_error: 28.7500 - val_loss: 2181.0317 - val_mean_absolute_error: 28.1057\n",
      "Epoch 36/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2379.4089 - mean_absolute_error: 27.3693 - val_loss: 2424.1580 - val_mean_absolute_error: 30.8766\n",
      "Epoch 37/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3245.4075 - mean_absolute_error: 28.9130 - val_loss: 2038.1312 - val_mean_absolute_error: 26.9872\n",
      "Epoch 38/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3133.6084 - mean_absolute_error: 26.9619 - val_loss: 1982.0551 - val_mean_absolute_error: 26.1576\n",
      "Epoch 39/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2575.9644 - mean_absolute_error: 26.2429 - val_loss: 1926.1384 - val_mean_absolute_error: 26.0129\n",
      "Epoch 40/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2531.1091 - mean_absolute_error: 25.8496 - val_loss: 1825.5363 - val_mean_absolute_error: 24.3146\n",
      "Epoch 41/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2733.2009 - mean_absolute_error: 25.2804 - val_loss: 1840.9790 - val_mean_absolute_error: 24.8002\n",
      "Epoch 42/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2675.1250 - mean_absolute_error: 24.8500 - val_loss: 1862.1495 - val_mean_absolute_error: 24.3803\n",
      "Epoch 43/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2537.4607 - mean_absolute_error: 25.5353 - val_loss: 1721.6539 - val_mean_absolute_error: 23.2743\n",
      "Epoch 44/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2743.0657 - mean_absolute_error: 24.1511 - val_loss: 1727.0496 - val_mean_absolute_error: 23.0617\n",
      "Epoch 45/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3667.0627 - mean_absolute_error: 25.6331 - val_loss: 1676.6489 - val_mean_absolute_error: 22.5563\n",
      "Epoch 46/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2878.9932 - mean_absolute_error: 24.0749 - val_loss: 1641.2322 - val_mean_absolute_error: 22.1515\n",
      "Epoch 47/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3502.0520 - mean_absolute_error: 24.3551 - val_loss: 1707.5238 - val_mean_absolute_error: 23.3305\n",
      "Epoch 48/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2440.2996 - mean_absolute_error: 23.1132 - val_loss: 1655.7317 - val_mean_absolute_error: 22.3955\n",
      "Epoch 49/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3269.2183 - mean_absolute_error: 23.5601 - val_loss: 1622.6345 - val_mean_absolute_error: 21.7151\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:57:58,653] Trial 62 finished with value: 22.186260460275413 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 8, 'learning_rate': 0.0036912716384849436, 'dropout_rate': 0.0006227748029407256, 'epoch': 49, 'batch_size': 92, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 73956.7031 - mean_absolute_error: 217.9798 - val_loss: 68907.4375 - val_mean_absolute_error: 212.5611\n",
      "Epoch 2/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71944.3516 - mean_absolute_error: 214.1321 - val_loss: 65925.0469 - val_mean_absolute_error: 207.0708\n",
      "Epoch 3/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66647.5000 - mean_absolute_error: 206.2984 - val_loss: 59826.5312 - val_mean_absolute_error: 195.8734\n",
      "Epoch 4/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 60304.9648 - mean_absolute_error: 192.7347 - val_loss: 49350.8477 - val_mean_absolute_error: 175.7900\n",
      "Epoch 5/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 47221.7188 - mean_absolute_error: 170.6335 - val_loss: 36522.5820 - val_mean_absolute_error: 148.5038\n",
      "Epoch 6/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 34960.4102 - mean_absolute_error: 143.4599 - val_loss: 23268.3477 - val_mean_absolute_error: 119.6210\n",
      "Epoch 7/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29147.1621 - mean_absolute_error: 120.5530 - val_loss: 15718.2725 - val_mean_absolute_error: 99.3553\n",
      "Epoch 8/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19705.3359 - mean_absolute_error: 101.2598 - val_loss: 12669.1523 - val_mean_absolute_error: 87.6012\n",
      "Epoch 9/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25643.4922 - mean_absolute_error: 95.8361 - val_loss: 11294.3496 - val_mean_absolute_error: 81.5395\n",
      "Epoch 10/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15708.7422 - mean_absolute_error: 86.6300 - val_loss: 9933.1279 - val_mean_absolute_error: 75.4963\n",
      "Epoch 11/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13280.2686 - mean_absolute_error: 79.0551 - val_loss: 8777.3643 - val_mean_absolute_error: 69.8041\n",
      "Epoch 12/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15325.5996 - mean_absolute_error: 77.0220 - val_loss: 7832.5596 - val_mean_absolute_error: 64.6839\n",
      "Epoch 13/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11564.0049 - mean_absolute_error: 69.0598 - val_loss: 6945.4707 - val_mean_absolute_error: 59.7049\n",
      "Epoch 14/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12680.6240 - mean_absolute_error: 66.3328 - val_loss: 6250.0645 - val_mean_absolute_error: 55.5650\n",
      "Epoch 15/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11790.7852 - mean_absolute_error: 64.2525 - val_loss: 5622.9390 - val_mean_absolute_error: 51.3933\n",
      "Epoch 16/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10815.6055 - mean_absolute_error: 61.3441 - val_loss: 5136.0366 - val_mean_absolute_error: 49.3546\n",
      "Epoch 17/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10064.9551 - mean_absolute_error: 56.4473 - val_loss: 4670.6299 - val_mean_absolute_error: 46.2370\n",
      "Epoch 18/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10291.9834 - mean_absolute_error: 55.2289 - val_loss: 4314.0835 - val_mean_absolute_error: 43.9540\n",
      "Epoch 19/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9372.0361 - mean_absolute_error: 54.1793 - val_loss: 3993.8882 - val_mean_absolute_error: 41.8352\n",
      "Epoch 20/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9507.0479 - mean_absolute_error: 53.2827 - val_loss: 3837.9553 - val_mean_absolute_error: 41.2996\n",
      "Epoch 21/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6961.5078 - mean_absolute_error: 50.0346 - val_loss: 3633.2283 - val_mean_absolute_error: 39.9218\n",
      "Epoch 22/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7428.6899 - mean_absolute_error: 49.8125 - val_loss: 3447.3948 - val_mean_absolute_error: 38.4720\n",
      "Epoch 23/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8132.1274 - mean_absolute_error: 49.8168 - val_loss: 3296.5791 - val_mean_absolute_error: 37.2020\n",
      "Epoch 24/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6937.4629 - mean_absolute_error: 47.7306 - val_loss: 3077.5459 - val_mean_absolute_error: 35.2692\n",
      "Epoch 25/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6132.8447 - mean_absolute_error: 46.7623 - val_loss: 2998.0115 - val_mean_absolute_error: 34.9918\n",
      "Epoch 26/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7801.9785 - mean_absolute_error: 45.5629 - val_loss: 2934.1228 - val_mean_absolute_error: 34.6780\n",
      "Epoch 27/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6584.9468 - mean_absolute_error: 45.5283 - val_loss: 2863.9214 - val_mean_absolute_error: 34.2334\n",
      "Epoch 28/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5445.9248 - mean_absolute_error: 43.1471 - val_loss: 2713.3081 - val_mean_absolute_error: 32.7443\n",
      "Epoch 29/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5285.0986 - mean_absolute_error: 43.9697 - val_loss: 2868.4468 - val_mean_absolute_error: 34.4526\n",
      "Epoch 30/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6317.1499 - mean_absolute_error: 44.6709 - val_loss: 2519.4941 - val_mean_absolute_error: 31.0873\n",
      "Epoch 31/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5237.1294 - mean_absolute_error: 43.4866 - val_loss: 2383.3967 - val_mean_absolute_error: 29.6351\n",
      "Epoch 32/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6892.9238 - mean_absolute_error: 44.7772 - val_loss: 2381.3101 - val_mean_absolute_error: 29.9833\n",
      "Epoch 33/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5577.5679 - mean_absolute_error: 43.7864 - val_loss: 2387.5403 - val_mean_absolute_error: 30.0381\n",
      "Epoch 34/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6647.8672 - mean_absolute_error: 44.8946 - val_loss: 2254.4578 - val_mean_absolute_error: 28.6109\n",
      "Epoch 35/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5038.5562 - mean_absolute_error: 42.3406 - val_loss: 2226.8357 - val_mean_absolute_error: 28.3191\n",
      "Epoch 36/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4837.0210 - mean_absolute_error: 41.3262 - val_loss: 2288.2405 - val_mean_absolute_error: 29.3334\n",
      "Epoch 37/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5106.7930 - mean_absolute_error: 41.2146 - val_loss: 2080.4905 - val_mean_absolute_error: 27.1304\n",
      "Epoch 38/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6384.1255 - mean_absolute_error: 41.5237 - val_loss: 2007.7899 - val_mean_absolute_error: 26.4577\n",
      "Epoch 39/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5797.9292 - mean_absolute_error: 42.5200 - val_loss: 2145.2234 - val_mean_absolute_error: 28.1755\n",
      "Epoch 40/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4946.1641 - mean_absolute_error: 41.4306 - val_loss: 2090.4797 - val_mean_absolute_error: 27.6309\n",
      "Epoch 41/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4124.7134 - mean_absolute_error: 39.5595 - val_loss: 1989.8336 - val_mean_absolute_error: 26.3808\n",
      "Epoch 42/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5078.5215 - mean_absolute_error: 39.7739 - val_loss: 1865.4847 - val_mean_absolute_error: 24.8034\n",
      "Epoch 43/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4331.8120 - mean_absolute_error: 40.0570 - val_loss: 1853.1958 - val_mean_absolute_error: 24.5064\n",
      "Epoch 44/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4304.9297 - mean_absolute_error: 39.3899 - val_loss: 1805.2148 - val_mean_absolute_error: 24.0892\n",
      "Epoch 45/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4637.1748 - mean_absolute_error: 39.7038 - val_loss: 1810.3651 - val_mean_absolute_error: 24.3813\n",
      "Epoch 46/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4973.4785 - mean_absolute_error: 39.4282 - val_loss: 1760.2809 - val_mean_absolute_error: 23.8198\n",
      "Epoch 47/47\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5469.8452 - mean_absolute_error: 41.4088 - val_loss: 1732.2334 - val_mean_absolute_error: 23.4619\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:58:04,047] Trial 63 finished with value: 24.03453184995651 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 8, 'learning_rate': 0.002024399600974916, 'dropout_rate': 0.05355234789256947, 'epoch': 47, 'batch_size': 89, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 50120.4414 - mean_absolute_error: 172.1214 - val_loss: 7919.5845 - val_mean_absolute_error: 71.9184\n",
      "Epoch 2/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10357.3291 - mean_absolute_error: 57.9581 - val_loss: 3142.8174 - val_mean_absolute_error: 35.8696\n",
      "Epoch 3/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10229.8809 - mean_absolute_error: 45.3231 - val_loss: 3012.8110 - val_mean_absolute_error: 34.4731\n",
      "Epoch 4/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12596.1719 - mean_absolute_error: 46.5539 - val_loss: 2823.5457 - val_mean_absolute_error: 33.7598\n",
      "Epoch 5/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7453.7168 - mean_absolute_error: 45.4289 - val_loss: 6968.4136 - val_mean_absolute_error: 51.7438\n",
      "Epoch 6/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7040.9976 - mean_absolute_error: 45.1880 - val_loss: 2956.9163 - val_mean_absolute_error: 32.8266\n",
      "Epoch 7/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5691.2568 - mean_absolute_error: 43.8726 - val_loss: 3529.2341 - val_mean_absolute_error: 36.7847\n",
      "Epoch 8/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5194.3608 - mean_absolute_error: 41.8988 - val_loss: 3795.1345 - val_mean_absolute_error: 40.5865\n",
      "Epoch 9/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5925.8975 - mean_absolute_error: 41.1649 - val_loss: 2866.7605 - val_mean_absolute_error: 32.4256\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:58:05,901] Trial 64 finished with value: 34.57648576100469 and parameters: {'layer_1': 7, 'layer_2': 8, 'layer_3': 7, 'learning_rate': 0.023905505371555984, 'dropout_rate': 0.03419437368129928, 'epoch': 50, 'batch_size': 95, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 70412.7812 - mean_absolute_error: 211.0106 - val_loss: 31915.8125 - val_mean_absolute_error: 141.8493\n",
      "Epoch 2/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26782.6934 - mean_absolute_error: 120.6199 - val_loss: 12008.6602 - val_mean_absolute_error: 85.4704\n",
      "Epoch 3/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15102.4307 - mean_absolute_error: 81.5517 - val_loss: 7948.7666 - val_mean_absolute_error: 65.6906\n",
      "Epoch 4/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8735.7646 - mean_absolute_error: 62.0945 - val_loss: 5539.2197 - val_mean_absolute_error: 52.9010\n",
      "Epoch 5/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8130.3662 - mean_absolute_error: 51.1145 - val_loss: 3954.6287 - val_mean_absolute_error: 40.9794\n",
      "Epoch 6/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6563.8672 - mean_absolute_error: 44.9633 - val_loss: 3300.7371 - val_mean_absolute_error: 36.7727\n",
      "Epoch 7/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5314.3408 - mean_absolute_error: 39.6432 - val_loss: 2917.6243 - val_mean_absolute_error: 34.1993\n",
      "Epoch 8/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6350.7456 - mean_absolute_error: 39.4166 - val_loss: 2590.3328 - val_mean_absolute_error: 31.7033\n",
      "Epoch 9/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4380.4175 - mean_absolute_error: 35.3639 - val_loss: 2402.9404 - val_mean_absolute_error: 29.6700\n",
      "Epoch 10/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3538.3105 - mean_absolute_error: 33.3058 - val_loss: 2153.9604 - val_mean_absolute_error: 27.3847\n",
      "Epoch 11/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3779.7939 - mean_absolute_error: 31.9634 - val_loss: 2018.9751 - val_mean_absolute_error: 26.5391\n",
      "Epoch 12/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3687.0515 - mean_absolute_error: 29.4506 - val_loss: 2012.9462 - val_mean_absolute_error: 26.4762\n",
      "Epoch 13/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3364.2188 - mean_absolute_error: 28.9397 - val_loss: 1841.4678 - val_mean_absolute_error: 24.9143\n",
      "Epoch 14/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2800.5193 - mean_absolute_error: 28.4904 - val_loss: 2173.9492 - val_mean_absolute_error: 28.1043\n",
      "Epoch 15/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3662.2419 - mean_absolute_error: 28.7219 - val_loss: 1825.5938 - val_mean_absolute_error: 24.4080\n",
      "Epoch 16/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3053.6885 - mean_absolute_error: 28.2858 - val_loss: 1706.3533 - val_mean_absolute_error: 23.1182\n",
      "Epoch 17/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2708.5520 - mean_absolute_error: 28.0550 - val_loss: 1622.3698 - val_mean_absolute_error: 21.9210\n",
      "Epoch 18/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2866.0312 - mean_absolute_error: 28.5612 - val_loss: 1621.9261 - val_mean_absolute_error: 21.8349\n",
      "Epoch 19/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3562.8501 - mean_absolute_error: 28.5374 - val_loss: 1645.5295 - val_mean_absolute_error: 22.2889\n",
      "Epoch 20/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3934.0059 - mean_absolute_error: 29.4630 - val_loss: 1625.2800 - val_mean_absolute_error: 21.7815\n",
      "Epoch 21/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3599.1687 - mean_absolute_error: 28.6482 - val_loss: 1683.5381 - val_mean_absolute_error: 22.6747\n",
      "Epoch 22/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4110.3364 - mean_absolute_error: 28.9469 - val_loss: 1584.8398 - val_mean_absolute_error: 21.3601\n",
      "Epoch 23/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3118.4517 - mean_absolute_error: 27.1078 - val_loss: 1612.5635 - val_mean_absolute_error: 21.5280\n",
      "Epoch 24/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2514.8706 - mean_absolute_error: 26.8043 - val_loss: 1735.2357 - val_mean_absolute_error: 23.1645\n",
      "Epoch 25/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3866.5195 - mean_absolute_error: 28.8343 - val_loss: 1563.3342 - val_mean_absolute_error: 21.0173\n",
      "Epoch 26/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3632.1475 - mean_absolute_error: 28.1630 - val_loss: 1568.4733 - val_mean_absolute_error: 21.1591\n",
      "Epoch 27/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3331.8674 - mean_absolute_error: 27.4381 - val_loss: 1588.1912 - val_mean_absolute_error: 21.4939\n",
      "Epoch 28/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3161.3062 - mean_absolute_error: 27.7596 - val_loss: 1583.9843 - val_mean_absolute_error: 21.5474\n",
      "Epoch 29/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2643.0071 - mean_absolute_error: 27.8441 - val_loss: 1636.8368 - val_mean_absolute_error: 22.3445\n",
      "Epoch 30/46\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3139.4197 - mean_absolute_error: 28.0382 - val_loss: 1588.1381 - val_mean_absolute_error: 21.1661\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:58:09,441] Trial 65 finished with value: 21.737511378729344 and parameters: {'layer_1': 8, 'layer_2': 7, 'layer_3': 8, 'learning_rate': 0.007331302519818928, 'dropout_rate': 0.015204293821430372, 'epoch': 46, 'batch_size': 100, 'optimizer': 'RMSprop'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69116.9922 - mean_absolute_error: 202.6481 - val_loss: 20472.5723 - val_mean_absolute_error: 114.9749\n",
      "Epoch 2/21\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20783.0391 - mean_absolute_error: 102.3370 - val_loss: 8452.9736 - val_mean_absolute_error: 71.1203\n",
      "Epoch 3/21\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12540.5166 - mean_absolute_error: 73.5674 - val_loss: 6237.8911 - val_mean_absolute_error: 58.7656\n",
      "Epoch 4/21\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8916.1123 - mean_absolute_error: 61.3092 - val_loss: 4715.0659 - val_mean_absolute_error: 48.5570\n",
      "Epoch 5/21\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10441.9297 - mean_absolute_error: 58.0075 - val_loss: 4168.7090 - val_mean_absolute_error: 46.1734\n",
      "Epoch 6/21\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6318.5342 - mean_absolute_error: 51.6326 - val_loss: 3870.6875 - val_mean_absolute_error: 44.4847\n",
      "Epoch 7/21\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8140.3887 - mean_absolute_error: 52.9044 - val_loss: 3641.6577 - val_mean_absolute_error: 42.8618\n",
      "Epoch 8/21\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8138.7480 - mean_absolute_error: 51.8764 - val_loss: 3215.5872 - val_mean_absolute_error: 38.9268\n",
      "Epoch 9/21\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6642.9058 - mean_absolute_error: 49.3520 - val_loss: 3039.2249 - val_mean_absolute_error: 37.5086\n",
      "Epoch 10/21\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7855.1792 - mean_absolute_error: 50.3817 - val_loss: 2899.8181 - val_mean_absolute_error: 36.5607\n",
      "Epoch 11/21\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5389.9004 - mean_absolute_error: 47.5829 - val_loss: 2861.2905 - val_mean_absolute_error: 36.3991\n",
      "Epoch 12/21\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5337.9126 - mean_absolute_error: 47.1956 - val_loss: 2796.7974 - val_mean_absolute_error: 35.8257\n",
      "Epoch 13/21\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7589.4775 - mean_absolute_error: 49.1319 - val_loss: 2648.8037 - val_mean_absolute_error: 34.3115\n",
      "Epoch 14/21\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7247.4727 - mean_absolute_error: 46.7672 - val_loss: 2589.9385 - val_mean_absolute_error: 33.6779\n",
      "Epoch 15/21\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7634.4268 - mean_absolute_error: 48.5049 - val_loss: 2547.0962 - val_mean_absolute_error: 33.5370\n",
      "Epoch 16/21\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6860.7100 - mean_absolute_error: 47.2160 - val_loss: 2440.3564 - val_mean_absolute_error: 32.2851\n",
      "Epoch 17/21\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5638.3042 - mean_absolute_error: 46.0910 - val_loss: 2472.3560 - val_mean_absolute_error: 32.7928\n",
      "Epoch 18/21\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6000.3594 - mean_absolute_error: 45.9970 - val_loss: 2456.5400 - val_mean_absolute_error: 32.5562\n",
      "Epoch 19/21\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6043.9912 - mean_absolute_error: 47.2696 - val_loss: 2384.3530 - val_mean_absolute_error: 31.7891\n",
      "Epoch 20/21\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4583.3232 - mean_absolute_error: 43.8568 - val_loss: 2323.5288 - val_mean_absolute_error: 31.1866\n",
      "Epoch 21/21\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5172.7969 - mean_absolute_error: 44.0261 - val_loss: 2210.8721 - val_mean_absolute_error: 29.7458\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:58:12,415] Trial 66 finished with value: 30.160038722395893 and parameters: {'layer_1': 8, 'layer_2': 3, 'layer_3': 7, 'learning_rate': 0.0394788878740388, 'dropout_rate': 0.05059672832735011, 'epoch': 21, 'batch_size': 60, 'optimizer': 'Adagrad'}. Best is trial 31 with value: 21.334652156585456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 61380.1289 - mean_absolute_error: 188.4330 - val_loss: 10081.4707 - val_mean_absolute_error: 74.5598\n",
      "Epoch 2/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 16205.0986 - mean_absolute_error: 71.5049 - val_loss: 6577.8491 - val_mean_absolute_error: 57.9033\n",
      "Epoch 3/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7485.9062 - mean_absolute_error: 49.3321 - val_loss: 3868.4297 - val_mean_absolute_error: 39.3330\n",
      "Epoch 4/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6372.2891 - mean_absolute_error: 38.5961 - val_loss: 2932.3579 - val_mean_absolute_error: 33.5829\n",
      "Epoch 5/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4305.9258 - mean_absolute_error: 34.1265 - val_loss: 2811.7485 - val_mean_absolute_error: 33.8875\n",
      "Epoch 6/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4723.3511 - mean_absolute_error: 32.7689 - val_loss: 2176.9070 - val_mean_absolute_error: 27.9719\n",
      "Epoch 7/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3022.1421 - mean_absolute_error: 29.2003 - val_loss: 2003.8546 - val_mean_absolute_error: 26.6707\n",
      "Epoch 8/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2745.9546 - mean_absolute_error: 26.8140 - val_loss: 1780.6749 - val_mean_absolute_error: 24.4013\n",
      "Epoch 9/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3573.5115 - mean_absolute_error: 26.7764 - val_loss: 1933.0938 - val_mean_absolute_error: 27.3319\n",
      "Epoch 10/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2320.2117 - mean_absolute_error: 24.3713 - val_loss: 1714.8141 - val_mean_absolute_error: 22.7090\n",
      "Epoch 11/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2631.2175 - mean_absolute_error: 23.6584 - val_loss: 1667.4662 - val_mean_absolute_error: 22.2469\n",
      "Epoch 12/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2548.1218 - mean_absolute_error: 22.9480 - val_loss: 2500.8875 - val_mean_absolute_error: 30.9382\n",
      "Epoch 13/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2892.6746 - mean_absolute_error: 24.8462 - val_loss: 1588.2415 - val_mean_absolute_error: 21.0715\n",
      "Epoch 14/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2908.3005 - mean_absolute_error: 23.2762 - val_loss: 1596.5322 - val_mean_absolute_error: 20.9152\n",
      "Epoch 15/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2158.9490 - mean_absolute_error: 22.1850 - val_loss: 1597.6774 - val_mean_absolute_error: 21.5462\n",
      "Epoch 16/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2005.7385 - mean_absolute_error: 22.2017 - val_loss: 1548.0302 - val_mean_absolute_error: 20.8138\n",
      "Epoch 17/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2397.3171 - mean_absolute_error: 22.4758 - val_loss: 1632.2429 - val_mean_absolute_error: 21.4737\n",
      "Epoch 18/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2132.1157 - mean_absolute_error: 21.6837 - val_loss: 1568.2285 - val_mean_absolute_error: 20.8318\n",
      "Epoch 19/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1935.9852 - mean_absolute_error: 22.5427 - val_loss: 1611.5721 - val_mean_absolute_error: 21.8415\n",
      "Epoch 20/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3118.5320 - mean_absolute_error: 22.4464 - val_loss: 1571.1229 - val_mean_absolute_error: 20.8248\n",
      "Epoch 21/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1953.4729 - mean_absolute_error: 21.5697 - val_loss: 2500.6682 - val_mean_absolute_error: 29.8839\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:58:15,308] Trial 67 finished with value: 21.33154242320284 and parameters: {'layer_1': 7, 'layer_2': 8, 'layer_3': 7, 'learning_rate': 0.01287163361487508, 'dropout_rate': 0.0005433597545415059, 'epoch': 45, 'batch_size': 75, 'optimizer': 'RMSprop'}. Best is trial 67 with value: 21.33154242320284.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 43987.1875 - mean_absolute_error: 154.5542 - val_loss: 5889.4170 - val_mean_absolute_error: 55.1571\n",
      "Epoch 2/48\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7035.4277 - mean_absolute_error: 51.3090 - val_loss: 3162.4836 - val_mean_absolute_error: 37.4181\n",
      "Epoch 3/48\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4344.0908 - mean_absolute_error: 38.9655 - val_loss: 2201.6970 - val_mean_absolute_error: 29.1102\n",
      "Epoch 4/48\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3558.1450 - mean_absolute_error: 34.2120 - val_loss: 2086.5325 - val_mean_absolute_error: 27.3917\n",
      "Epoch 5/48\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3213.3604 - mean_absolute_error: 31.5801 - val_loss: 1758.9108 - val_mean_absolute_error: 23.9034\n",
      "Epoch 6/48\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 3872.6199 - mean_absolute_error: 31.1734 - val_loss: 1642.1333 - val_mean_absolute_error: 22.3046\n",
      "Epoch 7/48\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3963.2109 - mean_absolute_error: 31.1285 - val_loss: 1679.4761 - val_mean_absolute_error: 23.0792\n",
      "Epoch 8/48\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3420.5188 - mean_absolute_error: 31.5814 - val_loss: 2061.4634 - val_mean_absolute_error: 26.9597\n",
      "Epoch 9/48\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - loss: 3148.0254 - mean_absolute_error: 30.9304 - val_loss: 1891.1373 - val_mean_absolute_error: 25.1420\n",
      "Epoch 10/48\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4031.1475 - mean_absolute_error: 32.5075 - val_loss: 1592.0641 - val_mean_absolute_error: 21.5646\n",
      "Epoch 11/48\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 3340.3381 - mean_absolute_error: 28.6200 - val_loss: 1735.3732 - val_mean_absolute_error: 23.3482\n",
      "Epoch 12/48\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3386.5513 - mean_absolute_error: 30.2707 - val_loss: 1617.5917 - val_mean_absolute_error: 21.7808\n",
      "Epoch 13/48\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 3110.5925 - mean_absolute_error: 30.1622 - val_loss: 1681.0283 - val_mean_absolute_error: 22.6406\n",
      "Epoch 14/48\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 3296.5945 - mean_absolute_error: 29.7558 - val_loss: 1571.5582 - val_mean_absolute_error: 21.2289\n",
      "Epoch 15/48\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4339.6089 - mean_absolute_error: 31.1421 - val_loss: 1897.2961 - val_mean_absolute_error: 24.7471\n",
      "Epoch 16/48\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 4537.8218 - mean_absolute_error: 31.5321 - val_loss: 1834.8677 - val_mean_absolute_error: 24.2412\n",
      "Epoch 17/48\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3052.0347 - mean_absolute_error: 29.9927 - val_loss: 1601.3112 - val_mean_absolute_error: 21.0800\n",
      "Epoch 18/48\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 5015.6270 - mean_absolute_error: 31.1268 - val_loss: 1652.7385 - val_mean_absolute_error: 21.9740\n",
      "Epoch 19/48\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4097.3140 - mean_absolute_error: 29.5488 - val_loss: 1596.3658 - val_mean_absolute_error: 21.6518\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:58:18,272] Trial 68 finished with value: 22.047659742313623 and parameters: {'layer_1': 6, 'layer_2': 7, 'layer_3': 8, 'learning_rate': 0.014620800553744701, 'dropout_rate': 0.020240364134620756, 'epoch': 48, 'batch_size': 52, 'optimizer': 'RMSprop'}. Best is trial 67 with value: 21.33154242320284.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 74655.5625 - mean_absolute_error: 217.1480 - val_loss: 69993.5625 - val_mean_absolute_error: 214.6141\n",
      "Epoch 2/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70961.8750 - mean_absolute_error: 213.2475 - val_loss: 69993.0859 - val_mean_absolute_error: 214.6116\n",
      "Epoch 3/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71686.7578 - mean_absolute_error: 215.2847 - val_loss: 69992.5625 - val_mean_absolute_error: 214.6090\n",
      "Epoch 4/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73932.2656 - mean_absolute_error: 216.9131 - val_loss: 69992.0156 - val_mean_absolute_error: 214.6062\n",
      "Epoch 5/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72669.4922 - mean_absolute_error: 215.9531 - val_loss: 69991.4375 - val_mean_absolute_error: 214.6033\n",
      "Epoch 6/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72256.4375 - mean_absolute_error: 215.0000 - val_loss: 69990.8203 - val_mean_absolute_error: 214.6003\n",
      "Epoch 7/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70856.5781 - mean_absolute_error: 214.0701 - val_loss: 69990.1797 - val_mean_absolute_error: 214.5971\n",
      "Epoch 8/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69075.3828 - mean_absolute_error: 211.5776 - val_loss: 69989.4844 - val_mean_absolute_error: 214.5937\n",
      "Epoch 9/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73699.0078 - mean_absolute_error: 216.0124 - val_loss: 69988.7734 - val_mean_absolute_error: 214.5902\n",
      "Epoch 10/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75439.9922 - mean_absolute_error: 220.2085 - val_loss: 69988.0156 - val_mean_absolute_error: 214.5865\n",
      "Epoch 11/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71216.0234 - mean_absolute_error: 214.6575 - val_loss: 69987.2422 - val_mean_absolute_error: 214.5828\n",
      "Epoch 12/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72559.8750 - mean_absolute_error: 214.1995 - val_loss: 69986.4297 - val_mean_absolute_error: 214.5789\n",
      "Epoch 13/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73340.0234 - mean_absolute_error: 215.3172 - val_loss: 69985.5781 - val_mean_absolute_error: 214.5748\n",
      "Epoch 14/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73953.7734 - mean_absolute_error: 216.8815 - val_loss: 69984.7344 - val_mean_absolute_error: 214.5707\n",
      "Epoch 15/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73474.7188 - mean_absolute_error: 216.9597 - val_loss: 69983.8594 - val_mean_absolute_error: 214.5666\n",
      "Epoch 16/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75424.0156 - mean_absolute_error: 217.5030 - val_loss: 69982.9844 - val_mean_absolute_error: 214.5624\n",
      "Epoch 17/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71599.8516 - mean_absolute_error: 212.9319 - val_loss: 69982.0625 - val_mean_absolute_error: 214.5581\n",
      "Epoch 18/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70308.4375 - mean_absolute_error: 212.4793 - val_loss: 69981.1172 - val_mean_absolute_error: 214.5537\n",
      "Epoch 19/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73869.8125 - mean_absolute_error: 215.7437 - val_loss: 69980.1641 - val_mean_absolute_error: 214.5493\n",
      "Epoch 20/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71113.9297 - mean_absolute_error: 214.1430 - val_loss: 69979.1953 - val_mean_absolute_error: 214.5448\n",
      "Epoch 21/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69672.2969 - mean_absolute_error: 212.5270 - val_loss: 69978.2031 - val_mean_absolute_error: 214.5403\n",
      "Epoch 22/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71995.0938 - mean_absolute_error: 213.3238 - val_loss: 69977.1797 - val_mean_absolute_error: 214.5357\n",
      "Epoch 23/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70927.3672 - mean_absolute_error: 214.0217 - val_loss: 69976.1328 - val_mean_absolute_error: 214.5309\n",
      "Epoch 24/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70614.6641 - mean_absolute_error: 214.8795 - val_loss: 69975.0703 - val_mean_absolute_error: 214.5262\n",
      "Epoch 25/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70995.9688 - mean_absolute_error: 214.0967 - val_loss: 69973.9609 - val_mean_absolute_error: 214.5213\n",
      "Epoch 26/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74391.3359 - mean_absolute_error: 217.4162 - val_loss: 69972.8125 - val_mean_absolute_error: 214.5163\n",
      "Epoch 27/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72608.7891 - mean_absolute_error: 216.8386 - val_loss: 69971.6641 - val_mean_absolute_error: 214.5112\n",
      "Epoch 28/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74309.4375 - mean_absolute_error: 217.7948 - val_loss: 69970.4688 - val_mean_absolute_error: 214.5060\n",
      "Epoch 29/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69674.4375 - mean_absolute_error: 211.4554 - val_loss: 69969.2812 - val_mean_absolute_error: 214.5009\n",
      "Epoch 30/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72029.6562 - mean_absolute_error: 214.5717 - val_loss: 69968.0625 - val_mean_absolute_error: 214.4956\n",
      "Epoch 31/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70398.9922 - mean_absolute_error: 213.1106 - val_loss: 69966.7891 - val_mean_absolute_error: 214.4903\n",
      "Epoch 32/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71400.1484 - mean_absolute_error: 214.6139 - val_loss: 69965.5078 - val_mean_absolute_error: 214.4849\n",
      "Epoch 33/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75971.2344 - mean_absolute_error: 218.1076 - val_loss: 69964.1953 - val_mean_absolute_error: 214.4793\n",
      "Epoch 34/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70726.0078 - mean_absolute_error: 214.3613 - val_loss: 69962.8203 - val_mean_absolute_error: 214.4736\n",
      "Epoch 35/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72495.6172 - mean_absolute_error: 215.1527 - val_loss: 69961.4375 - val_mean_absolute_error: 214.4678\n",
      "Epoch 36/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72943.6172 - mean_absolute_error: 215.9608 - val_loss: 69960.0312 - val_mean_absolute_error: 214.4620\n",
      "Epoch 37/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69063.5000 - mean_absolute_error: 212.8869 - val_loss: 69958.5703 - val_mean_absolute_error: 214.4560\n",
      "Epoch 38/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72437.2578 - mean_absolute_error: 215.2741 - val_loss: 69957.0703 - val_mean_absolute_error: 214.4498\n",
      "Epoch 39/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74349.0000 - mean_absolute_error: 218.1987 - val_loss: 69955.5156 - val_mean_absolute_error: 214.4435\n",
      "Epoch 40/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74047.9453 - mean_absolute_error: 218.8668 - val_loss: 69953.9375 - val_mean_absolute_error: 214.4371\n",
      "Epoch 41/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73175.9453 - mean_absolute_error: 215.8338 - val_loss: 69952.3203 - val_mean_absolute_error: 214.4306\n",
      "Epoch 42/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67980.3594 - mean_absolute_error: 210.6369 - val_loss: 69950.6484 - val_mean_absolute_error: 214.4239\n",
      "Epoch 43/43\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70796.1172 - mean_absolute_error: 214.2756 - val_loss: 69948.9297 - val_mean_absolute_error: 214.4171\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:58:23,423] Trial 69 finished with value: 215.1935208115195 and parameters: {'layer_1': 7, 'layer_2': 8, 'layer_3': 7, 'learning_rate': 0.004790348191529845, 'dropout_rate': 0.0685916078556264, 'epoch': 43, 'batch_size': 79, 'optimizer': 'Adadelta'}. Best is trial 67 with value: 21.33154242320284.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 68972.6875 - mean_absolute_error: 209.5049 - val_loss: 64660.0547 - val_mean_absolute_error: 206.2083\n",
      "Epoch 2/10\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 63653.5820 - mean_absolute_error: 201.4749 - val_loss: 45986.8750 - val_mean_absolute_error: 173.8998\n",
      "Epoch 3/10\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 44581.3984 - mean_absolute_error: 166.1709 - val_loss: 22675.2363 - val_mean_absolute_error: 121.6837\n",
      "Epoch 4/10\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26470.3203 - mean_absolute_error: 114.2228 - val_loss: 13086.9932 - val_mean_absolute_error: 93.0252\n",
      "Epoch 5/10\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35270.9727 - mean_absolute_error: 100.5840 - val_loss: 10752.6807 - val_mean_absolute_error: 83.3092\n",
      "Epoch 6/10\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21256.6641 - mean_absolute_error: 87.7932 - val_loss: 8836.0215 - val_mean_absolute_error: 73.3295\n",
      "Epoch 7/10\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11992.1357 - mean_absolute_error: 76.0717 - val_loss: 7262.2549 - val_mean_absolute_error: 65.5175\n",
      "Epoch 8/10\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11747.0898 - mean_absolute_error: 68.1254 - val_loss: 6235.2881 - val_mean_absolute_error: 59.1250\n",
      "Epoch 9/10\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8591.1602 - mean_absolute_error: 59.1619 - val_loss: 5312.7607 - val_mean_absolute_error: 52.3520\n",
      "Epoch 10/10\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7921.2280 - mean_absolute_error: 56.1665 - val_loss: 4790.1899 - val_mean_absolute_error: 48.6540\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:58:25,278] Trial 70 finished with value: 48.85978685564994 and parameters: {'layer_1': 7, 'layer_2': 8, 'layer_3': 7, 'learning_rate': 0.0033071104041736783, 'dropout_rate': 0.039087235397247816, 'epoch': 10, 'batch_size': 85, 'optimizer': 'RMSprop'}. Best is trial 67 with value: 21.33154242320284.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 62341.2305 - mean_absolute_error: 195.9393 - val_loss: 14079.3008 - val_mean_absolute_error: 94.3541\n",
      "Epoch 2/45\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13163.4551 - mean_absolute_error: 85.9148 - val_loss: 7712.3242 - val_mean_absolute_error: 68.2958\n",
      "Epoch 3/45\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8055.3638 - mean_absolute_error: 59.6514 - val_loss: 4317.0288 - val_mean_absolute_error: 44.0498\n",
      "Epoch 4/45\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5348.0615 - mean_absolute_error: 41.2374 - val_loss: 3318.2844 - val_mean_absolute_error: 37.1689\n",
      "Epoch 5/45\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4718.2969 - mean_absolute_error: 37.7018 - val_loss: 2913.9092 - val_mean_absolute_error: 32.9286\n",
      "Epoch 6/45\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3579.8267 - mean_absolute_error: 32.9258 - val_loss: 2428.6536 - val_mean_absolute_error: 29.7378\n",
      "Epoch 7/45\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3405.8726 - mean_absolute_error: 31.1691 - val_loss: 2289.0251 - val_mean_absolute_error: 29.3840\n",
      "Epoch 8/45\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4226.5068 - mean_absolute_error: 30.7704 - val_loss: 2240.9490 - val_mean_absolute_error: 27.7414\n",
      "Epoch 9/45\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2903.9771 - mean_absolute_error: 27.0667 - val_loss: 2259.8862 - val_mean_absolute_error: 29.0759\n",
      "Epoch 10/45\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2416.7625 - mean_absolute_error: 25.3247 - val_loss: 1677.6855 - val_mean_absolute_error: 22.8180\n",
      "Epoch 11/45\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3939.3445 - mean_absolute_error: 25.1240 - val_loss: 2161.7324 - val_mean_absolute_error: 27.4160\n",
      "Epoch 12/45\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2523.4050 - mean_absolute_error: 23.7787 - val_loss: 1574.1079 - val_mean_absolute_error: 21.4222\n",
      "Epoch 13/45\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1786.6619 - mean_absolute_error: 22.3492 - val_loss: 2284.5452 - val_mean_absolute_error: 29.9257\n",
      "Epoch 14/45\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2302.0208 - mean_absolute_error: 22.9812 - val_loss: 1802.9370 - val_mean_absolute_error: 24.8523\n",
      "Epoch 15/45\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2194.6416 - mean_absolute_error: 23.1269 - val_loss: 1707.4452 - val_mean_absolute_error: 22.8222\n",
      "Epoch 16/45\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2741.7080 - mean_absolute_error: 23.3374 - val_loss: 2546.1074 - val_mean_absolute_error: 30.3492\n",
      "Epoch 17/45\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3536.6172 - mean_absolute_error: 25.1139 - val_loss: 1552.4677 - val_mean_absolute_error: 21.0423\n",
      "Epoch 18/45\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2381.8066 - mean_absolute_error: 23.4804 - val_loss: 1670.5786 - val_mean_absolute_error: 22.4301\n",
      "Epoch 19/45\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2392.8142 - mean_absolute_error: 21.8966 - val_loss: 2182.2500 - val_mean_absolute_error: 30.0380\n",
      "Epoch 20/45\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2386.5593 - mean_absolute_error: 23.9045 - val_loss: 2490.3909 - val_mean_absolute_error: 30.9639\n",
      "Epoch 21/45\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3081.8481 - mean_absolute_error: 23.9715 - val_loss: 3162.2761 - val_mean_absolute_error: 35.6841\n",
      "Epoch 22/45\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2753.7610 - mean_absolute_error: 24.2208 - val_loss: 1570.9908 - val_mean_absolute_error: 20.9005\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:58:28,163] Trial 71 finished with value: 21.76623973056972 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 6, 'learning_rate': 0.009685798789193291, 'dropout_rate': 0.0004282956779868035, 'epoch': 45, 'batch_size': 93, 'optimizer': 'RMSprop'}. Best is trial 67 with value: 21.33154242320284.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 23272.6465 - mean_absolute_error: 100.1805 - val_loss: 2725.9692 - val_mean_absolute_error: 30.2916\n",
      "Epoch 2/49\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6438.1763 - mean_absolute_error: 41.5521 - val_loss: 1955.6755 - val_mean_absolute_error: 26.0869\n",
      "Epoch 3/49\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5244.8652 - mean_absolute_error: 38.9338 - val_loss: 2859.4285 - val_mean_absolute_error: 34.5101\n",
      "Epoch 4/49\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4080.6421 - mean_absolute_error: 36.6637 - val_loss: 1949.5063 - val_mean_absolute_error: 26.1576\n",
      "Epoch 5/49\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4258.4111 - mean_absolute_error: 36.1667 - val_loss: 1960.9913 - val_mean_absolute_error: 25.1786\n",
      "Epoch 6/49\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3999.0242 - mean_absolute_error: 34.1925 - val_loss: 2797.6482 - val_mean_absolute_error: 32.9306\n",
      "Epoch 7/49\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4593.1064 - mean_absolute_error: 36.1176 - val_loss: 5720.6709 - val_mean_absolute_error: 49.9600\n",
      "Epoch 8/49\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4387.3550 - mean_absolute_error: 35.8555 - val_loss: 4088.9060 - val_mean_absolute_error: 39.5588\n",
      "Epoch 9/49\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3440.5942 - mean_absolute_error: 33.8088 - val_loss: 2232.5725 - val_mean_absolute_error: 27.5888\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:58:30,138] Trial 72 finished with value: 26.30771805519462 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 7, 'learning_rate': 0.030426526870203828, 'dropout_rate': 0.027494494441380808, 'epoch': 49, 'batch_size': 48, 'optimizer': 'RMSprop'}. Best is trial 67 with value: 21.33154242320284.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 25189.6406 - mean_absolute_error: 104.1978 - val_loss: 2497.6626 - val_mean_absolute_error: 29.1476\n",
      "Epoch 2/47\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5892.9780 - mean_absolute_error: 41.6251 - val_loss: 2201.9846 - val_mean_absolute_error: 28.4571\n",
      "Epoch 3/47\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4758.5029 - mean_absolute_error: 38.5908 - val_loss: 3047.6194 - val_mean_absolute_error: 33.2552\n",
      "Epoch 4/47\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5544.9771 - mean_absolute_error: 37.4589 - val_loss: 2587.4062 - val_mean_absolute_error: 32.9080\n",
      "Epoch 5/47\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5641.6113 - mean_absolute_error: 40.7685 - val_loss: 1880.8707 - val_mean_absolute_error: 25.5064\n",
      "Epoch 6/47\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5078.7021 - mean_absolute_error: 37.5227 - val_loss: 4314.4639 - val_mean_absolute_error: 42.0483\n",
      "Epoch 7/47\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7107.7734 - mean_absolute_error: 40.9299 - val_loss: 1811.3201 - val_mean_absolute_error: 23.9210\n",
      "Epoch 8/47\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5239.3120 - mean_absolute_error: 39.2346 - val_loss: 3422.5408 - val_mean_absolute_error: 40.5945\n",
      "Epoch 9/47\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3577.7444 - mean_absolute_error: 36.7520 - val_loss: 1657.0555 - val_mean_absolute_error: 21.9648\n",
      "Epoch 10/47\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4035.8184 - mean_absolute_error: 33.8165 - val_loss: 1613.8723 - val_mean_absolute_error: 22.6314\n",
      "Epoch 11/47\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3950.8687 - mean_absolute_error: 32.9408 - val_loss: 1910.2743 - val_mean_absolute_error: 24.2226\n",
      "Epoch 12/47\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5334.8984 - mean_absolute_error: 34.5954 - val_loss: 1871.0308 - val_mean_absolute_error: 25.2898\n",
      "Epoch 13/47\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4521.7598 - mean_absolute_error: 34.7514 - val_loss: 1846.7262 - val_mean_absolute_error: 25.7504\n",
      "Epoch 14/47\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4422.8594 - mean_absolute_error: 33.7227 - val_loss: 1781.7910 - val_mean_absolute_error: 25.2180\n",
      "Epoch 15/47\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4803.3374 - mean_absolute_error: 37.8696 - val_loss: 1717.0425 - val_mean_absolute_error: 23.0379\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:58:32,509] Trial 73 finished with value: 23.494092846143246 and parameters: {'layer_1': 7, 'layer_2': 8, 'layer_3': 6, 'learning_rate': 0.07462742924183088, 'dropout_rate': 0.013082577579165327, 'epoch': 47, 'batch_size': 73, 'optimizer': 'RMSprop'}. Best is trial 67 with value: 21.33154242320284.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 61018.5781 - mean_absolute_error: 193.9903 - val_loss: 9721.3926 - val_mean_absolute_error: 75.8220\n",
      "Epoch 2/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13277.6377 - mean_absolute_error: 75.7777 - val_loss: 5655.7437 - val_mean_absolute_error: 52.5901\n",
      "Epoch 3/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9472.6328 - mean_absolute_error: 57.3299 - val_loss: 3912.1860 - val_mean_absolute_error: 40.5538\n",
      "Epoch 4/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6909.4224 - mean_absolute_error: 48.6983 - val_loss: 4080.8875 - val_mean_absolute_error: 42.5585\n",
      "Epoch 5/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 7848.3643 - mean_absolute_error: 49.0405 - val_loss: 3054.7515 - val_mean_absolute_error: 33.6325\n",
      "Epoch 6/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6544.6260 - mean_absolute_error: 45.8840 - val_loss: 2755.3442 - val_mean_absolute_error: 32.7586\n",
      "Epoch 7/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - loss: 6463.8486 - mean_absolute_error: 45.6276 - val_loss: 2762.1826 - val_mean_absolute_error: 33.2367\n",
      "Epoch 8/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - loss: 7248.1035 - mean_absolute_error: 43.7554 - val_loss: 2200.0676 - val_mean_absolute_error: 27.4579\n",
      "Epoch 9/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5416.3174 - mean_absolute_error: 42.0752 - val_loss: 2079.6643 - val_mean_absolute_error: 26.4345\n",
      "Epoch 10/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4108.2959 - mean_absolute_error: 39.3670 - val_loss: 2554.6040 - val_mean_absolute_error: 31.8922\n",
      "Epoch 11/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5903.5381 - mean_absolute_error: 39.6522 - val_loss: 1951.2098 - val_mean_absolute_error: 25.6452\n",
      "Epoch 12/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4226.8633 - mean_absolute_error: 38.2270 - val_loss: 1785.0552 - val_mean_absolute_error: 24.5361\n",
      "Epoch 13/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4675.3140 - mean_absolute_error: 39.8632 - val_loss: 1840.9236 - val_mean_absolute_error: 24.5046\n",
      "Epoch 14/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 4619.1973 - mean_absolute_error: 37.3945 - val_loss: 1757.6619 - val_mean_absolute_error: 23.5095\n",
      "Epoch 15/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 4660.1807 - mean_absolute_error: 38.5783 - val_loss: 1817.9258 - val_mean_absolute_error: 24.7353\n",
      "Epoch 16/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4477.3584 - mean_absolute_error: 37.3399 - val_loss: 1710.2615 - val_mean_absolute_error: 23.5398\n",
      "Epoch 17/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 4714.0420 - mean_absolute_error: 36.6889 - val_loss: 1840.8622 - val_mean_absolute_error: 25.1297\n",
      "Epoch 18/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4109.3086 - mean_absolute_error: 36.6052 - val_loss: 1761.6067 - val_mean_absolute_error: 24.1088\n",
      "Epoch 19/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5322.1460 - mean_absolute_error: 36.5789 - val_loss: 2123.9563 - val_mean_absolute_error: 27.8585\n",
      "Epoch 20/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 4023.2832 - mean_absolute_error: 37.0383 - val_loss: 1934.7002 - val_mean_absolute_error: 25.7363\n",
      "Epoch 21/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4631.8662 - mean_absolute_error: 37.0993 - val_loss: 1652.7524 - val_mean_absolute_error: 22.7600\n",
      "Epoch 22/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3761.1318 - mean_absolute_error: 35.8441 - val_loss: 1876.8878 - val_mean_absolute_error: 25.4500\n",
      "Epoch 23/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3312.1616 - mean_absolute_error: 34.6381 - val_loss: 1719.5095 - val_mean_absolute_error: 23.0381\n",
      "Epoch 24/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3829.3242 - mean_absolute_error: 36.0164 - val_loss: 1737.6091 - val_mean_absolute_error: 23.7882\n",
      "Epoch 25/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 3631.8552 - mean_absolute_error: 34.7593 - val_loss: 1747.1877 - val_mean_absolute_error: 24.0578\n",
      "Epoch 26/45\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3803.4321 - mean_absolute_error: 35.9293 - val_loss: 3016.9934 - val_mean_absolute_error: 36.3581\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:58:37,320] Trial 74 finished with value: 23.525541953969004 and parameters: {'layer_1': 8, 'layer_2': 7, 'layer_3': 7, 'learning_rate': 0.00596910523209824, 'dropout_rate': 0.060086554916790595, 'epoch': 45, 'batch_size': 41, 'optimizer': 'RMSprop'}. Best is trial 67 with value: 21.33154242320284.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 70398.3516 - mean_absolute_error: 214.1630 - val_loss: 63033.7188 - val_mean_absolute_error: 204.9406\n",
      "Epoch 2/42\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56211.8203 - mean_absolute_error: 191.4478 - val_loss: 16949.6680 - val_mean_absolute_error: 109.6387\n",
      "Epoch 3/42\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24060.9805 - mean_absolute_error: 110.3335 - val_loss: 8327.7207 - val_mean_absolute_error: 70.3258\n",
      "Epoch 4/42\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15983.9434 - mean_absolute_error: 77.0312 - val_loss: 6007.7412 - val_mean_absolute_error: 56.7479\n",
      "Epoch 5/42\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9655.6201 - mean_absolute_error: 62.5649 - val_loss: 5065.8618 - val_mean_absolute_error: 50.4912\n",
      "Epoch 6/42\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9233.0566 - mean_absolute_error: 55.6241 - val_loss: 3712.1682 - val_mean_absolute_error: 39.8871\n",
      "Epoch 7/42\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7731.4912 - mean_absolute_error: 50.0973 - val_loss: 2890.7620 - val_mean_absolute_error: 33.4202\n",
      "Epoch 8/42\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8460.9111 - mean_absolute_error: 48.9156 - val_loss: 2972.4614 - val_mean_absolute_error: 34.1811\n",
      "Epoch 9/42\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6322.0923 - mean_absolute_error: 44.8274 - val_loss: 2603.7529 - val_mean_absolute_error: 32.1850\n",
      "Epoch 10/42\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4745.5098 - mean_absolute_error: 42.8203 - val_loss: 2348.3821 - val_mean_absolute_error: 29.6021\n",
      "Epoch 11/42\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5028.0547 - mean_absolute_error: 43.5789 - val_loss: 2189.3657 - val_mean_absolute_error: 28.2719\n",
      "Epoch 12/42\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4886.4165 - mean_absolute_error: 41.3847 - val_loss: 2411.3953 - val_mean_absolute_error: 30.3433\n",
      "Epoch 13/42\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5655.2700 - mean_absolute_error: 41.0472 - val_loss: 2029.3184 - val_mean_absolute_error: 27.7839\n",
      "Epoch 14/42\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5518.8315 - mean_absolute_error: 42.4203 - val_loss: 2106.3994 - val_mean_absolute_error: 27.1682\n",
      "Epoch 15/42\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4432.2480 - mean_absolute_error: 38.3094 - val_loss: 2081.0259 - val_mean_absolute_error: 27.3191\n",
      "Epoch 16/42\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4077.2871 - mean_absolute_error: 37.6568 - val_loss: 1882.3658 - val_mean_absolute_error: 25.1756\n",
      "Epoch 17/42\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4462.5967 - mean_absolute_error: 39.4479 - val_loss: 2265.7749 - val_mean_absolute_error: 28.0542\n",
      "Epoch 18/42\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4974.3701 - mean_absolute_error: 39.4815 - val_loss: 1877.8643 - val_mean_absolute_error: 25.9064\n",
      "Epoch 19/42\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3195.1970 - mean_absolute_error: 35.1731 - val_loss: 2012.7950 - val_mean_absolute_error: 26.3938\n",
      "Epoch 20/42\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4906.8438 - mean_absolute_error: 39.2801 - val_loss: 1965.0978 - val_mean_absolute_error: 26.5589\n",
      "Epoch 21/42\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5999.3799 - mean_absolute_error: 39.1827 - val_loss: 1915.4719 - val_mean_absolute_error: 25.3061\n",
      "Epoch 22/42\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4790.3701 - mean_absolute_error: 38.9179 - val_loss: 1888.6058 - val_mean_absolute_error: 25.1342\n",
      "Epoch 23/42\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4172.6865 - mean_absolute_error: 37.0292 - val_loss: 2007.5101 - val_mean_absolute_error: 26.8402\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:58:40,546] Trial 75 finished with value: 26.183513205772634 and parameters: {'layer_1': 8, 'layer_2': 2, 'layer_3': 8, 'learning_rate': 0.011650903798513856, 'dropout_rate': 0.0414465446588283, 'epoch': 42, 'batch_size': 97, 'optimizer': 'Adam'}. Best is trial 67 with value: 21.33154242320284.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 242246992.0000 - mean_absolute_error: 2541.1997 - val_loss: 70001.7891 - val_mean_absolute_error: 214.6510\n",
      "Epoch 2/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72969.1094 - mean_absolute_error: 214.9460 - val_loss: 70001.7891 - val_mean_absolute_error: 214.6510\n",
      "Epoch 3/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74096.1875 - mean_absolute_error: 215.0688 - val_loss: 70001.7891 - val_mean_absolute_error: 214.6510\n",
      "Epoch 4/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73758.9688 - mean_absolute_error: 217.5702 - val_loss: 70001.7891 - val_mean_absolute_error: 214.6510\n",
      "Epoch 5/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75322.7266 - mean_absolute_error: 218.4737 - val_loss: 70001.7891 - val_mean_absolute_error: 214.6510\n",
      "Epoch 6/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73356.2500 - mean_absolute_error: 217.5350 - val_loss: 70001.7891 - val_mean_absolute_error: 214.6510\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:58:41,816] Trial 76 finished with value: 215.42847832031254 and parameters: {'layer_1': 7, 'layer_2': 8, 'layer_3': 7, 'learning_rate': 0.021637379909909774, 'dropout_rate': 0.013636716129129485, 'epoch': 40, 'batch_size': 87, 'optimizer': 'SGD'}. Best is trial 67 with value: 21.33154242320284.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 73486.2500 - mean_absolute_error: 217.3017 - val_loss: 69666.5547 - val_mean_absolute_error: 213.8271\n",
      "Epoch 2/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68414.9688 - mean_absolute_error: 210.2693 - val_loss: 69176.3281 - val_mean_absolute_error: 212.7662\n",
      "Epoch 3/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71736.3359 - mean_absolute_error: 214.4248 - val_loss: 68400.8828 - val_mean_absolute_error: 211.1749\n",
      "Epoch 4/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70752.7578 - mean_absolute_error: 212.5756 - val_loss: 67271.6953 - val_mean_absolute_error: 208.9735\n",
      "Epoch 5/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69655.8203 - mean_absolute_error: 211.2254 - val_loss: 65633.0703 - val_mean_absolute_error: 205.8194\n",
      "Epoch 6/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68517.9453 - mean_absolute_error: 205.7141 - val_loss: 63302.8867 - val_mean_absolute_error: 201.4383\n",
      "Epoch 7/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 64282.3125 - mean_absolute_error: 199.9549 - val_loss: 60436.9492 - val_mean_absolute_error: 195.9494\n",
      "Epoch 8/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 60543.8555 - mean_absolute_error: 193.8413 - val_loss: 56698.8828 - val_mean_absolute_error: 188.7263\n",
      "Epoch 9/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 58754.7148 - mean_absolute_error: 188.4077 - val_loss: 52261.7930 - val_mean_absolute_error: 180.0841\n",
      "Epoch 10/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 51812.2891 - mean_absolute_error: 180.0253 - val_loss: 46879.6172 - val_mean_absolute_error: 169.4322\n",
      "Epoch 11/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 50744.7734 - mean_absolute_error: 173.6514 - val_loss: 41143.8047 - val_mean_absolute_error: 157.7862\n",
      "Epoch 12/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 45273.9688 - mean_absolute_error: 162.6208 - val_loss: 34909.3281 - val_mean_absolute_error: 144.8803\n",
      "Epoch 13/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 41588.8672 - mean_absolute_error: 153.4651 - val_loss: 28870.7598 - val_mean_absolute_error: 131.9462\n",
      "Epoch 14/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34143.0664 - mean_absolute_error: 141.6995 - val_loss: 24065.2207 - val_mean_absolute_error: 120.8876\n",
      "Epoch 15/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30972.5254 - mean_absolute_error: 134.5123 - val_loss: 20405.8418 - val_mean_absolute_error: 111.8068\n",
      "Epoch 16/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31166.5195 - mean_absolute_error: 130.9723 - val_loss: 18125.8555 - val_mean_absolute_error: 105.4367\n",
      "Epoch 17/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31366.2539 - mean_absolute_error: 127.9857 - val_loss: 15932.5977 - val_mean_absolute_error: 98.9523\n",
      "Epoch 18/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31695.2402 - mean_absolute_error: 126.5230 - val_loss: 15287.5215 - val_mean_absolute_error: 96.8354\n",
      "Epoch 19/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31256.3477 - mean_absolute_error: 121.4829 - val_loss: 14279.6279 - val_mean_absolute_error: 93.4812\n",
      "Epoch 20/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 29904.9961 - mean_absolute_error: 117.5364 - val_loss: 13913.4990 - val_mean_absolute_error: 92.0335\n",
      "Epoch 21/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27193.6875 - mean_absolute_error: 117.4669 - val_loss: 13515.8711 - val_mean_absolute_error: 90.5155\n",
      "Epoch 22/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 29350.5156 - mean_absolute_error: 117.1384 - val_loss: 13363.2881 - val_mean_absolute_error: 89.6978\n",
      "Epoch 23/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26628.6719 - mean_absolute_error: 113.9168 - val_loss: 13310.1094 - val_mean_absolute_error: 89.1759\n",
      "Epoch 24/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 43898.8398 - mean_absolute_error: 119.0148 - val_loss: 13010.8457 - val_mean_absolute_error: 87.8608\n",
      "Epoch 25/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27461.2637 - mean_absolute_error: 113.4051 - val_loss: 12484.7715 - val_mean_absolute_error: 85.6929\n",
      "Epoch 26/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26430.9160 - mean_absolute_error: 110.9666 - val_loss: 11870.8652 - val_mean_absolute_error: 83.1638\n",
      "Epoch 27/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25908.9414 - mean_absolute_error: 108.6756 - val_loss: 11213.4229 - val_mean_absolute_error: 80.4861\n",
      "Epoch 28/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30488.2910 - mean_absolute_error: 113.3671 - val_loss: 11075.5508 - val_mean_absolute_error: 79.7331\n",
      "Epoch 29/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22619.8301 - mean_absolute_error: 105.4749 - val_loss: 10738.0693 - val_mean_absolute_error: 78.2035\n",
      "Epoch 30/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24403.9824 - mean_absolute_error: 108.6527 - val_loss: 10213.4062 - val_mean_absolute_error: 75.7859\n",
      "Epoch 31/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25505.4062 - mean_absolute_error: 107.2888 - val_loss: 10045.3232 - val_mean_absolute_error: 74.7914\n",
      "Epoch 32/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24068.4941 - mean_absolute_error: 105.2964 - val_loss: 10038.2061 - val_mean_absolute_error: 74.5751\n",
      "Epoch 33/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23687.5078 - mean_absolute_error: 104.3398 - val_loss: 9857.3828 - val_mean_absolute_error: 73.4448\n",
      "Epoch 34/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21171.6602 - mean_absolute_error: 97.5004 - val_loss: 9667.0850 - val_mean_absolute_error: 72.5752\n",
      "Epoch 35/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27307.1855 - mean_absolute_error: 104.0146 - val_loss: 9732.8398 - val_mean_absolute_error: 72.7068\n",
      "Epoch 36/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25618.6172 - mean_absolute_error: 102.3913 - val_loss: 9302.7822 - val_mean_absolute_error: 70.6449\n",
      "Epoch 37/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20916.5352 - mean_absolute_error: 98.5520 - val_loss: 8892.6660 - val_mean_absolute_error: 68.7664\n",
      "Epoch 38/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23916.5918 - mean_absolute_error: 99.7191 - val_loss: 8966.6895 - val_mean_absolute_error: 68.7123\n",
      "Epoch 39/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27055.4707 - mean_absolute_error: 102.1818 - val_loss: 8683.6055 - val_mean_absolute_error: 67.2865\n",
      "Epoch 40/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22546.8516 - mean_absolute_error: 96.7162 - val_loss: 8276.6621 - val_mean_absolute_error: 65.4806\n",
      "Epoch 41/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23481.9609 - mean_absolute_error: 96.4550 - val_loss: 8797.7861 - val_mean_absolute_error: 67.6203\n",
      "Epoch 42/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25368.0195 - mean_absolute_error: 102.1986 - val_loss: 8576.6104 - val_mean_absolute_error: 66.3504\n",
      "Epoch 43/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23123.9746 - mean_absolute_error: 97.2058 - val_loss: 8174.3604 - val_mean_absolute_error: 64.3759\n",
      "Epoch 44/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22793.5137 - mean_absolute_error: 97.8202 - val_loss: 8422.8164 - val_mean_absolute_error: 65.2122\n",
      "Epoch 45/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23534.7988 - mean_absolute_error: 97.1831 - val_loss: 8416.7842 - val_mean_absolute_error: 64.9734\n",
      "Epoch 46/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 18416.6602 - mean_absolute_error: 90.8624 - val_loss: 8133.2764 - val_mean_absolute_error: 63.5677\n",
      "Epoch 47/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25522.0488 - mean_absolute_error: 98.9942 - val_loss: 8108.0576 - val_mean_absolute_error: 63.4237\n",
      "Epoch 48/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28092.8945 - mean_absolute_error: 97.5764 - val_loss: 8153.0210 - val_mean_absolute_error: 63.3859\n",
      "Epoch 49/49\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20069.2637 - mean_absolute_error: 92.2806 - val_loss: 7735.6934 - val_mean_absolute_error: 61.5527\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:58:47,058] Trial 77 finished with value: 62.69976318829059 and parameters: {'layer_1': 3, 'layer_2': 8, 'layer_3': 6, 'learning_rate': 0.0011725890176857874, 'dropout_rate': 0.2921008333437501, 'epoch': 49, 'batch_size': 92, 'optimizer': 'RMSprop'}. Best is trial 67 with value: 21.33154242320284.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 67586.3203 - mean_absolute_error: 207.6316 - val_loss: 43911.5625 - val_mean_absolute_error: 162.7019\n",
      "Epoch 2/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 34379.2695 - mean_absolute_error: 140.9967 - val_loss: 13446.9521 - val_mean_absolute_error: 94.5932\n",
      "Epoch 3/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19340.1777 - mean_absolute_error: 93.4769 - val_loss: 9025.0127 - val_mean_absolute_error: 75.5923\n",
      "Epoch 4/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11091.8418 - mean_absolute_error: 73.1833 - val_loss: 6296.7710 - val_mean_absolute_error: 60.9104\n",
      "Epoch 5/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8619.9082 - mean_absolute_error: 58.2666 - val_loss: 4459.8555 - val_mean_absolute_error: 48.3226\n",
      "Epoch 6/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8353.3467 - mean_absolute_error: 52.3629 - val_loss: 3733.8398 - val_mean_absolute_error: 42.6058\n",
      "Epoch 7/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5378.6030 - mean_absolute_error: 45.7913 - val_loss: 3125.1914 - val_mean_absolute_error: 36.9556\n",
      "Epoch 8/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5707.0391 - mean_absolute_error: 43.5041 - val_loss: 2825.4988 - val_mean_absolute_error: 33.7934\n",
      "Epoch 9/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9084.5957 - mean_absolute_error: 45.4502 - val_loss: 2600.3955 - val_mean_absolute_error: 32.5822\n",
      "Epoch 10/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4396.0366 - mean_absolute_error: 40.6768 - val_loss: 2425.2134 - val_mean_absolute_error: 29.8197\n",
      "Epoch 11/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4988.4360 - mean_absolute_error: 39.5067 - val_loss: 2269.9846 - val_mean_absolute_error: 28.7660\n",
      "Epoch 12/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4351.3984 - mean_absolute_error: 38.1741 - val_loss: 2369.3638 - val_mean_absolute_error: 30.5198\n",
      "Epoch 13/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4423.0317 - mean_absolute_error: 36.6578 - val_loss: 2083.9666 - val_mean_absolute_error: 27.5555\n",
      "Epoch 14/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4617.7666 - mean_absolute_error: 36.4442 - val_loss: 2255.5977 - val_mean_absolute_error: 29.9623\n",
      "Epoch 15/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4885.0659 - mean_absolute_error: 36.1983 - val_loss: 2035.7672 - val_mean_absolute_error: 27.2152\n",
      "Epoch 16/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4790.2397 - mean_absolute_error: 36.2557 - val_loss: 1889.1521 - val_mean_absolute_error: 25.2344\n",
      "Epoch 17/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3682.1252 - mean_absolute_error: 34.5046 - val_loss: 1902.9628 - val_mean_absolute_error: 26.0362\n",
      "Epoch 18/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4600.0000 - mean_absolute_error: 36.0741 - val_loss: 1928.0800 - val_mean_absolute_error: 26.4265\n",
      "Epoch 19/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4904.2461 - mean_absolute_error: 35.0132 - val_loss: 1934.9655 - val_mean_absolute_error: 26.3474\n",
      "Epoch 20/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4286.2397 - mean_absolute_error: 36.4060 - val_loss: 1818.8439 - val_mean_absolute_error: 24.7614\n",
      "Epoch 21/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3787.6201 - mean_absolute_error: 34.0524 - val_loss: 2053.0581 - val_mean_absolute_error: 27.5917\n",
      "Epoch 22/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4542.6577 - mean_absolute_error: 35.8794 - val_loss: 1807.4703 - val_mean_absolute_error: 24.9671\n",
      "Epoch 23/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4264.5913 - mean_absolute_error: 34.6704 - val_loss: 1709.9437 - val_mean_absolute_error: 23.6810\n",
      "Epoch 24/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3987.8457 - mean_absolute_error: 34.5910 - val_loss: 1684.5458 - val_mean_absolute_error: 23.1821\n",
      "Epoch 25/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3745.4917 - mean_absolute_error: 35.0519 - val_loss: 1971.5608 - val_mean_absolute_error: 26.8513\n",
      "Epoch 26/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5587.0464 - mean_absolute_error: 35.7657 - val_loss: 1728.1934 - val_mean_absolute_error: 23.7322\n",
      "Epoch 27/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5289.2109 - mean_absolute_error: 36.3860 - val_loss: 1639.8500 - val_mean_absolute_error: 22.5574\n",
      "Epoch 28/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3966.5049 - mean_absolute_error: 35.6733 - val_loss: 1830.4314 - val_mean_absolute_error: 25.1671\n",
      "Epoch 29/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2866.0320 - mean_absolute_error: 32.5777 - val_loss: 1720.9802 - val_mean_absolute_error: 23.4080\n",
      "Epoch 30/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4329.4219 - mean_absolute_error: 35.8600 - val_loss: 1726.0245 - val_mean_absolute_error: 23.9183\n",
      "Epoch 31/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4112.8491 - mean_absolute_error: 34.1835 - val_loss: 1875.0083 - val_mean_absolute_error: 25.4490\n",
      "Epoch 32/44\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4020.5632 - mean_absolute_error: 33.5913 - val_loss: 1672.6627 - val_mean_absolute_error: 23.0308\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:58:50,798] Trial 78 finished with value: 23.234762167984247 and parameters: {'layer_1': 5, 'layer_2': 7, 'layer_3': 7, 'learning_rate': 0.007994338380523951, 'dropout_rate': 0.03050481068763278, 'epoch': 44, 'batch_size': 98, 'optimizer': 'RMSprop'}. Best is trial 67 with value: 21.33154242320284.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 39181.0938 - mean_absolute_error: 138.6849 - val_loss: 4646.5991 - val_mean_absolute_error: 45.7764\n",
      "Epoch 2/47\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11694.3994 - mean_absolute_error: 61.1823 - val_loss: 3284.1907 - val_mean_absolute_error: 37.4299\n",
      "Epoch 3/47\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10985.1191 - mean_absolute_error: 58.8077 - val_loss: 6073.7764 - val_mean_absolute_error: 51.1418\n",
      "Epoch 4/47\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11820.4922 - mean_absolute_error: 58.4223 - val_loss: 4526.9785 - val_mean_absolute_error: 43.6329\n",
      "Epoch 5/47\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8414.4512 - mean_absolute_error: 54.7876 - val_loss: 2077.2200 - val_mean_absolute_error: 29.0533\n",
      "Epoch 6/47\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8449.2646 - mean_absolute_error: 54.0691 - val_loss: 2063.4045 - val_mean_absolute_error: 27.8682\n",
      "Epoch 7/47\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8487.1699 - mean_absolute_error: 52.6592 - val_loss: 7195.9902 - val_mean_absolute_error: 55.9381\n",
      "Epoch 8/47\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6750.4360 - mean_absolute_error: 52.2264 - val_loss: 1786.8440 - val_mean_absolute_error: 24.1547\n",
      "Epoch 9/47\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8450.8721 - mean_absolute_error: 53.3522 - val_loss: 5237.3970 - val_mean_absolute_error: 49.3994\n",
      "Epoch 10/47\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6231.3198 - mean_absolute_error: 48.7666 - val_loss: 7300.7412 - val_mean_absolute_error: 58.5526\n",
      "Epoch 11/47\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6551.6455 - mean_absolute_error: 50.6052 - val_loss: 4775.7183 - val_mean_absolute_error: 49.4867\n",
      "Epoch 12/47\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6132.6699 - mean_absolute_error: 48.1349 - val_loss: 3661.9341 - val_mean_absolute_error: 45.2138\n",
      "Epoch 13/47\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7148.5547 - mean_absolute_error: 50.1617 - val_loss: 2748.3779 - val_mean_absolute_error: 33.7285\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:58:53,011] Trial 79 finished with value: 25.053255189883707 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 6, 'learning_rate': 0.0486978900613496, 'dropout_rate': 0.08795267580494075, 'epoch': 47, 'batch_size': 76, 'optimizer': 'RMSprop'}. Best is trial 67 with value: 21.33154242320284.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 72379.0312 - mean_absolute_error: 213.3167 - val_loss: 66815.8984 - val_mean_absolute_error: 206.9804\n",
      "Epoch 2/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68019.1172 - mean_absolute_error: 204.7919 - val_loss: 58752.0273 - val_mean_absolute_error: 187.0237\n",
      "Epoch 3/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59512.6289 - mean_absolute_error: 182.7139 - val_loss: 43731.5977 - val_mean_absolute_error: 154.9690\n",
      "Epoch 4/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 43445.6953 - mean_absolute_error: 151.5687 - val_loss: 26273.1289 - val_mean_absolute_error: 121.9634\n",
      "Epoch 5/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28874.5801 - mean_absolute_error: 119.8716 - val_loss: 13796.2227 - val_mean_absolute_error: 90.5331\n",
      "Epoch 6/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15556.2861 - mean_absolute_error: 87.5651 - val_loss: 9660.8545 - val_mean_absolute_error: 70.4324\n",
      "Epoch 7/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13618.2188 - mean_absolute_error: 70.4714 - val_loss: 8291.0283 - val_mean_absolute_error: 63.3729\n",
      "Epoch 8/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19741.4473 - mean_absolute_error: 66.9834 - val_loss: 7337.0918 - val_mean_absolute_error: 57.0276\n",
      "Epoch 9/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9677.1113 - mean_absolute_error: 58.2416 - val_loss: 6293.9458 - val_mean_absolute_error: 53.4005\n",
      "Epoch 10/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9347.9150 - mean_absolute_error: 55.9795 - val_loss: 5548.2212 - val_mean_absolute_error: 49.2146\n",
      "Epoch 11/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10371.6475 - mean_absolute_error: 50.4267 - val_loss: 4965.3750 - val_mean_absolute_error: 46.1971\n",
      "Epoch 12/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8414.5264 - mean_absolute_error: 47.2023 - val_loss: 4468.2671 - val_mean_absolute_error: 43.4875\n",
      "Epoch 13/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6184.1323 - mean_absolute_error: 44.9501 - val_loss: 4029.5852 - val_mean_absolute_error: 40.7433\n",
      "Epoch 14/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6969.1724 - mean_absolute_error: 41.6336 - val_loss: 3713.7227 - val_mean_absolute_error: 39.5770\n",
      "Epoch 15/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6969.7676 - mean_absolute_error: 42.5302 - val_loss: 3459.5876 - val_mean_absolute_error: 36.9883\n",
      "Epoch 16/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10203.6367 - mean_absolute_error: 40.9201 - val_loss: 3242.3616 - val_mean_absolute_error: 35.5569\n",
      "Epoch 17/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4609.5742 - mean_absolute_error: 37.1166 - val_loss: 3047.5176 - val_mean_absolute_error: 35.0552\n",
      "Epoch 18/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4134.9580 - mean_absolute_error: 36.3702 - val_loss: 2893.1045 - val_mean_absolute_error: 33.5548\n",
      "Epoch 19/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5977.9507 - mean_absolute_error: 37.3629 - val_loss: 2752.8628 - val_mean_absolute_error: 32.9930\n",
      "Epoch 20/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4944.9072 - mean_absolute_error: 36.4672 - val_loss: 2647.1548 - val_mean_absolute_error: 32.2093\n",
      "Epoch 21/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3809.2290 - mean_absolute_error: 34.5867 - val_loss: 2540.1282 - val_mean_absolute_error: 31.4483\n",
      "Epoch 22/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5515.7368 - mean_absolute_error: 35.7912 - val_loss: 2459.3242 - val_mean_absolute_error: 30.0119\n",
      "Epoch 23/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3724.0999 - mean_absolute_error: 33.0708 - val_loss: 2419.7756 - val_mean_absolute_error: 30.6103\n",
      "Epoch 24/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3433.4771 - mean_absolute_error: 32.8123 - val_loss: 2335.7058 - val_mean_absolute_error: 29.6213\n",
      "Epoch 25/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3870.8560 - mean_absolute_error: 32.0187 - val_loss: 2281.6301 - val_mean_absolute_error: 29.0708\n",
      "Epoch 26/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3815.0552 - mean_absolute_error: 32.3324 - val_loss: 2237.6179 - val_mean_absolute_error: 28.9034\n",
      "Epoch 27/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3397.8208 - mean_absolute_error: 31.2749 - val_loss: 2190.2681 - val_mean_absolute_error: 28.5669\n",
      "Epoch 28/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3023.9797 - mean_absolute_error: 30.3868 - val_loss: 2130.9536 - val_mean_absolute_error: 28.1257\n",
      "Epoch 29/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3720.5386 - mean_absolute_error: 31.8361 - val_loss: 2091.6780 - val_mean_absolute_error: 27.5312\n",
      "Epoch 30/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4415.5728 - mean_absolute_error: 31.1119 - val_loss: 2050.5483 - val_mean_absolute_error: 27.0743\n",
      "Epoch 31/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2819.3157 - mean_absolute_error: 28.8446 - val_loss: 2057.5476 - val_mean_absolute_error: 27.5459\n",
      "Epoch 32/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3402.1582 - mean_absolute_error: 30.3033 - val_loss: 1957.8265 - val_mean_absolute_error: 26.2141\n",
      "Epoch 33/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2415.7893 - mean_absolute_error: 28.1878 - val_loss: 1951.1628 - val_mean_absolute_error: 26.2280\n",
      "Epoch 34/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3572.5437 - mean_absolute_error: 29.9873 - val_loss: 1913.6294 - val_mean_absolute_error: 25.8259\n",
      "Epoch 35/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4007.5486 - mean_absolute_error: 30.1430 - val_loss: 1872.3677 - val_mean_absolute_error: 25.5415\n",
      "Epoch 36/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2704.4253 - mean_absolute_error: 28.1284 - val_loss: 1830.6112 - val_mean_absolute_error: 24.9212\n",
      "Epoch 37/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3808.0933 - mean_absolute_error: 28.9556 - val_loss: 1875.6847 - val_mean_absolute_error: 25.4420\n",
      "Epoch 38/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5511.0591 - mean_absolute_error: 30.0994 - val_loss: 1853.4265 - val_mean_absolute_error: 25.3854\n",
      "Epoch 39/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2805.1038 - mean_absolute_error: 27.9825 - val_loss: 1774.7910 - val_mean_absolute_error: 24.4911\n",
      "Epoch 40/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2892.1406 - mean_absolute_error: 27.1266 - val_loss: 1757.3700 - val_mean_absolute_error: 24.1325\n",
      "Epoch 41/41\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2785.7598 - mean_absolute_error: 27.1250 - val_loss: 1758.2913 - val_mean_absolute_error: 24.1711\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:58:57,716] Trial 80 finished with value: 24.485160615628956 and parameters: {'layer_1': 6, 'layer_2': 8, 'layer_3': 8, 'learning_rate': 0.002560786666695187, 'dropout_rate': 0.010333672120577198, 'epoch': 41, 'batch_size': 83, 'optimizer': 'RMSprop'}. Best is trial 67 with value: 21.33154242320284.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 71073.2891 - mean_absolute_error: 212.1042 - val_loss: 52398.3242 - val_mean_absolute_error: 177.8674\n",
      "Epoch 2/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 44070.0312 - mean_absolute_error: 158.2956 - val_loss: 16229.7852 - val_mean_absolute_error: 102.5838\n",
      "Epoch 3/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23985.4902 - mean_absolute_error: 99.7522 - val_loss: 9944.1260 - val_mean_absolute_error: 75.2141\n",
      "Epoch 4/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11671.4482 - mean_absolute_error: 70.4287 - val_loss: 6428.4155 - val_mean_absolute_error: 58.3594\n",
      "Epoch 5/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7584.7773 - mean_absolute_error: 54.2575 - val_loss: 4295.9155 - val_mean_absolute_error: 43.2676\n",
      "Epoch 6/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5664.8960 - mean_absolute_error: 45.1607 - val_loss: 3509.0481 - val_mean_absolute_error: 39.7008\n",
      "Epoch 7/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6175.8154 - mean_absolute_error: 42.1892 - val_loss: 2829.3059 - val_mean_absolute_error: 33.4922\n",
      "Epoch 8/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6386.2798 - mean_absolute_error: 39.3536 - val_loss: 2500.2224 - val_mean_absolute_error: 30.8179\n",
      "Epoch 9/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6016.5088 - mean_absolute_error: 37.4514 - val_loss: 2270.9307 - val_mean_absolute_error: 28.6223\n",
      "Epoch 10/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3357.1208 - mean_absolute_error: 32.6922 - val_loss: 2577.6418 - val_mean_absolute_error: 32.4472\n",
      "Epoch 11/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3811.6868 - mean_absolute_error: 32.2929 - val_loss: 1914.3074 - val_mean_absolute_error: 24.9673\n",
      "Epoch 12/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3070.0593 - mean_absolute_error: 30.1724 - val_loss: 1811.8546 - val_mean_absolute_error: 24.3246\n",
      "Epoch 13/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3299.1748 - mean_absolute_error: 30.6021 - val_loss: 1785.6774 - val_mean_absolute_error: 24.4637\n",
      "Epoch 14/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3033.3677 - mean_absolute_error: 29.4674 - val_loss: 1748.0762 - val_mean_absolute_error: 23.7366\n",
      "Epoch 15/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4252.2837 - mean_absolute_error: 29.6253 - val_loss: 1861.3823 - val_mean_absolute_error: 25.0368\n",
      "Epoch 16/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2680.8784 - mean_absolute_error: 27.9791 - val_loss: 1670.7753 - val_mean_absolute_error: 22.2093\n",
      "Epoch 17/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3536.0913 - mean_absolute_error: 28.9146 - val_loss: 1625.1360 - val_mean_absolute_error: 22.0323\n",
      "Epoch 18/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3389.5891 - mean_absolute_error: 29.0940 - val_loss: 1607.8470 - val_mean_absolute_error: 21.5361\n",
      "Epoch 19/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2564.4629 - mean_absolute_error: 27.7982 - val_loss: 1609.0413 - val_mean_absolute_error: 22.0425\n",
      "Epoch 20/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2899.3735 - mean_absolute_error: 28.9568 - val_loss: 1598.0560 - val_mean_absolute_error: 21.3270\n",
      "Epoch 21/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4494.3682 - mean_absolute_error: 31.2467 - val_loss: 1561.4669 - val_mean_absolute_error: 20.8779\n",
      "Epoch 22/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3719.1887 - mean_absolute_error: 28.2211 - val_loss: 2242.6504 - val_mean_absolute_error: 30.1234\n",
      "Epoch 23/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3154.2266 - mean_absolute_error: 28.6838 - val_loss: 1559.7421 - val_mean_absolute_error: 20.9801\n",
      "Epoch 24/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3115.3523 - mean_absolute_error: 28.3566 - val_loss: 1582.0732 - val_mean_absolute_error: 21.3608\n",
      "Epoch 25/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4168.8403 - mean_absolute_error: 29.3799 - val_loss: 1909.4425 - val_mean_absolute_error: 24.7990\n",
      "Epoch 26/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3046.2644 - mean_absolute_error: 27.9096 - val_loss: 1586.5873 - val_mean_absolute_error: 21.0962\n",
      "Epoch 27/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3308.7581 - mean_absolute_error: 29.2237 - val_loss: 1597.0205 - val_mean_absolute_error: 21.5377\n",
      "Epoch 28/46\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2645.0962 - mean_absolute_error: 28.8670 - val_loss: 1591.0878 - val_mean_absolute_error: 21.2526\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:59:01,053] Trial 81 finished with value: 21.62924426652789 and parameters: {'layer_1': 8, 'layer_2': 7, 'layer_3': 8, 'learning_rate': 0.0076580205787403315, 'dropout_rate': 0.01601460943341768, 'epoch': 46, 'batch_size': 99, 'optimizer': 'RMSprop'}. Best is trial 67 with value: 21.33154242320284.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 70592.4531 - mean_absolute_error: 211.3053 - val_loss: 60186.0391 - val_mean_absolute_error: 195.1314\n",
      "Epoch 2/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57524.9023 - mean_absolute_error: 184.8096 - val_loss: 30405.2324 - val_mean_absolute_error: 135.9568\n",
      "Epoch 3/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28145.7520 - mean_absolute_error: 126.1343 - val_loss: 13068.8467 - val_mean_absolute_error: 91.5600\n",
      "Epoch 4/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21839.0918 - mean_absolute_error: 91.6900 - val_loss: 10385.3652 - val_mean_absolute_error: 76.7210\n",
      "Epoch 5/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20063.7422 - mean_absolute_error: 77.0304 - val_loss: 8241.6748 - val_mean_absolute_error: 65.8400\n",
      "Epoch 6/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9882.5186 - mean_absolute_error: 63.0354 - val_loss: 6507.2017 - val_mean_absolute_error: 57.3823\n",
      "Epoch 7/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11368.5361 - mean_absolute_error: 57.2016 - val_loss: 5421.5059 - val_mean_absolute_error: 48.8357\n",
      "Epoch 8/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6426.2070 - mean_absolute_error: 47.0411 - val_loss: 4347.0371 - val_mean_absolute_error: 43.2254\n",
      "Epoch 9/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5629.3311 - mean_absolute_error: 43.0432 - val_loss: 3737.9312 - val_mean_absolute_error: 39.9453\n",
      "Epoch 10/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4842.1055 - mean_absolute_error: 39.9742 - val_loss: 3295.5542 - val_mean_absolute_error: 37.7310\n",
      "Epoch 11/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4173.9736 - mean_absolute_error: 36.7816 - val_loss: 2997.0352 - val_mean_absolute_error: 34.4513\n",
      "Epoch 12/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4615.0830 - mean_absolute_error: 34.4659 - val_loss: 2708.5732 - val_mean_absolute_error: 32.8673\n",
      "Epoch 13/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3917.1736 - mean_absolute_error: 33.3539 - val_loss: 2524.5271 - val_mean_absolute_error: 31.4484\n",
      "Epoch 14/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4796.6035 - mean_absolute_error: 31.8236 - val_loss: 2348.1902 - val_mean_absolute_error: 29.2922\n",
      "Epoch 15/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3488.7537 - mean_absolute_error: 29.1152 - val_loss: 2223.9878 - val_mean_absolute_error: 28.1617\n",
      "Epoch 16/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3967.4062 - mean_absolute_error: 29.5992 - val_loss: 2116.2190 - val_mean_absolute_error: 27.3624\n",
      "Epoch 17/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3726.7341 - mean_absolute_error: 28.0709 - val_loss: 2037.3307 - val_mean_absolute_error: 26.0384\n",
      "Epoch 18/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3091.8396 - mean_absolute_error: 26.6072 - val_loss: 1892.1786 - val_mean_absolute_error: 24.6612\n",
      "Epoch 19/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2736.8579 - mean_absolute_error: 25.7134 - val_loss: 1846.5948 - val_mean_absolute_error: 24.7226\n",
      "Epoch 20/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3709.5356 - mean_absolute_error: 27.2201 - val_loss: 1785.2783 - val_mean_absolute_error: 23.9467\n",
      "Epoch 21/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2880.1572 - mean_absolute_error: 24.6083 - val_loss: 1790.5527 - val_mean_absolute_error: 23.8805\n",
      "Epoch 22/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5671.2690 - mean_absolute_error: 26.4491 - val_loss: 1776.7527 - val_mean_absolute_error: 23.6826\n",
      "Epoch 23/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3226.9741 - mean_absolute_error: 24.3909 - val_loss: 1662.2728 - val_mean_absolute_error: 21.8993\n",
      "Epoch 24/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4114.0283 - mean_absolute_error: 24.6115 - val_loss: 1803.7928 - val_mean_absolute_error: 23.8842\n",
      "Epoch 25/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3560.9504 - mean_absolute_error: 24.5640 - val_loss: 1607.5562 - val_mean_absolute_error: 21.4587\n",
      "Epoch 26/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2150.0278 - mean_absolute_error: 22.2632 - val_loss: 1597.0667 - val_mean_absolute_error: 21.2592\n",
      "Epoch 27/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4478.4043 - mean_absolute_error: 24.5438 - val_loss: 1591.3307 - val_mean_absolute_error: 21.0392\n",
      "Epoch 28/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2303.9229 - mean_absolute_error: 22.0309 - val_loss: 1593.7789 - val_mean_absolute_error: 21.0038\n",
      "Epoch 29/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2302.7471 - mean_absolute_error: 21.7177 - val_loss: 1585.7144 - val_mean_absolute_error: 21.1363\n",
      "Epoch 30/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2215.4836 - mean_absolute_error: 22.2446 - val_loss: 1598.6531 - val_mean_absolute_error: 21.2380\n",
      "Epoch 31/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1828.7261 - mean_absolute_error: 21.5445 - val_loss: 1582.9250 - val_mean_absolute_error: 21.1410\n",
      "Epoch 32/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3204.7544 - mean_absolute_error: 23.3986 - val_loss: 1594.1406 - val_mean_absolute_error: 21.7035\n",
      "Epoch 33/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2291.9028 - mean_absolute_error: 22.5090 - val_loss: 1558.6577 - val_mean_absolute_error: 20.5958\n",
      "Epoch 34/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2299.4526 - mean_absolute_error: 22.3785 - val_loss: 1624.3324 - val_mean_absolute_error: 21.3074\n",
      "Epoch 35/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3503.3867 - mean_absolute_error: 23.6931 - val_loss: 1667.3940 - val_mean_absolute_error: 21.9769\n",
      "Epoch 36/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2584.8362 - mean_absolute_error: 22.1563 - val_loss: 1573.6886 - val_mean_absolute_error: 20.7866\n",
      "Epoch 37/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2650.4739 - mean_absolute_error: 22.2499 - val_loss: 1605.1420 - val_mean_absolute_error: 21.0631\n",
      "Epoch 38/46\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2228.1165 - mean_absolute_error: 21.8908 - val_loss: 1568.3680 - val_mean_absolute_error: 20.5517\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:59:05,302] Trial 82 finished with value: 21.198321127447485 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 8, 'learning_rate': 0.004151214775167525, 'dropout_rate': 0.0008759686785751964, 'epoch': 46, 'batch_size': 94, 'optimizer': 'RMSprop'}. Best is trial 82 with value: 21.198321127447485.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 72669.3359 - mean_absolute_error: 216.8929 - val_loss: 62306.0195 - val_mean_absolute_error: 202.8396\n",
      "Epoch 2/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 60847.9688 - mean_absolute_error: 198.6282 - val_loss: 35930.1055 - val_mean_absolute_error: 156.9596\n",
      "Epoch 3/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34539.9180 - mean_absolute_error: 146.3710 - val_loss: 14726.7656 - val_mean_absolute_error: 95.6444\n",
      "Epoch 4/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19371.8047 - mean_absolute_error: 92.5819 - val_loss: 10914.6543 - val_mean_absolute_error: 79.6356\n",
      "Epoch 5/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12515.0049 - mean_absolute_error: 77.3480 - val_loss: 8643.0166 - val_mean_absolute_error: 69.4216\n",
      "Epoch 6/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14409.6865 - mean_absolute_error: 70.0176 - val_loss: 7160.0625 - val_mean_absolute_error: 60.4973\n",
      "Epoch 7/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8782.9258 - mean_absolute_error: 58.2933 - val_loss: 5901.5396 - val_mean_absolute_error: 53.6351\n",
      "Epoch 8/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7193.2632 - mean_absolute_error: 50.6316 - val_loss: 5081.4395 - val_mean_absolute_error: 48.9224\n",
      "Epoch 9/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8215.8652 - mean_absolute_error: 48.0633 - val_loss: 4835.7949 - val_mean_absolute_error: 43.3832\n",
      "Epoch 10/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6163.8315 - mean_absolute_error: 42.9709 - val_loss: 3986.4612 - val_mean_absolute_error: 40.4692\n",
      "Epoch 11/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6436.2529 - mean_absolute_error: 40.7068 - val_loss: 4066.7927 - val_mean_absolute_error: 38.6186\n",
      "Epoch 12/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13107.0635 - mean_absolute_error: 41.8580 - val_loss: 3628.6155 - val_mean_absolute_error: 38.1451\n",
      "Epoch 13/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4296.3237 - mean_absolute_error: 37.6455 - val_loss: 3483.5161 - val_mean_absolute_error: 37.3900\n",
      "Epoch 14/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6048.5391 - mean_absolute_error: 39.1435 - val_loss: 3585.7056 - val_mean_absolute_error: 36.1899\n",
      "Epoch 15/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5368.6733 - mean_absolute_error: 37.0909 - val_loss: 3319.4282 - val_mean_absolute_error: 35.4774\n",
      "Epoch 16/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5003.7847 - mean_absolute_error: 35.9431 - val_loss: 3210.8267 - val_mean_absolute_error: 35.3894\n",
      "Epoch 17/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4015.4954 - mean_absolute_error: 35.5228 - val_loss: 3143.0862 - val_mean_absolute_error: 35.1291\n",
      "Epoch 18/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4239.2002 - mean_absolute_error: 35.4151 - val_loss: 3145.4207 - val_mean_absolute_error: 35.0260\n",
      "Epoch 19/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3352.3926 - mean_absolute_error: 33.8016 - val_loss: 2999.7141 - val_mean_absolute_error: 34.0575\n",
      "Epoch 20/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4189.8521 - mean_absolute_error: 34.6006 - val_loss: 2999.2200 - val_mean_absolute_error: 33.3784\n",
      "Epoch 21/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5990.7007 - mean_absolute_error: 34.8787 - val_loss: 2858.9751 - val_mean_absolute_error: 33.1905\n",
      "Epoch 22/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2892.1548 - mean_absolute_error: 32.6256 - val_loss: 2754.7249 - val_mean_absolute_error: 32.5482\n",
      "Epoch 23/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5461.4150 - mean_absolute_error: 33.7034 - val_loss: 2674.5527 - val_mean_absolute_error: 32.0756\n",
      "Epoch 24/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3805.1106 - mean_absolute_error: 32.1726 - val_loss: 2600.0942 - val_mean_absolute_error: 31.5811\n",
      "Epoch 25/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3463.4834 - mean_absolute_error: 32.2312 - val_loss: 2663.3669 - val_mean_absolute_error: 32.3562\n",
      "Epoch 26/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5245.7983 - mean_absolute_error: 32.9904 - val_loss: 2496.3662 - val_mean_absolute_error: 30.4230\n",
      "Epoch 27/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2428.7786 - mean_absolute_error: 29.5636 - val_loss: 2424.0525 - val_mean_absolute_error: 30.2011\n",
      "Epoch 28/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3233.8872 - mean_absolute_error: 29.8622 - val_loss: 2328.3489 - val_mean_absolute_error: 29.3719\n",
      "Epoch 29/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3675.8628 - mean_absolute_error: 29.6418 - val_loss: 2297.9583 - val_mean_absolute_error: 29.3027\n",
      "Epoch 30/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3935.5422 - mean_absolute_error: 29.6877 - val_loss: 2228.8264 - val_mean_absolute_error: 28.1859\n",
      "Epoch 31/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3457.0979 - mean_absolute_error: 28.7867 - val_loss: 2156.6519 - val_mean_absolute_error: 27.6030\n",
      "Epoch 32/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2827.8750 - mean_absolute_error: 27.9410 - val_loss: 2143.0273 - val_mean_absolute_error: 27.7295\n",
      "Epoch 33/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2498.4133 - mean_absolute_error: 27.0123 - val_loss: 2032.2009 - val_mean_absolute_error: 26.6618\n",
      "Epoch 34/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2136.1912 - mean_absolute_error: 26.2969 - val_loss: 1994.1560 - val_mean_absolute_error: 26.1441\n",
      "Epoch 35/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2111.3484 - mean_absolute_error: 25.3554 - val_loss: 2121.5203 - val_mean_absolute_error: 27.6674\n",
      "Epoch 36/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2923.9924 - mean_absolute_error: 26.0146 - val_loss: 2033.8638 - val_mean_absolute_error: 27.0194\n",
      "Epoch 37/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2351.0103 - mean_absolute_error: 24.9560 - val_loss: 1872.6738 - val_mean_absolute_error: 24.9896\n",
      "Epoch 38/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2041.8882 - mean_absolute_error: 25.2711 - val_loss: 1826.0203 - val_mean_absolute_error: 24.3293\n",
      "Epoch 39/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3799.8098 - mean_absolute_error: 25.1351 - val_loss: 1941.3088 - val_mean_absolute_error: 25.7611\n",
      "Epoch 40/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3169.9634 - mean_absolute_error: 25.0580 - val_loss: 1750.2410 - val_mean_absolute_error: 23.0994\n",
      "Epoch 41/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2198.4832 - mean_absolute_error: 23.3810 - val_loss: 1817.1729 - val_mean_absolute_error: 24.0965\n",
      "Epoch 42/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2975.6079 - mean_absolute_error: 23.7606 - val_loss: 1807.3065 - val_mean_absolute_error: 24.4068\n",
      "Epoch 43/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2915.8130 - mean_absolute_error: 24.3985 - val_loss: 1640.8431 - val_mean_absolute_error: 21.7911\n",
      "Epoch 44/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2393.3857 - mean_absolute_error: 21.7993 - val_loss: 1619.3702 - val_mean_absolute_error: 21.4879\n",
      "Epoch 45/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2166.1040 - mean_absolute_error: 21.8777 - val_loss: 1637.1371 - val_mean_absolute_error: 21.5848\n",
      "Epoch 46/46\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3058.1179 - mean_absolute_error: 22.6291 - val_loss: 1632.6958 - val_mean_absolute_error: 21.8604\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:59:10,337] Trial 83 finished with value: 22.02532310203016 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 8, 'learning_rate': 0.004283056468733703, 'dropout_rate': 6.43248342181409e-05, 'epoch': 46, 'batch_size': 89, 'optimizer': 'RMSprop'}. Best is trial 82 with value: 21.198321127447485.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 73847.2500 - mean_absolute_error: 217.2119 - val_loss: 69906.7109 - val_mean_absolute_error: 214.4381\n",
      "Epoch 2/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72955.9609 - mean_absolute_error: 214.7563 - val_loss: 69525.8750 - val_mean_absolute_error: 213.7761\n",
      "Epoch 3/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75580.3906 - mean_absolute_error: 219.5388 - val_loss: 68631.7734 - val_mean_absolute_error: 212.4007\n",
      "Epoch 4/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73967.2031 - mean_absolute_error: 217.9471 - val_loss: 67061.3438 - val_mean_absolute_error: 210.0757\n",
      "Epoch 5/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68477.9375 - mean_absolute_error: 209.1804 - val_loss: 64188.2773 - val_mean_absolute_error: 205.9932\n",
      "Epoch 6/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65398.8984 - mean_absolute_error: 205.4521 - val_loss: 59666.9453 - val_mean_absolute_error: 199.5557\n",
      "Epoch 7/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59007.9102 - mean_absolute_error: 197.2960 - val_loss: 52711.0156 - val_mean_absolute_error: 189.2773\n",
      "Epoch 8/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54451.4102 - mean_absolute_error: 191.3029 - val_loss: 44320.2422 - val_mean_absolute_error: 175.8882\n",
      "Epoch 9/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 46035.0898 - mean_absolute_error: 175.4943 - val_loss: 34063.4336 - val_mean_absolute_error: 156.9317\n",
      "Epoch 10/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33598.0625 - mean_absolute_error: 152.6839 - val_loss: 24973.7266 - val_mean_absolute_error: 135.8782\n",
      "Epoch 11/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27826.0176 - mean_absolute_error: 136.7616 - val_loss: 18672.5059 - val_mean_absolute_error: 116.4988\n",
      "Epoch 12/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19738.0996 - mean_absolute_error: 114.6993 - val_loss: 15802.1621 - val_mean_absolute_error: 105.0116\n",
      "Epoch 13/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19560.7227 - mean_absolute_error: 106.0944 - val_loss: 14040.9590 - val_mean_absolute_error: 96.8975\n",
      "Epoch 14/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 17732.2734 - mean_absolute_error: 96.7810 - val_loss: 12459.1865 - val_mean_absolute_error: 88.8560\n",
      "Epoch 15/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15470.9424 - mean_absolute_error: 91.8815 - val_loss: 11137.9014 - val_mean_absolute_error: 82.3772\n",
      "Epoch 16/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14917.7861 - mean_absolute_error: 85.4120 - val_loss: 9870.9248 - val_mean_absolute_error: 75.8526\n",
      "Epoch 17/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14968.9170 - mean_absolute_error: 81.4336 - val_loss: 8864.1943 - val_mean_absolute_error: 71.3471\n",
      "Epoch 18/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12772.6367 - mean_absolute_error: 77.8935 - val_loss: 8102.8740 - val_mean_absolute_error: 67.4601\n",
      "Epoch 19/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12714.0312 - mean_absolute_error: 73.7007 - val_loss: 7424.3594 - val_mean_absolute_error: 63.6362\n",
      "Epoch 20/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15715.9990 - mean_absolute_error: 71.4367 - val_loss: 7017.4326 - val_mean_absolute_error: 61.5981\n",
      "Epoch 21/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9976.2773 - mean_absolute_error: 65.2056 - val_loss: 6523.2837 - val_mean_absolute_error: 58.7058\n",
      "Epoch 22/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13000.2646 - mean_absolute_error: 66.1961 - val_loss: 6226.8726 - val_mean_absolute_error: 57.3404\n",
      "Epoch 23/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11788.8018 - mean_absolute_error: 65.0322 - val_loss: 5884.7744 - val_mean_absolute_error: 55.1126\n",
      "Epoch 24/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12487.4658 - mean_absolute_error: 64.2614 - val_loss: 5543.4155 - val_mean_absolute_error: 52.4706\n",
      "Epoch 25/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8289.8711 - mean_absolute_error: 58.6889 - val_loss: 5292.7402 - val_mean_absolute_error: 50.8060\n",
      "Epoch 26/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8042.5991 - mean_absolute_error: 56.7893 - val_loss: 5054.9590 - val_mean_absolute_error: 49.1063\n",
      "Epoch 27/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7595.1802 - mean_absolute_error: 55.8257 - val_loss: 4851.7944 - val_mean_absolute_error: 48.0226\n",
      "Epoch 28/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9808.2285 - mean_absolute_error: 57.0866 - val_loss: 4647.4761 - val_mean_absolute_error: 46.1770\n",
      "Epoch 29/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9521.9238 - mean_absolute_error: 56.4086 - val_loss: 4487.0918 - val_mean_absolute_error: 45.0469\n",
      "Epoch 30/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10150.9609 - mean_absolute_error: 53.6391 - val_loss: 4344.4570 - val_mean_absolute_error: 44.0259\n",
      "Epoch 31/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6926.4019 - mean_absolute_error: 51.1463 - val_loss: 4192.0571 - val_mean_absolute_error: 42.6740\n",
      "Epoch 32/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8136.5454 - mean_absolute_error: 52.4988 - val_loss: 4109.5894 - val_mean_absolute_error: 42.3052\n",
      "Epoch 33/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9623.7334 - mean_absolute_error: 51.9613 - val_loss: 3995.6165 - val_mean_absolute_error: 41.1491\n",
      "Epoch 34/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7656.2642 - mean_absolute_error: 50.6290 - val_loss: 3951.6194 - val_mean_absolute_error: 41.0814\n",
      "Epoch 35/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7048.0835 - mean_absolute_error: 49.7934 - val_loss: 3904.3706 - val_mean_absolute_error: 40.7718\n",
      "Epoch 36/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7880.8647 - mean_absolute_error: 49.7717 - val_loss: 3987.6567 - val_mean_absolute_error: 41.6150\n",
      "Epoch 37/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5889.3931 - mean_absolute_error: 48.3635 - val_loss: 3807.0110 - val_mean_absolute_error: 39.9864\n",
      "Epoch 38/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8147.5498 - mean_absolute_error: 51.2072 - val_loss: 3719.2092 - val_mean_absolute_error: 39.2867\n",
      "Epoch 39/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5742.8276 - mean_absolute_error: 47.5678 - val_loss: 3749.0535 - val_mean_absolute_error: 39.8621\n",
      "Epoch 40/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6466.1069 - mean_absolute_error: 47.9334 - val_loss: 3616.5398 - val_mean_absolute_error: 38.4304\n",
      "Epoch 41/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9477.8633 - mean_absolute_error: 49.5022 - val_loss: 3689.1748 - val_mean_absolute_error: 39.3690\n",
      "Epoch 42/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6167.2368 - mean_absolute_error: 47.6166 - val_loss: 3558.6521 - val_mean_absolute_error: 37.9804\n",
      "Epoch 43/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6499.2656 - mean_absolute_error: 48.9536 - val_loss: 3625.1775 - val_mean_absolute_error: 38.8633\n",
      "Epoch 44/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7643.4336 - mean_absolute_error: 50.3919 - val_loss: 3505.7964 - val_mean_absolute_error: 37.4686\n",
      "Epoch 45/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8322.1025 - mean_absolute_error: 49.0459 - val_loss: 3592.5649 - val_mean_absolute_error: 38.6468\n",
      "Epoch 46/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5174.5684 - mean_absolute_error: 44.9152 - val_loss: 3491.1655 - val_mean_absolute_error: 37.7413\n",
      "Epoch 47/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6186.0732 - mean_absolute_error: 47.7285 - val_loss: 3543.8877 - val_mean_absolute_error: 38.5200\n",
      "Epoch 48/48\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6148.3188 - mean_absolute_error: 47.9785 - val_loss: 3554.8677 - val_mean_absolute_error: 38.7203\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:59:15,466] Trial 84 finished with value: 38.008235237336166 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 8, 'learning_rate': 0.0016906571019653966, 'dropout_rate': 0.04724103483337315, 'epoch': 48, 'batch_size': 95, 'optimizer': 'RMSprop'}. Best is trial 82 with value: 21.198321127447485.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 70804.2969 - mean_absolute_error: 209.6943 - val_loss: 43891.8555 - val_mean_absolute_error: 167.4810\n",
      "Epoch 2/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 33438.4961 - mean_absolute_error: 141.5143 - val_loss: 14101.6113 - val_mean_absolute_error: 94.1753\n",
      "Epoch 3/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19910.7031 - mean_absolute_error: 92.7008 - val_loss: 9781.4961 - val_mean_absolute_error: 77.6472\n",
      "Epoch 4/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11910.3340 - mean_absolute_error: 72.3318 - val_loss: 6802.7290 - val_mean_absolute_error: 61.2695\n",
      "Epoch 5/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7675.6074 - mean_absolute_error: 58.2239 - val_loss: 5247.7163 - val_mean_absolute_error: 50.4559\n",
      "Epoch 6/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6599.3940 - mean_absolute_error: 48.7683 - val_loss: 4321.5293 - val_mean_absolute_error: 42.4983\n",
      "Epoch 7/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8737.2969 - mean_absolute_error: 48.5730 - val_loss: 3968.6604 - val_mean_absolute_error: 41.0198\n",
      "Epoch 8/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7577.6821 - mean_absolute_error: 43.1938 - val_loss: 3555.1150 - val_mean_absolute_error: 38.4069\n",
      "Epoch 9/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7759.2554 - mean_absolute_error: 43.1275 - val_loss: 3306.7925 - val_mean_absolute_error: 35.8654\n",
      "Epoch 10/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5085.8608 - mean_absolute_error: 41.3869 - val_loss: 3342.3943 - val_mean_absolute_error: 36.7997\n",
      "Epoch 11/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5121.3452 - mean_absolute_error: 39.1722 - val_loss: 3150.4177 - val_mean_absolute_error: 35.8857\n",
      "Epoch 12/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5132.8130 - mean_absolute_error: 38.5436 - val_loss: 2785.2390 - val_mean_absolute_error: 32.6401\n",
      "Epoch 13/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5037.1450 - mean_absolute_error: 38.0081 - val_loss: 3184.8306 - val_mean_absolute_error: 36.2677\n",
      "Epoch 14/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3967.4944 - mean_absolute_error: 37.2130 - val_loss: 2498.0701 - val_mean_absolute_error: 30.5085\n",
      "Epoch 15/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4130.8301 - mean_absolute_error: 36.2547 - val_loss: 2541.0537 - val_mean_absolute_error: 31.1423\n",
      "Epoch 16/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3881.4023 - mean_absolute_error: 35.7829 - val_loss: 2257.2119 - val_mean_absolute_error: 28.6814\n",
      "Epoch 17/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4947.0225 - mean_absolute_error: 36.5653 - val_loss: 2184.7810 - val_mean_absolute_error: 27.6336\n",
      "Epoch 18/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3498.1016 - mean_absolute_error: 32.7516 - val_loss: 2166.4790 - val_mean_absolute_error: 28.0527\n",
      "Epoch 19/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3195.5947 - mean_absolute_error: 33.0696 - val_loss: 1907.9581 - val_mean_absolute_error: 24.8152\n",
      "Epoch 20/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4402.0874 - mean_absolute_error: 32.5298 - val_loss: 1921.0007 - val_mean_absolute_error: 25.4818\n",
      "Epoch 21/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3005.5425 - mean_absolute_error: 32.0273 - val_loss: 1861.2758 - val_mean_absolute_error: 24.9104\n",
      "Epoch 22/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3272.7690 - mean_absolute_error: 30.0999 - val_loss: 1839.1836 - val_mean_absolute_error: 24.5969\n",
      "Epoch 23/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2977.8052 - mean_absolute_error: 31.5091 - val_loss: 1730.8492 - val_mean_absolute_error: 23.0972\n",
      "Epoch 24/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3602.0386 - mean_absolute_error: 31.3501 - val_loss: 1795.0933 - val_mean_absolute_error: 23.9063\n",
      "Epoch 25/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3694.1633 - mean_absolute_error: 32.1306 - val_loss: 1841.8353 - val_mean_absolute_error: 24.5033\n",
      "Epoch 26/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3636.1021 - mean_absolute_error: 31.3778 - val_loss: 1770.9501 - val_mean_absolute_error: 23.7826\n",
      "Epoch 27/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2577.5747 - mean_absolute_error: 29.9964 - val_loss: 1685.9044 - val_mean_absolute_error: 22.6650\n",
      "Epoch 28/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4307.3491 - mean_absolute_error: 30.4570 - val_loss: 1814.3197 - val_mean_absolute_error: 24.5990\n",
      "Epoch 29/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4352.0923 - mean_absolute_error: 31.3444 - val_loss: 1629.7509 - val_mean_absolute_error: 22.0276\n",
      "Epoch 30/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2924.2500 - mean_absolute_error: 30.9612 - val_loss: 1627.6388 - val_mean_absolute_error: 21.8833\n",
      "Epoch 31/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3254.9351 - mean_absolute_error: 30.1833 - val_loss: 1690.8134 - val_mean_absolute_error: 22.9559\n",
      "Epoch 32/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2891.8328 - mean_absolute_error: 30.3402 - val_loss: 1705.8381 - val_mean_absolute_error: 23.1133\n",
      "Epoch 33/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4124.6509 - mean_absolute_error: 31.3230 - val_loss: 1598.4963 - val_mean_absolute_error: 21.4798\n",
      "Epoch 34/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3449.4548 - mean_absolute_error: 30.3540 - val_loss: 1641.9976 - val_mean_absolute_error: 22.1147\n",
      "Epoch 35/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3229.6978 - mean_absolute_error: 30.2210 - val_loss: 1660.7417 - val_mean_absolute_error: 22.3916\n",
      "Epoch 36/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3033.2498 - mean_absolute_error: 30.2513 - val_loss: 1640.0621 - val_mean_absolute_error: 22.4814\n",
      "Epoch 37/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3296.3320 - mean_absolute_error: 30.4357 - val_loss: 1655.4989 - val_mean_absolute_error: 22.3746\n",
      "Epoch 38/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2935.6086 - mean_absolute_error: 30.1687 - val_loss: 1608.5918 - val_mean_absolute_error: 21.8184\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:59:19,643] Trial 85 finished with value: 22.29114323770404 and parameters: {'layer_1': 8, 'layer_2': 7, 'layer_3': 8, 'learning_rate': 0.0064073529376790506, 'dropout_rate': 0.025577617705735113, 'epoch': 50, 'batch_size': 100, 'optimizer': 'RMSprop'}. Best is trial 82 with value: 21.198321127447485.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 72780.5078 - mean_absolute_error: 214.0736 - val_loss: 57649.6797 - val_mean_absolute_error: 195.9160\n",
      "Epoch 2/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52236.5977 - mean_absolute_error: 186.8286 - val_loss: 34857.6484 - val_mean_absolute_error: 154.7248\n",
      "Epoch 3/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31885.6445 - mean_absolute_error: 144.7173 - val_loss: 20275.7832 - val_mean_absolute_error: 116.1173\n",
      "Epoch 4/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19828.1270 - mean_absolute_error: 112.6749 - val_loss: 14473.7773 - val_mean_absolute_error: 96.6475\n",
      "Epoch 5/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19032.3340 - mean_absolute_error: 97.6256 - val_loss: 12347.0322 - val_mean_absolute_error: 87.7615\n",
      "Epoch 6/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 17910.8516 - mean_absolute_error: 89.7806 - val_loss: 11302.3672 - val_mean_absolute_error: 82.8838\n",
      "Epoch 7/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13203.7217 - mean_absolute_error: 83.9438 - val_loss: 10551.8096 - val_mean_absolute_error: 79.6768\n",
      "Epoch 8/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13167.7822 - mean_absolute_error: 80.4411 - val_loss: 9942.8965 - val_mean_absolute_error: 76.8662\n",
      "Epoch 9/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12192.2051 - mean_absolute_error: 78.1743 - val_loss: 9415.4268 - val_mean_absolute_error: 74.1449\n",
      "Epoch 10/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13362.9834 - mean_absolute_error: 77.4109 - val_loss: 8950.7383 - val_mean_absolute_error: 71.4503\n",
      "Epoch 11/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11077.5615 - mean_absolute_error: 73.0816 - val_loss: 8562.2998 - val_mean_absolute_error: 69.6844\n",
      "Epoch 12/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11368.1953 - mean_absolute_error: 73.3614 - val_loss: 8177.1133 - val_mean_absolute_error: 67.0497\n",
      "Epoch 13/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10747.0117 - mean_absolute_error: 68.2734 - val_loss: 7870.9102 - val_mean_absolute_error: 65.2736\n",
      "Epoch 14/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10908.5752 - mean_absolute_error: 67.8637 - val_loss: 7599.4810 - val_mean_absolute_error: 63.9663\n",
      "Epoch 15/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11267.2812 - mean_absolute_error: 67.9279 - val_loss: 7339.4702 - val_mean_absolute_error: 62.2607\n",
      "Epoch 16/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12277.9043 - mean_absolute_error: 65.6627 - val_loss: 7108.8672 - val_mean_absolute_error: 61.1012\n",
      "Epoch 17/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8597.7793 - mean_absolute_error: 62.3527 - val_loss: 6951.1255 - val_mean_absolute_error: 61.2221\n",
      "Epoch 18/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7802.8799 - mean_absolute_error: 61.8076 - val_loss: 6697.1797 - val_mean_absolute_error: 59.3763\n",
      "Epoch 19/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8644.4346 - mean_absolute_error: 59.6769 - val_loss: 6508.0601 - val_mean_absolute_error: 58.1109\n",
      "Epoch 20/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8794.4150 - mean_absolute_error: 60.9550 - val_loss: 6329.3906 - val_mean_absolute_error: 56.9827\n",
      "Epoch 21/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9437.3252 - mean_absolute_error: 61.5024 - val_loss: 6165.7358 - val_mean_absolute_error: 55.6587\n",
      "Epoch 22/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7029.9697 - mean_absolute_error: 56.2890 - val_loss: 6019.3584 - val_mean_absolute_error: 55.0830\n",
      "Epoch 23/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8921.7031 - mean_absolute_error: 56.7689 - val_loss: 5861.7666 - val_mean_absolute_error: 54.0264\n",
      "Epoch 24/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8036.8364 - mean_absolute_error: 55.4909 - val_loss: 5709.1426 - val_mean_absolute_error: 52.7858\n",
      "Epoch 25/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8317.3838 - mean_absolute_error: 54.7408 - val_loss: 5555.6187 - val_mean_absolute_error: 51.6200\n",
      "Epoch 26/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7050.5195 - mean_absolute_error: 52.2597 - val_loss: 5419.9424 - val_mean_absolute_error: 50.7559\n",
      "Epoch 27/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6837.4146 - mean_absolute_error: 52.1169 - val_loss: 5304.8848 - val_mean_absolute_error: 50.9498\n",
      "Epoch 28/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6172.3330 - mean_absolute_error: 52.1242 - val_loss: 5161.9624 - val_mean_absolute_error: 49.6672\n",
      "Epoch 29/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6286.0571 - mean_absolute_error: 48.8429 - val_loss: 5046.5469 - val_mean_absolute_error: 48.6630\n",
      "Epoch 30/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6423.5679 - mean_absolute_error: 50.6837 - val_loss: 4948.7324 - val_mean_absolute_error: 47.8677\n",
      "Epoch 31/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7458.3315 - mean_absolute_error: 49.9872 - val_loss: 4862.8081 - val_mean_absolute_error: 47.2645\n",
      "Epoch 32/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7400.3647 - mean_absolute_error: 50.3228 - val_loss: 4786.1475 - val_mean_absolute_error: 46.8306\n",
      "Epoch 33/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7759.0503 - mean_absolute_error: 51.1287 - val_loss: 4711.5073 - val_mean_absolute_error: 46.2341\n",
      "Epoch 34/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6109.1592 - mean_absolute_error: 48.0471 - val_loss: 4644.3379 - val_mean_absolute_error: 46.0059\n",
      "Epoch 35/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6004.6069 - mean_absolute_error: 48.7906 - val_loss: 4575.8320 - val_mean_absolute_error: 45.4859\n",
      "Epoch 36/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6806.2168 - mean_absolute_error: 48.4441 - val_loss: 4511.0303 - val_mean_absolute_error: 45.0131\n",
      "Epoch 37/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5743.8174 - mean_absolute_error: 46.6623 - val_loss: 4449.8325 - val_mean_absolute_error: 44.6752\n",
      "Epoch 38/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5692.0762 - mean_absolute_error: 46.6271 - val_loss: 4387.7412 - val_mean_absolute_error: 44.3088\n",
      "Epoch 39/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5120.8037 - mean_absolute_error: 44.5299 - val_loss: 4332.1465 - val_mean_absolute_error: 44.0138\n",
      "Epoch 40/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5513.3550 - mean_absolute_error: 45.6685 - val_loss: 4279.8818 - val_mean_absolute_error: 43.6438\n",
      "Epoch 41/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5194.9570 - mean_absolute_error: 45.5243 - val_loss: 4232.3662 - val_mean_absolute_error: 43.4858\n",
      "Epoch 42/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4879.9629 - mean_absolute_error: 44.8649 - val_loss: 4176.4150 - val_mean_absolute_error: 43.0332\n",
      "Epoch 43/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6474.3062 - mean_absolute_error: 45.9702 - val_loss: 4127.9062 - val_mean_absolute_error: 42.6849\n",
      "Epoch 44/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6206.5430 - mean_absolute_error: 45.6336 - val_loss: 4081.6318 - val_mean_absolute_error: 42.5069\n",
      "Epoch 45/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5750.7725 - mean_absolute_error: 44.6525 - val_loss: 4032.5496 - val_mean_absolute_error: 42.2137\n",
      "Epoch 46/46\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5591.3369 - mean_absolute_error: 45.8742 - val_loss: 3985.5850 - val_mean_absolute_error: 41.7961\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:59:24,572] Trial 86 finished with value: 40.85242946580052 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 8, 'learning_rate': 0.016181299691093175, 'dropout_rate': 0.021165428692617304, 'epoch': 46, 'batch_size': 93, 'optimizer': 'Adagrad'}. Best is trial 82 with value: 21.198321127447485.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 73724.5781 - mean_absolute_error: 216.7958 - val_loss: 61879.1992 - val_mean_absolute_error: 202.7874\n",
      "Epoch 2/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55413.5547 - mean_absolute_error: 191.0916 - val_loss: 28008.4766 - val_mean_absolute_error: 142.9037\n",
      "Epoch 3/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24634.2363 - mean_absolute_error: 127.6944 - val_loss: 12657.4805 - val_mean_absolute_error: 88.8099\n",
      "Epoch 4/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 17076.9316 - mean_absolute_error: 88.1706 - val_loss: 8839.1709 - val_mean_absolute_error: 71.0602\n",
      "Epoch 5/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12576.8232 - mean_absolute_error: 72.1585 - val_loss: 7098.9497 - val_mean_absolute_error: 62.0746\n",
      "Epoch 6/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12806.7236 - mean_absolute_error: 63.0875 - val_loss: 5978.0742 - val_mean_absolute_error: 54.3610\n",
      "Epoch 7/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7412.5747 - mean_absolute_error: 55.6395 - val_loss: 5363.4009 - val_mean_absolute_error: 50.9559\n",
      "Epoch 8/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8824.5000 - mean_absolute_error: 52.6814 - val_loss: 4698.4399 - val_mean_absolute_error: 44.2927\n",
      "Epoch 9/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11203.2188 - mean_absolute_error: 50.4931 - val_loss: 4338.9424 - val_mean_absolute_error: 42.2350\n",
      "Epoch 10/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9062.8857 - mean_absolute_error: 47.6548 - val_loss: 4190.4883 - val_mean_absolute_error: 42.3545\n",
      "Epoch 11/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7123.3257 - mean_absolute_error: 45.8727 - val_loss: 3975.7463 - val_mean_absolute_error: 40.6503\n",
      "Epoch 12/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11016.3721 - mean_absolute_error: 47.8271 - val_loss: 3829.8745 - val_mean_absolute_error: 39.7854\n",
      "Epoch 13/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6603.5825 - mean_absolute_error: 45.3957 - val_loss: 3644.0286 - val_mean_absolute_error: 38.1908\n",
      "Epoch 14/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7383.3599 - mean_absolute_error: 44.3028 - val_loss: 3613.7610 - val_mean_absolute_error: 38.4874\n",
      "Epoch 15/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5568.5596 - mean_absolute_error: 42.9971 - val_loss: 3390.2087 - val_mean_absolute_error: 35.8275\n",
      "Epoch 16/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8570.5244 - mean_absolute_error: 45.7248 - val_loss: 3281.0786 - val_mean_absolute_error: 35.7238\n",
      "Epoch 17/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5526.3872 - mean_absolute_error: 41.6073 - val_loss: 3422.0024 - val_mean_absolute_error: 35.2966\n",
      "Epoch 18/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5403.1030 - mean_absolute_error: 42.4283 - val_loss: 3052.4688 - val_mean_absolute_error: 34.1184\n",
      "Epoch 19/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4740.9697 - mean_absolute_error: 40.7107 - val_loss: 2984.6140 - val_mean_absolute_error: 34.2238\n",
      "Epoch 20/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4368.4717 - mean_absolute_error: 39.0539 - val_loss: 2944.5044 - val_mean_absolute_error: 34.0680\n",
      "Epoch 21/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5765.7266 - mean_absolute_error: 39.8992 - val_loss: 2822.2886 - val_mean_absolute_error: 33.2313\n",
      "Epoch 22/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5677.8262 - mean_absolute_error: 39.7145 - val_loss: 2695.0439 - val_mean_absolute_error: 32.0869\n",
      "Epoch 23/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6903.1646 - mean_absolute_error: 40.8524 - val_loss: 2642.6860 - val_mean_absolute_error: 31.6490\n",
      "Epoch 24/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4354.7222 - mean_absolute_error: 39.0949 - val_loss: 2492.5464 - val_mean_absolute_error: 30.5742\n",
      "Epoch 25/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5378.0088 - mean_absolute_error: 37.1917 - val_loss: 2404.7930 - val_mean_absolute_error: 29.7204\n",
      "Epoch 26/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4474.4121 - mean_absolute_error: 38.3606 - val_loss: 2413.3792 - val_mean_absolute_error: 30.6055\n",
      "Epoch 27/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4759.1704 - mean_absolute_error: 37.7463 - val_loss: 2255.6689 - val_mean_absolute_error: 29.2540\n",
      "Epoch 28/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4511.7065 - mean_absolute_error: 37.4168 - val_loss: 2140.8984 - val_mean_absolute_error: 27.6569\n",
      "Epoch 29/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4865.5967 - mean_absolute_error: 34.9688 - val_loss: 2068.9487 - val_mean_absolute_error: 26.6866\n",
      "Epoch 30/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4004.9338 - mean_absolute_error: 35.7878 - val_loss: 2002.9769 - val_mean_absolute_error: 26.2113\n",
      "Epoch 31/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4977.1118 - mean_absolute_error: 36.3174 - val_loss: 2490.4792 - val_mean_absolute_error: 31.4829\n",
      "Epoch 32/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4211.8594 - mean_absolute_error: 34.8618 - val_loss: 1881.2655 - val_mean_absolute_error: 25.4684\n",
      "Epoch 33/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3595.1362 - mean_absolute_error: 34.6901 - val_loss: 1853.9343 - val_mean_absolute_error: 25.0702\n",
      "Epoch 34/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4169.3940 - mean_absolute_error: 34.8826 - val_loss: 1797.4374 - val_mean_absolute_error: 24.3771\n",
      "Epoch 35/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4714.6240 - mean_absolute_error: 34.9760 - val_loss: 1804.6093 - val_mean_absolute_error: 24.4746\n",
      "Epoch 36/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3456.7317 - mean_absolute_error: 33.8120 - val_loss: 1767.3998 - val_mean_absolute_error: 24.4134\n",
      "Epoch 37/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4034.8806 - mean_absolute_error: 35.4196 - val_loss: 1759.5223 - val_mean_absolute_error: 24.3795\n",
      "Epoch 38/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3680.8550 - mean_absolute_error: 33.3275 - val_loss: 1844.2783 - val_mean_absolute_error: 25.5600\n",
      "Epoch 39/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4521.9668 - mean_absolute_error: 34.2323 - val_loss: 1796.6996 - val_mean_absolute_error: 24.5969\n",
      "Epoch 40/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3097.0229 - mean_absolute_error: 32.4462 - val_loss: 1697.9045 - val_mean_absolute_error: 23.6768\n",
      "Epoch 41/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3044.3835 - mean_absolute_error: 33.7131 - val_loss: 2018.5468 - val_mean_absolute_error: 27.1712\n",
      "Epoch 42/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4514.6626 - mean_absolute_error: 34.0257 - val_loss: 1659.4512 - val_mean_absolute_error: 22.7275\n",
      "Epoch 43/43\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4114.0771 - mean_absolute_error: 33.5781 - val_loss: 1691.6952 - val_mean_absolute_error: 23.2568\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:59:29,712] Trial 87 finished with value: 23.617001138556002 and parameters: {'layer_1': 8, 'layer_2': 7, 'layer_3': 8, 'learning_rate': 0.003618572399027163, 'dropout_rate': 0.03580808374258985, 'epoch': 43, 'batch_size': 66, 'optimizer': 'RMSprop'}. Best is trial 82 with value: 21.198321127447485.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 71086.3984 - mean_absolute_error: 213.8892 - val_loss: 69950.2734 - val_mean_absolute_error: 214.5567\n",
      "Epoch 2/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 74872.9844 - mean_absolute_error: 220.7645 - val_loss: 69948.0703 - val_mean_absolute_error: 214.5527\n",
      "Epoch 3/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 75738.5547 - mean_absolute_error: 217.9564 - val_loss: 69945.7891 - val_mean_absolute_error: 214.5485\n",
      "Epoch 4/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 69159.0391 - mean_absolute_error: 211.9223 - val_loss: 69943.3516 - val_mean_absolute_error: 214.5441\n",
      "Epoch 5/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 75635.4453 - mean_absolute_error: 217.9039 - val_loss: 69940.8984 - val_mean_absolute_error: 214.5396\n",
      "Epoch 6/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 74931.6016 - mean_absolute_error: 217.6055 - val_loss: 69938.3672 - val_mean_absolute_error: 214.5349\n",
      "Epoch 7/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 69881.3359 - mean_absolute_error: 211.5444 - val_loss: 69935.7422 - val_mean_absolute_error: 214.5301\n",
      "Epoch 8/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70497.5781 - mean_absolute_error: 214.7179 - val_loss: 69933.0000 - val_mean_absolute_error: 214.5251\n",
      "Epoch 9/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71677.9922 - mean_absolute_error: 213.4932 - val_loss: 69930.2656 - val_mean_absolute_error: 214.5200\n",
      "Epoch 10/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 69659.6172 - mean_absolute_error: 211.9595 - val_loss: 69927.3672 - val_mean_absolute_error: 214.5146\n",
      "Epoch 11/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70069.5938 - mean_absolute_error: 212.9052 - val_loss: 69924.3125 - val_mean_absolute_error: 214.5090\n",
      "Epoch 12/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72102.2500 - mean_absolute_error: 214.6286 - val_loss: 69921.2031 - val_mean_absolute_error: 214.5032\n",
      "Epoch 13/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71631.5625 - mean_absolute_error: 216.3020 - val_loss: 69918.1328 - val_mean_absolute_error: 214.4975\n",
      "Epoch 14/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68718.3125 - mean_absolute_error: 210.5484 - val_loss: 69914.9062 - val_mean_absolute_error: 214.4915\n",
      "Epoch 15/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73406.9453 - mean_absolute_error: 215.9393 - val_loss: 69911.6094 - val_mean_absolute_error: 214.4854\n",
      "Epoch 16/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70242.4688 - mean_absolute_error: 213.9543 - val_loss: 69908.2266 - val_mean_absolute_error: 214.4791\n",
      "Epoch 17/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71362.4062 - mean_absolute_error: 216.0350 - val_loss: 69904.8359 - val_mean_absolute_error: 214.4727\n",
      "Epoch 18/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72331.4688 - mean_absolute_error: 213.9628 - val_loss: 69901.3672 - val_mean_absolute_error: 214.4662\n",
      "Epoch 19/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70543.6328 - mean_absolute_error: 213.4977 - val_loss: 69897.7891 - val_mean_absolute_error: 214.4595\n",
      "Epoch 20/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69750.2344 - mean_absolute_error: 213.1861 - val_loss: 69894.2578 - val_mean_absolute_error: 214.4528\n",
      "Epoch 21/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70887.0156 - mean_absolute_error: 212.9176 - val_loss: 69890.5547 - val_mean_absolute_error: 214.4458\n",
      "Epoch 22/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73656.7656 - mean_absolute_error: 214.7306 - val_loss: 69886.9062 - val_mean_absolute_error: 214.4388\n",
      "Epoch 23/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71825.8594 - mean_absolute_error: 214.3567 - val_loss: 69883.1250 - val_mean_absolute_error: 214.4316\n",
      "Epoch 24/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73309.8906 - mean_absolute_error: 214.4463 - val_loss: 69879.1875 - val_mean_absolute_error: 214.4242\n",
      "Epoch 25/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71796.7969 - mean_absolute_error: 214.4679 - val_loss: 69875.3594 - val_mean_absolute_error: 214.4169\n",
      "Epoch 26/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67877.2500 - mean_absolute_error: 211.4868 - val_loss: 69871.3047 - val_mean_absolute_error: 214.4092\n",
      "Epoch 27/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71916.0156 - mean_absolute_error: 214.7917 - val_loss: 69867.1562 - val_mean_absolute_error: 214.4013\n",
      "Epoch 28/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71314.2031 - mean_absolute_error: 214.7224 - val_loss: 69863.0234 - val_mean_absolute_error: 214.3934\n",
      "Epoch 29/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67925.3750 - mean_absolute_error: 210.8996 - val_loss: 69858.7188 - val_mean_absolute_error: 214.3852\n",
      "Epoch 30/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71282.5859 - mean_absolute_error: 212.8936 - val_loss: 69854.4609 - val_mean_absolute_error: 214.3770\n",
      "Epoch 31/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71405.3281 - mean_absolute_error: 215.3300 - val_loss: 69850.0469 - val_mean_absolute_error: 214.3685\n",
      "Epoch 32/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76286.5312 - mean_absolute_error: 218.6762 - val_loss: 69845.6953 - val_mean_absolute_error: 214.3600\n",
      "Epoch 33/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69326.1172 - mean_absolute_error: 209.7669 - val_loss: 69841.1875 - val_mean_absolute_error: 214.3513\n",
      "Epoch 34/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68234.9609 - mean_absolute_error: 211.0211 - val_loss: 69836.5156 - val_mean_absolute_error: 214.3423\n",
      "Epoch 35/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69592.9453 - mean_absolute_error: 212.9609 - val_loss: 69831.9688 - val_mean_absolute_error: 214.3334\n",
      "Epoch 36/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71171.9922 - mean_absolute_error: 211.8725 - val_loss: 69827.2734 - val_mean_absolute_error: 214.3242\n",
      "Epoch 37/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67884.2188 - mean_absolute_error: 212.3472 - val_loss: 69822.4219 - val_mean_absolute_error: 214.3147\n",
      "Epoch 38/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71181.6250 - mean_absolute_error: 214.9631 - val_loss: 69817.4844 - val_mean_absolute_error: 214.3050\n",
      "Epoch 39/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73257.7109 - mean_absolute_error: 214.6259 - val_loss: 69812.4922 - val_mean_absolute_error: 214.2952\n",
      "Epoch 40/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72762.8125 - mean_absolute_error: 216.7605 - val_loss: 69807.5234 - val_mean_absolute_error: 214.2852\n",
      "Epoch 41/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71631.2734 - mean_absolute_error: 214.5323 - val_loss: 69802.3438 - val_mean_absolute_error: 214.2750\n",
      "Epoch 42/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73333.5859 - mean_absolute_error: 215.2221 - val_loss: 69797.1250 - val_mean_absolute_error: 214.2646\n",
      "Epoch 43/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70520.4922 - mean_absolute_error: 212.9224 - val_loss: 69791.7031 - val_mean_absolute_error: 214.2538\n",
      "Epoch 44/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70555.4844 - mean_absolute_error: 213.1322 - val_loss: 69786.1406 - val_mean_absolute_error: 214.2428\n",
      "Epoch 45/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72467.0781 - mean_absolute_error: 216.0443 - val_loss: 69780.5312 - val_mean_absolute_error: 214.2315\n",
      "Epoch 46/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73616.8125 - mean_absolute_error: 217.3258 - val_loss: 69774.8281 - val_mean_absolute_error: 214.2201\n",
      "Epoch 47/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75435.8906 - mean_absolute_error: 218.6518 - val_loss: 69769.0234 - val_mean_absolute_error: 214.2084\n",
      "Epoch 48/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69772.3750 - mean_absolute_error: 212.4776 - val_loss: 69763.1172 - val_mean_absolute_error: 214.1964\n",
      "Epoch 49/49\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 75161.2734 - mean_absolute_error: 217.3539 - val_loss: 69757.1641 - val_mean_absolute_error: 214.1841\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:59:35,164] Trial 88 finished with value: 214.97054579360844 and parameters: {'layer_1': 8, 'layer_2': 8, 'layer_3': 7, 'learning_rate': 0.010343837374517408, 'dropout_rate': 0.06016819716593698, 'epoch': 49, 'batch_size': 98, 'optimizer': 'Adadelta'}. Best is trial 82 with value: 21.198321127447485.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 69230.3516 - mean_absolute_error: 212.7452 - val_loss: 56067.5977 - val_mean_absolute_error: 189.4611\n",
      "Epoch 2/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 46929.9688 - mean_absolute_error: 169.7425 - val_loss: 20763.0137 - val_mean_absolute_error: 116.2167\n",
      "Epoch 3/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22243.6250 - mean_absolute_error: 110.3371 - val_loss: 11393.5693 - val_mean_absolute_error: 83.5745\n",
      "Epoch 4/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13771.5762 - mean_absolute_error: 81.4767 - val_loss: 8461.1123 - val_mean_absolute_error: 70.0457\n",
      "Epoch 5/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 18256.5449 - mean_absolute_error: 73.3613 - val_loss: 6457.3940 - val_mean_absolute_error: 57.6262\n",
      "Epoch 6/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9181.9189 - mean_absolute_error: 56.5184 - val_loss: 5239.2710 - val_mean_absolute_error: 50.4159\n",
      "Epoch 7/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12555.5068 - mean_absolute_error: 51.0448 - val_loss: 4421.2891 - val_mean_absolute_error: 44.2056\n",
      "Epoch 8/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7508.8608 - mean_absolute_error: 45.5593 - val_loss: 3975.6938 - val_mean_absolute_error: 40.4759\n",
      "Epoch 9/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5595.2007 - mean_absolute_error: 42.6672 - val_loss: 3641.8359 - val_mean_absolute_error: 38.3129\n",
      "Epoch 10/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4608.7310 - mean_absolute_error: 40.1298 - val_loss: 3599.6648 - val_mean_absolute_error: 39.3524\n",
      "Epoch 11/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5469.6895 - mean_absolute_error: 40.2497 - val_loss: 3152.8604 - val_mean_absolute_error: 35.4356\n",
      "Epoch 12/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5081.6655 - mean_absolute_error: 38.0603 - val_loss: 2944.4238 - val_mean_absolute_error: 34.1989\n",
      "Epoch 13/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5959.5278 - mean_absolute_error: 37.5982 - val_loss: 2757.7075 - val_mean_absolute_error: 32.7321\n",
      "Epoch 14/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6196.5483 - mean_absolute_error: 36.8060 - val_loss: 2715.6213 - val_mean_absolute_error: 32.7482\n",
      "Epoch 15/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5072.9775 - mean_absolute_error: 34.0180 - val_loss: 2392.3267 - val_mean_absolute_error: 29.5533\n",
      "Epoch 16/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3671.5056 - mean_absolute_error: 32.2163 - val_loss: 2294.3638 - val_mean_absolute_error: 29.1267\n",
      "Epoch 17/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3074.7063 - mean_absolute_error: 31.4298 - val_loss: 2123.6995 - val_mean_absolute_error: 27.0433\n",
      "Epoch 18/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4108.4019 - mean_absolute_error: 31.9441 - val_loss: 2061.9832 - val_mean_absolute_error: 26.7723\n",
      "Epoch 19/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3792.5989 - mean_absolute_error: 29.7829 - val_loss: 1885.8821 - val_mean_absolute_error: 24.9961\n",
      "Epoch 20/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3973.1006 - mean_absolute_error: 29.1317 - val_loss: 1890.2316 - val_mean_absolute_error: 25.0559\n",
      "Epoch 21/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3990.3374 - mean_absolute_error: 27.9927 - val_loss: 1771.4666 - val_mean_absolute_error: 23.7334\n",
      "Epoch 22/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3685.0823 - mean_absolute_error: 28.5317 - val_loss: 2057.1394 - val_mean_absolute_error: 26.2654\n",
      "Epoch 23/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3065.1433 - mean_absolute_error: 26.3450 - val_loss: 1691.1714 - val_mean_absolute_error: 22.8210\n",
      "Epoch 24/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2446.7273 - mean_absolute_error: 25.7132 - val_loss: 1627.8344 - val_mean_absolute_error: 21.9632\n",
      "Epoch 25/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3461.1873 - mean_absolute_error: 27.6500 - val_loss: 1640.8032 - val_mean_absolute_error: 21.7808\n",
      "Epoch 26/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2455.3074 - mean_absolute_error: 25.3948 - val_loss: 1768.2037 - val_mean_absolute_error: 23.6964\n",
      "Epoch 27/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2171.4331 - mean_absolute_error: 24.9457 - val_loss: 1599.7872 - val_mean_absolute_error: 21.3351\n",
      "Epoch 28/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2895.9717 - mean_absolute_error: 26.6468 - val_loss: 1621.1705 - val_mean_absolute_error: 21.6343\n",
      "Epoch 29/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2770.3362 - mean_absolute_error: 25.3578 - val_loss: 1745.9010 - val_mean_absolute_error: 23.1827\n",
      "Epoch 30/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2354.1716 - mean_absolute_error: 26.2085 - val_loss: 1586.7179 - val_mean_absolute_error: 21.1227\n",
      "Epoch 31/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3246.1431 - mean_absolute_error: 25.9402 - val_loss: 1654.8615 - val_mean_absolute_error: 22.1267\n",
      "Epoch 32/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3202.2771 - mean_absolute_error: 26.5364 - val_loss: 1553.2417 - val_mean_absolute_error: 20.8679\n",
      "Epoch 33/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2649.8752 - mean_absolute_error: 25.4792 - val_loss: 1613.9606 - val_mean_absolute_error: 22.7173\n",
      "Epoch 34/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3308.9414 - mean_absolute_error: 27.5095 - val_loss: 1588.5081 - val_mean_absolute_error: 21.4067\n",
      "Epoch 35/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2921.3301 - mean_absolute_error: 26.0304 - val_loss: 1608.0992 - val_mean_absolute_error: 21.3855\n",
      "Epoch 36/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2953.2605 - mean_absolute_error: 25.5917 - val_loss: 1624.2538 - val_mean_absolute_error: 21.6344\n",
      "Epoch 37/45\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2842.4072 - mean_absolute_error: 25.2642 - val_loss: 1657.4861 - val_mean_absolute_error: 21.9750\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:59:39,550] Trial 89 finished with value: 21.52288004629612 and parameters: {'layer_1': 7, 'layer_2': 6, 'layer_3': 8, 'learning_rate': 0.005011209174760127, 'dropout_rate': 0.010660116082739254, 'epoch': 45, 'batch_size': 85, 'optimizer': 'RMSprop'}. Best is trial 82 with value: 21.198321127447485.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 84734951424.0000 - mean_absolute_error: 12737.5635 - val_loss: 70001.7891 - val_mean_absolute_error: 214.6510\n",
      "Epoch 2/45\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71267.6797 - mean_absolute_error: 214.0431 - val_loss: 70001.7891 - val_mean_absolute_error: 214.6510\n",
      "Epoch 3/45\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73665.3438 - mean_absolute_error: 218.3414 - val_loss: 70001.7891 - val_mean_absolute_error: 214.6510\n",
      "Epoch 4/45\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75341.8594 - mean_absolute_error: 217.7121 - val_loss: 70001.7891 - val_mean_absolute_error: 214.6510\n",
      "Epoch 5/45\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76221.9219 - mean_absolute_error: 219.2854 - val_loss: 70001.7891 - val_mean_absolute_error: 214.6510\n",
      "Epoch 6/45\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73800.5000 - mean_absolute_error: 216.0779 - val_loss: 70001.7891 - val_mean_absolute_error: 214.6510\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:59:40,983] Trial 90 finished with value: 215.42847832031254 and parameters: {'layer_1': 6, 'layer_2': 6, 'layer_3': 8, 'learning_rate': 0.005163344440092788, 'dropout_rate': 0.07847327884024413, 'epoch': 45, 'batch_size': 81, 'optimizer': 'SGD'}. Best is trial 82 with value: 21.198321127447485.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 71565.1875 - mean_absolute_error: 215.3375 - val_loss: 66461.7891 - val_mean_absolute_error: 209.4710\n",
      "Epoch 2/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70563.9375 - mean_absolute_error: 212.5927 - val_loss: 59405.5352 - val_mean_absolute_error: 198.6101\n",
      "Epoch 3/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 61322.8359 - mean_absolute_error: 200.3443 - val_loss: 47001.4258 - val_mean_absolute_error: 176.7695\n",
      "Epoch 4/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 44936.2148 - mean_absolute_error: 169.9490 - val_loss: 30047.1855 - val_mean_absolute_error: 140.3604\n",
      "Epoch 5/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27310.1738 - mean_absolute_error: 132.6264 - val_loss: 16334.8750 - val_mean_absolute_error: 104.5721\n",
      "Epoch 6/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 17016.6426 - mean_absolute_error: 99.6796 - val_loss: 11650.5137 - val_mean_absolute_error: 86.1803\n",
      "Epoch 7/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14877.2480 - mean_absolute_error: 87.0089 - val_loss: 10105.7051 - val_mean_absolute_error: 79.1297\n",
      "Epoch 8/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12315.6104 - mean_absolute_error: 79.0794 - val_loss: 8859.1260 - val_mean_absolute_error: 72.3336\n",
      "Epoch 9/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11426.4785 - mean_absolute_error: 73.6137 - val_loss: 7792.6001 - val_mean_absolute_error: 66.5414\n",
      "Epoch 10/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9420.3857 - mean_absolute_error: 67.0831 - val_loss: 6976.4136 - val_mean_absolute_error: 62.7460\n",
      "Epoch 11/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8996.3896 - mean_absolute_error: 63.0361 - val_loss: 6080.5586 - val_mean_absolute_error: 55.9984\n",
      "Epoch 12/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7712.5337 - mean_absolute_error: 55.9981 - val_loss: 5404.5220 - val_mean_absolute_error: 51.9166\n",
      "Epoch 13/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6772.3809 - mean_absolute_error: 52.3313 - val_loss: 4793.4272 - val_mean_absolute_error: 46.8415\n",
      "Epoch 14/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7207.1182 - mean_absolute_error: 50.3160 - val_loss: 4308.4985 - val_mean_absolute_error: 44.3181\n",
      "Epoch 15/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6825.9736 - mean_absolute_error: 45.8836 - val_loss: 3956.6604 - val_mean_absolute_error: 42.0382\n",
      "Epoch 16/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6290.5986 - mean_absolute_error: 42.9606 - val_loss: 3646.0669 - val_mean_absolute_error: 39.0055\n",
      "Epoch 17/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6219.7866 - mean_absolute_error: 41.5066 - val_loss: 3522.9612 - val_mean_absolute_error: 38.9264\n",
      "Epoch 18/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5574.2769 - mean_absolute_error: 40.1157 - val_loss: 3343.6960 - val_mean_absolute_error: 36.6719\n",
      "Epoch 19/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5658.3857 - mean_absolute_error: 39.1340 - val_loss: 3175.6782 - val_mean_absolute_error: 36.0767\n",
      "Epoch 20/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4426.4907 - mean_absolute_error: 38.5036 - val_loss: 3058.7354 - val_mean_absolute_error: 34.8053\n",
      "Epoch 21/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6039.1855 - mean_absolute_error: 37.1712 - val_loss: 2962.9224 - val_mean_absolute_error: 34.7134\n",
      "Epoch 22/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4414.5234 - mean_absolute_error: 35.9467 - val_loss: 2829.8459 - val_mean_absolute_error: 33.5176\n",
      "Epoch 23/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3805.6052 - mean_absolute_error: 35.8020 - val_loss: 2752.6851 - val_mean_absolute_error: 33.1972\n",
      "Epoch 24/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4405.3853 - mean_absolute_error: 35.0696 - val_loss: 2631.7139 - val_mean_absolute_error: 32.0511\n",
      "Epoch 25/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5125.2012 - mean_absolute_error: 35.1011 - val_loss: 2555.2007 - val_mean_absolute_error: 31.4214\n",
      "Epoch 26/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4499.6118 - mean_absolute_error: 35.1067 - val_loss: 2466.9895 - val_mean_absolute_error: 30.5118\n",
      "Epoch 27/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3769.8455 - mean_absolute_error: 33.3343 - val_loss: 2392.0352 - val_mean_absolute_error: 30.1400\n",
      "Epoch 28/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3608.5596 - mean_absolute_error: 32.4709 - val_loss: 2290.7368 - val_mean_absolute_error: 29.2208\n",
      "Epoch 29/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4518.5762 - mean_absolute_error: 32.8061 - val_loss: 2234.1592 - val_mean_absolute_error: 28.7280\n",
      "Epoch 30/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4639.4541 - mean_absolute_error: 32.5844 - val_loss: 2168.1145 - val_mean_absolute_error: 28.1982\n",
      "Epoch 31/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3736.1768 - mean_absolute_error: 31.5804 - val_loss: 2118.7529 - val_mean_absolute_error: 27.3273\n",
      "Epoch 32/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3505.1973 - mean_absolute_error: 30.7073 - val_loss: 2042.2529 - val_mean_absolute_error: 26.8002\n",
      "Epoch 33/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3252.8325 - mean_absolute_error: 29.4941 - val_loss: 1971.8145 - val_mean_absolute_error: 25.8812\n",
      "Epoch 34/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3368.3933 - mean_absolute_error: 29.0906 - val_loss: 2033.8615 - val_mean_absolute_error: 27.0754\n",
      "Epoch 35/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2591.5996 - mean_absolute_error: 29.5619 - val_loss: 1932.4615 - val_mean_absolute_error: 25.8055\n",
      "Epoch 36/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2931.7520 - mean_absolute_error: 29.0193 - val_loss: 1850.5284 - val_mean_absolute_error: 25.0138\n",
      "Epoch 37/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2712.8198 - mean_absolute_error: 27.0138 - val_loss: 1830.5747 - val_mean_absolute_error: 24.7091\n",
      "Epoch 38/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3681.9771 - mean_absolute_error: 28.7964 - val_loss: 1838.2426 - val_mean_absolute_error: 25.0685\n",
      "Epoch 39/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2976.0696 - mean_absolute_error: 27.4127 - val_loss: 1731.1082 - val_mean_absolute_error: 23.4566\n",
      "Epoch 40/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3401.1033 - mean_absolute_error: 28.2835 - val_loss: 1702.1490 - val_mean_absolute_error: 23.1832\n",
      "Epoch 41/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2934.3721 - mean_absolute_error: 27.7624 - val_loss: 1673.9908 - val_mean_absolute_error: 22.8675\n",
      "Epoch 42/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3457.5291 - mean_absolute_error: 28.0431 - val_loss: 1662.5735 - val_mean_absolute_error: 22.7546\n",
      "Epoch 43/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2884.7031 - mean_absolute_error: 27.1120 - val_loss: 1676.4333 - val_mean_absolute_error: 22.7537\n",
      "Epoch 44/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4405.1035 - mean_absolute_error: 26.6118 - val_loss: 1643.4379 - val_mean_absolute_error: 22.2058\n",
      "Epoch 45/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2633.0969 - mean_absolute_error: 26.1648 - val_loss: 1609.2789 - val_mean_absolute_error: 21.9458\n",
      "Epoch 46/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2751.8984 - mean_absolute_error: 25.7532 - val_loss: 1629.8711 - val_mean_absolute_error: 22.2227\n",
      "Epoch 47/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3253.2622 - mean_absolute_error: 27.3682 - val_loss: 1590.5234 - val_mean_absolute_error: 21.6244\n",
      "Epoch 48/48\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2419.4622 - mean_absolute_error: 25.4298 - val_loss: 1597.6938 - val_mean_absolute_error: 21.7825\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:59:46,621] Trial 91 finished with value: 22.290804898741843 and parameters: {'layer_1': 7, 'layer_2': 6, 'layer_3': 8, 'learning_rate': 0.002251286433757075, 'dropout_rate': 0.011312748689945182, 'epoch': 48, 'batch_size': 85, 'optimizer': 'RMSprop'}. Best is trial 82 with value: 21.198321127447485.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 73250.3594 - mean_absolute_error: 215.8237 - val_loss: 49873.8281 - val_mean_absolute_error: 181.5171\n",
      "Epoch 2/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37097.8906 - mean_absolute_error: 150.5992 - val_loss: 12370.5479 - val_mean_absolute_error: 87.7677\n",
      "Epoch 3/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13802.7500 - mean_absolute_error: 85.1209 - val_loss: 8656.3652 - val_mean_absolute_error: 71.0467\n",
      "Epoch 4/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13064.7451 - mean_absolute_error: 68.2732 - val_loss: 5973.7803 - val_mean_absolute_error: 56.0155\n",
      "Epoch 5/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6998.8960 - mean_absolute_error: 51.4359 - val_loss: 4457.3979 - val_mean_absolute_error: 43.7433\n",
      "Epoch 6/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5183.1201 - mean_absolute_error: 42.1562 - val_loss: 3677.2141 - val_mean_absolute_error: 39.5412\n",
      "Epoch 7/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5728.4819 - mean_absolute_error: 39.1540 - val_loss: 3168.5884 - val_mean_absolute_error: 35.5578\n",
      "Epoch 8/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5372.2046 - mean_absolute_error: 36.7591 - val_loss: 2725.1416 - val_mean_absolute_error: 31.9946\n",
      "Epoch 9/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3315.7632 - mean_absolute_error: 31.2223 - val_loss: 2368.4099 - val_mean_absolute_error: 29.3959\n",
      "Epoch 10/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3354.3828 - mean_absolute_error: 29.6547 - val_loss: 2135.6045 - val_mean_absolute_error: 27.3335\n",
      "Epoch 11/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3777.1367 - mean_absolute_error: 28.3619 - val_loss: 2069.0901 - val_mean_absolute_error: 26.3655\n",
      "Epoch 12/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2703.4849 - mean_absolute_error: 27.3580 - val_loss: 2017.6869 - val_mean_absolute_error: 25.7429\n",
      "Epoch 13/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2683.2432 - mean_absolute_error: 24.7123 - val_loss: 1764.1211 - val_mean_absolute_error: 23.3733\n",
      "Epoch 14/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2470.0933 - mean_absolute_error: 24.5788 - val_loss: 1698.4634 - val_mean_absolute_error: 22.7160\n",
      "Epoch 15/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2289.5422 - mean_absolute_error: 23.2486 - val_loss: 1669.1152 - val_mean_absolute_error: 22.3018\n",
      "Epoch 16/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3091.1238 - mean_absolute_error: 24.1589 - val_loss: 2371.8584 - val_mean_absolute_error: 28.4296\n",
      "Epoch 17/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2414.8594 - mean_absolute_error: 23.8251 - val_loss: 1804.8784 - val_mean_absolute_error: 23.4299\n",
      "Epoch 18/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2103.7178 - mean_absolute_error: 23.1352 - val_loss: 1719.7424 - val_mean_absolute_error: 23.3671\n",
      "Epoch 19/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3853.4709 - mean_absolute_error: 26.0292 - val_loss: 1613.6544 - val_mean_absolute_error: 21.3791\n",
      "Epoch 20/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2357.5947 - mean_absolute_error: 22.4002 - val_loss: 1707.1198 - val_mean_absolute_error: 22.8537\n",
      "Epoch 21/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2458.8047 - mean_absolute_error: 23.2804 - val_loss: 1707.2711 - val_mean_absolute_error: 22.1761\n",
      "Epoch 22/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3204.9221 - mean_absolute_error: 23.5911 - val_loss: 1607.2163 - val_mean_absolute_error: 21.4312\n",
      "Epoch 23/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2041.4385 - mean_absolute_error: 22.6873 - val_loss: 1586.8308 - val_mean_absolute_error: 21.2441\n",
      "Epoch 24/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2174.2112 - mean_absolute_error: 22.2249 - val_loss: 1610.0388 - val_mean_absolute_error: 21.5026\n",
      "Epoch 25/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2294.7505 - mean_absolute_error: 22.6353 - val_loss: 1611.2488 - val_mean_absolute_error: 21.2569\n",
      "Epoch 26/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3226.4246 - mean_absolute_error: 23.1644 - val_loss: 1615.7949 - val_mean_absolute_error: 21.7978\n",
      "Epoch 27/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2042.0728 - mean_absolute_error: 21.8986 - val_loss: 1628.3083 - val_mean_absolute_error: 21.1091\n",
      "Epoch 28/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2212.9141 - mean_absolute_error: 22.0204 - val_loss: 1583.0593 - val_mean_absolute_error: 20.8651\n",
      "Epoch 29/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2194.5654 - mean_absolute_error: 21.8823 - val_loss: 1672.8623 - val_mean_absolute_error: 21.8160\n",
      "Epoch 30/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2357.0662 - mean_absolute_error: 22.1373 - val_loss: 1575.7722 - val_mean_absolute_error: 20.6841\n",
      "Epoch 31/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2378.4646 - mean_absolute_error: 22.1684 - val_loss: 1614.2439 - val_mean_absolute_error: 21.0549\n",
      "Epoch 32/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3093.2268 - mean_absolute_error: 23.3575 - val_loss: 1617.9823 - val_mean_absolute_error: 20.8350\n",
      "Epoch 33/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2310.2058 - mean_absolute_error: 21.7965 - val_loss: 1706.3687 - val_mean_absolute_error: 22.3106\n",
      "Epoch 34/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1671.8677 - mean_absolute_error: 20.8020 - val_loss: 2098.9082 - val_mean_absolute_error: 26.0740\n",
      "Epoch 35/45\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2569.7781 - mean_absolute_error: 23.0333 - val_loss: 1591.7704 - val_mean_absolute_error: 20.6372\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:59:51,940] Trial 92 finished with value: 21.152993560005722 and parameters: {'layer_1': 7, 'layer_2': 5, 'layer_3': 8, 'learning_rate': 0.008009635619625224, 'dropout_rate': 0.0006149438353628724, 'epoch': 45, 'batch_size': 90, 'optimizer': 'RMSprop'}. Best is trial 92 with value: 21.152993560005722.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 64840.9609 - mean_absolute_error: 197.1147 - val_loss: 13834.4043 - val_mean_absolute_error: 96.2981\n",
      "Epoch 2/43\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17621.7637 - mean_absolute_error: 87.0282 - val_loss: 6704.3862 - val_mean_absolute_error: 62.3778\n",
      "Epoch 3/43\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8660.5645 - mean_absolute_error: 58.2459 - val_loss: 4611.9956 - val_mean_absolute_error: 48.8807\n",
      "Epoch 4/43\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8946.9297 - mean_absolute_error: 47.2270 - val_loss: 3411.7524 - val_mean_absolute_error: 37.8422\n",
      "Epoch 5/43\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6193.2310 - mean_absolute_error: 41.2510 - val_loss: 2978.3218 - val_mean_absolute_error: 34.6764\n",
      "Epoch 6/43\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6051.2026 - mean_absolute_error: 36.3570 - val_loss: 2595.3621 - val_mean_absolute_error: 32.3462\n",
      "Epoch 7/43\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4939.3955 - mean_absolute_error: 35.5567 - val_loss: 2275.8843 - val_mean_absolute_error: 27.8779\n",
      "Epoch 8/43\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4926.7651 - mean_absolute_error: 33.7358 - val_loss: 2107.8921 - val_mean_absolute_error: 26.4250\n",
      "Epoch 9/43\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4438.6729 - mean_absolute_error: 31.7308 - val_loss: 1996.0765 - val_mean_absolute_error: 25.4393\n",
      "Epoch 10/43\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3485.0942 - mean_absolute_error: 30.9653 - val_loss: 1820.8608 - val_mean_absolute_error: 23.7668\n",
      "Epoch 11/43\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3221.0764 - mean_absolute_error: 28.1895 - val_loss: 1741.4529 - val_mean_absolute_error: 23.3542\n",
      "Epoch 12/43\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3283.0601 - mean_absolute_error: 27.5354 - val_loss: 2109.8745 - val_mean_absolute_error: 28.7908\n",
      "Epoch 13/43\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2603.1060 - mean_absolute_error: 27.4078 - val_loss: 1702.3109 - val_mean_absolute_error: 22.8193\n",
      "Epoch 14/43\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2970.6104 - mean_absolute_error: 27.4893 - val_loss: 1906.6254 - val_mean_absolute_error: 25.4229\n",
      "Epoch 15/43\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3848.3752 - mean_absolute_error: 28.4861 - val_loss: 1781.7347 - val_mean_absolute_error: 23.9885\n",
      "Epoch 16/43\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4104.8853 - mean_absolute_error: 29.5003 - val_loss: 2176.2563 - val_mean_absolute_error: 27.3020\n",
      "Epoch 17/43\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3076.1492 - mean_absolute_error: 27.2171 - val_loss: 1599.5845 - val_mean_absolute_error: 22.0413\n",
      "Epoch 18/43\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3475.2217 - mean_absolute_error: 27.7564 - val_loss: 1618.6351 - val_mean_absolute_error: 21.6456\n",
      "Epoch 19/43\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3931.2061 - mean_absolute_error: 28.2634 - val_loss: 2144.1506 - val_mean_absolute_error: 29.3615\n",
      "Epoch 20/43\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3175.6914 - mean_absolute_error: 27.9209 - val_loss: 1564.9561 - val_mean_absolute_error: 21.2131\n",
      "Epoch 21/43\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3242.6499 - mean_absolute_error: 27.3176 - val_loss: 1735.1937 - val_mean_absolute_error: 23.4388\n",
      "Epoch 22/43\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3441.8650 - mean_absolute_error: 27.3677 - val_loss: 1615.6704 - val_mean_absolute_error: 22.0817\n",
      "Epoch 23/43\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2550.7297 - mean_absolute_error: 25.9856 - val_loss: 1582.3645 - val_mean_absolute_error: 21.4786\n",
      "Epoch 24/43\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3925.0017 - mean_absolute_error: 27.5823 - val_loss: 1628.2733 - val_mean_absolute_error: 22.3734\n",
      "Epoch 25/43\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3129.2021 - mean_absolute_error: 26.5734 - val_loss: 1758.6670 - val_mean_absolute_error: 23.3530\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:59:55,317] Trial 93 finished with value: 21.767584106850627 and parameters: {'layer_1': 7, 'layer_2': 5, 'layer_3': 8, 'learning_rate': 0.011678479654908026, 'dropout_rate': 0.01062309468261826, 'epoch': 43, 'batch_size': 90, 'optimizer': 'RMSprop'}. Best is trial 92 with value: 21.152993560005722.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 64665.7188 - mean_absolute_error: 203.9657 - val_loss: 18251.9551 - val_mean_absolute_error: 108.6120\n",
      "Epoch 2/44\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15997.3672 - mean_absolute_error: 94.9516 - val_loss: 9593.2715 - val_mean_absolute_error: 76.6327\n",
      "Epoch 3/44\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14570.9707 - mean_absolute_error: 73.7003 - val_loss: 5464.4536 - val_mean_absolute_error: 47.1385\n",
      "Epoch 4/44\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8592.3604 - mean_absolute_error: 51.1399 - val_loss: 3927.8357 - val_mean_absolute_error: 39.9717\n",
      "Epoch 5/44\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4516.3315 - mean_absolute_error: 42.9056 - val_loss: 3610.9971 - val_mean_absolute_error: 38.4453\n",
      "Epoch 6/44\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6362.3306 - mean_absolute_error: 43.1621 - val_loss: 3544.1792 - val_mean_absolute_error: 39.1598\n",
      "Epoch 7/44\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6659.6089 - mean_absolute_error: 41.6816 - val_loss: 2687.6184 - val_mean_absolute_error: 31.5170\n",
      "Epoch 8/44\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4853.4067 - mean_absolute_error: 39.9499 - val_loss: 2608.6160 - val_mean_absolute_error: 30.3796\n",
      "Epoch 9/44\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3810.2939 - mean_absolute_error: 36.0895 - val_loss: 2341.3472 - val_mean_absolute_error: 29.4377\n",
      "Epoch 10/44\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3958.6411 - mean_absolute_error: 35.4495 - val_loss: 2167.3220 - val_mean_absolute_error: 27.2623\n",
      "Epoch 11/44\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3751.1650 - mean_absolute_error: 35.5751 - val_loss: 1951.4689 - val_mean_absolute_error: 25.6526\n",
      "Epoch 12/44\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4482.0454 - mean_absolute_error: 35.1388 - val_loss: 2091.2610 - val_mean_absolute_error: 27.3048\n",
      "Epoch 13/44\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5338.0200 - mean_absolute_error: 34.6715 - val_loss: 1907.9948 - val_mean_absolute_error: 25.5923\n",
      "Epoch 14/44\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3451.9209 - mean_absolute_error: 32.7878 - val_loss: 1881.2073 - val_mean_absolute_error: 24.9743\n",
      "Epoch 15/44\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5388.2593 - mean_absolute_error: 34.7988 - val_loss: 1725.2673 - val_mean_absolute_error: 23.2740\n",
      "Epoch 16/44\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3352.6982 - mean_absolute_error: 32.6232 - val_loss: 1661.7115 - val_mean_absolute_error: 22.5734\n",
      "Epoch 17/44\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4458.5781 - mean_absolute_error: 33.4697 - val_loss: 2643.6765 - val_mean_absolute_error: 31.1518\n",
      "Epoch 18/44\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3889.8137 - mean_absolute_error: 33.5071 - val_loss: 1618.2856 - val_mean_absolute_error: 21.8437\n",
      "Epoch 19/44\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6172.4946 - mean_absolute_error: 32.8897 - val_loss: 1764.6660 - val_mean_absolute_error: 23.8349\n",
      "Epoch 20/44\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3335.6736 - mean_absolute_error: 31.6409 - val_loss: 1795.6847 - val_mean_absolute_error: 24.2228\n",
      "Epoch 21/44\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3740.4482 - mean_absolute_error: 33.6767 - val_loss: 1639.6088 - val_mean_absolute_error: 22.4517\n",
      "Epoch 22/44\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3428.1365 - mean_absolute_error: 33.0768 - val_loss: 1697.5544 - val_mean_absolute_error: 23.1978\n",
      "Epoch 23/44\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3577.6951 - mean_absolute_error: 33.0515 - val_loss: 1923.1980 - val_mean_absolute_error: 25.6236\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 12:59:58,719] Trial 94 finished with value: 22.696839470134677 and parameters: {'layer_1': 7, 'layer_2': 5, 'layer_3': 8, 'learning_rate': 0.008118762940248334, 'dropout_rate': 0.028341059959080483, 'epoch': 44, 'batch_size': 70, 'optimizer': 'RMSprop'}. Best is trial 92 with value: 21.152993560005722.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 72156.5469 - mean_absolute_error: 214.8236 - val_loss: 65244.7305 - val_mean_absolute_error: 206.7117\n",
      "Epoch 2/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 60829.2891 - mean_absolute_error: 198.5980 - val_loss: 33116.5234 - val_mean_absolute_error: 149.8647\n",
      "Epoch 3/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30976.8965 - mean_absolute_error: 135.6040 - val_loss: 11969.2773 - val_mean_absolute_error: 84.2373\n",
      "Epoch 4/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21173.4238 - mean_absolute_error: 102.8874 - val_loss: 10162.7285 - val_mean_absolute_error: 75.7680\n",
      "Epoch 5/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18664.6465 - mean_absolute_error: 93.3470 - val_loss: 6760.8467 - val_mean_absolute_error: 59.3388\n",
      "Epoch 6/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 17370.9043 - mean_absolute_error: 87.6291 - val_loss: 6283.3291 - val_mean_absolute_error: 56.6346\n",
      "Epoch 7/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15848.6885 - mean_absolute_error: 83.6231 - val_loss: 5051.2300 - val_mean_absolute_error: 49.3965\n",
      "Epoch 8/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14200.9219 - mean_absolute_error: 77.7999 - val_loss: 6375.4209 - val_mean_absolute_error: 56.4330\n",
      "Epoch 9/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14792.2197 - mean_absolute_error: 75.6481 - val_loss: 3473.2671 - val_mean_absolute_error: 38.8612\n",
      "Epoch 10/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13656.9219 - mean_absolute_error: 72.9903 - val_loss: 4284.2051 - val_mean_absolute_error: 44.4022\n",
      "Epoch 11/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13005.4229 - mean_absolute_error: 71.6007 - val_loss: 5363.8687 - val_mean_absolute_error: 50.4279\n",
      "Epoch 12/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13695.6162 - mean_absolute_error: 72.4821 - val_loss: 5846.3916 - val_mean_absolute_error: 53.6695\n",
      "Epoch 13/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13179.3359 - mean_absolute_error: 71.0614 - val_loss: 4179.2129 - val_mean_absolute_error: 44.5760\n",
      "Epoch 14/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12854.9355 - mean_absolute_error: 72.2792 - val_loss: 2937.1584 - val_mean_absolute_error: 35.5315\n",
      "Epoch 15/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12460.9551 - mean_absolute_error: 69.6452 - val_loss: 3548.7715 - val_mean_absolute_error: 40.3180\n",
      "Epoch 16/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10850.4434 - mean_absolute_error: 68.0253 - val_loss: 3457.3223 - val_mean_absolute_error: 40.4323\n",
      "Epoch 17/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10333.8418 - mean_absolute_error: 67.0742 - val_loss: 2447.2410 - val_mean_absolute_error: 30.8960\n",
      "Epoch 18/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12870.2158 - mean_absolute_error: 68.8700 - val_loss: 5137.1646 - val_mean_absolute_error: 49.4523\n",
      "Epoch 19/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11395.2734 - mean_absolute_error: 68.2237 - val_loss: 2886.9155 - val_mean_absolute_error: 35.1006\n",
      "Epoch 20/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10423.8838 - mean_absolute_error: 66.2325 - val_loss: 3819.4209 - val_mean_absolute_error: 42.0134\n",
      "Epoch 21/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11608.5234 - mean_absolute_error: 68.9037 - val_loss: 2440.8574 - val_mean_absolute_error: 32.4925\n",
      "Epoch 22/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10510.1875 - mean_absolute_error: 65.3511 - val_loss: 2313.9580 - val_mean_absolute_error: 30.8809\n",
      "Epoch 23/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11657.6406 - mean_absolute_error: 67.2935 - val_loss: 2939.3171 - val_mean_absolute_error: 37.3449\n",
      "Epoch 24/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10066.0771 - mean_absolute_error: 66.1924 - val_loss: 3411.4038 - val_mean_absolute_error: 39.7728\n",
      "Epoch 25/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11189.1484 - mean_absolute_error: 66.2695 - val_loss: 3181.9487 - val_mean_absolute_error: 38.2476\n",
      "Epoch 26/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10603.5098 - mean_absolute_error: 64.4506 - val_loss: 2608.3188 - val_mean_absolute_error: 34.1669\n",
      "Epoch 27/47\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10880.5361 - mean_absolute_error: 65.6712 - val_loss: 3883.3552 - val_mean_absolute_error: 43.3286\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 13:00:02,253] Trial 95 finished with value: 31.291717225289347 and parameters: {'layer_1': 7, 'layer_2': 4, 'layer_3': 8, 'learning_rate': 0.006787086026196568, 'dropout_rate': 0.20234385296708035, 'epoch': 47, 'batch_size': 87, 'optimizer': 'RMSprop'}. Best is trial 92 with value: 21.152993560005722.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 75729.3906 - mean_absolute_error: 218.4648 - val_loss: 67656.1016 - val_mean_absolute_error: 210.8175\n",
      "Epoch 2/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68811.3594 - mean_absolute_error: 211.7673 - val_loss: 60852.3477 - val_mean_absolute_error: 200.1090\n",
      "Epoch 3/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 61367.5273 - mean_absolute_error: 198.4044 - val_loss: 45966.4414 - val_mean_absolute_error: 174.8564\n",
      "Epoch 4/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 42700.0508 - mean_absolute_error: 167.3613 - val_loss: 25752.9395 - val_mean_absolute_error: 132.0092\n",
      "Epoch 5/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25818.7305 - mean_absolute_error: 126.4635 - val_loss: 13883.7705 - val_mean_absolute_error: 95.2135\n",
      "Epoch 6/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19046.8477 - mean_absolute_error: 100.0835 - val_loss: 10713.2051 - val_mean_absolute_error: 82.2239\n",
      "Epoch 7/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14937.0615 - mean_absolute_error: 89.1504 - val_loss: 9142.6963 - val_mean_absolute_error: 75.2514\n",
      "Epoch 8/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13606.4922 - mean_absolute_error: 80.4208 - val_loss: 7695.8252 - val_mean_absolute_error: 66.7162\n",
      "Epoch 9/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11222.0049 - mean_absolute_error: 72.6946 - val_loss: 6636.7793 - val_mean_absolute_error: 59.6221\n",
      "Epoch 10/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13019.1143 - mean_absolute_error: 69.4071 - val_loss: 5833.8306 - val_mean_absolute_error: 54.7560\n",
      "Epoch 11/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10471.4307 - mean_absolute_error: 64.8530 - val_loss: 5155.3823 - val_mean_absolute_error: 50.4125\n",
      "Epoch 12/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8481.3975 - mean_absolute_error: 58.3168 - val_loss: 4649.6177 - val_mean_absolute_error: 46.8940\n",
      "Epoch 13/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8316.1680 - mean_absolute_error: 55.9288 - val_loss: 4280.3052 - val_mean_absolute_error: 43.8836\n",
      "Epoch 14/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8085.4297 - mean_absolute_error: 54.3540 - val_loss: 4033.5830 - val_mean_absolute_error: 42.3019\n",
      "Epoch 15/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7999.0615 - mean_absolute_error: 53.5418 - val_loss: 3760.9443 - val_mean_absolute_error: 39.8125\n",
      "Epoch 16/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7559.6055 - mean_absolute_error: 51.8714 - val_loss: 3568.3101 - val_mean_absolute_error: 38.5057\n",
      "Epoch 17/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6508.1030 - mean_absolute_error: 49.1316 - val_loss: 3445.6360 - val_mean_absolute_error: 37.8241\n",
      "Epoch 18/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6526.4092 - mean_absolute_error: 48.4504 - val_loss: 3323.9785 - val_mean_absolute_error: 36.9440\n",
      "Epoch 19/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6006.3037 - mean_absolute_error: 45.7166 - val_loss: 3234.1987 - val_mean_absolute_error: 36.5448\n",
      "Epoch 20/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6171.4072 - mean_absolute_error: 47.2409 - val_loss: 3131.5659 - val_mean_absolute_error: 35.8733\n",
      "Epoch 21/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5567.4761 - mean_absolute_error: 45.9477 - val_loss: 2955.1685 - val_mean_absolute_error: 34.2014\n",
      "Epoch 22/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5580.4463 - mean_absolute_error: 44.8128 - val_loss: 2917.7405 - val_mean_absolute_error: 34.3027\n",
      "Epoch 23/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5196.1943 - mean_absolute_error: 43.1662 - val_loss: 2924.6782 - val_mean_absolute_error: 34.4849\n",
      "Epoch 24/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5969.8501 - mean_absolute_error: 46.7716 - val_loss: 2766.8369 - val_mean_absolute_error: 33.0464\n",
      "Epoch 25/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4571.8691 - mean_absolute_error: 42.3072 - val_loss: 2528.9358 - val_mean_absolute_error: 31.0237\n",
      "Epoch 26/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7524.9155 - mean_absolute_error: 44.8719 - val_loss: 2579.4004 - val_mean_absolute_error: 31.9122\n",
      "Epoch 27/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6371.9648 - mean_absolute_error: 43.4887 - val_loss: 2361.5312 - val_mean_absolute_error: 29.7296\n",
      "Epoch 28/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6985.2183 - mean_absolute_error: 43.2177 - val_loss: 2356.5603 - val_mean_absolute_error: 29.8760\n",
      "Epoch 29/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5246.3599 - mean_absolute_error: 41.4756 - val_loss: 2442.0601 - val_mean_absolute_error: 31.0508\n",
      "Epoch 30/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4575.0649 - mean_absolute_error: 41.9813 - val_loss: 2319.5688 - val_mean_absolute_error: 29.8683\n",
      "Epoch 31/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5490.5068 - mean_absolute_error: 41.3506 - val_loss: 2238.2747 - val_mean_absolute_error: 29.2954\n",
      "Epoch 32/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6014.0322 - mean_absolute_error: 43.0228 - val_loss: 2092.6978 - val_mean_absolute_error: 27.8050\n",
      "Epoch 33/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4226.0835 - mean_absolute_error: 38.9679 - val_loss: 2106.7214 - val_mean_absolute_error: 27.9826\n",
      "Epoch 34/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5312.6270 - mean_absolute_error: 40.6845 - val_loss: 2120.8796 - val_mean_absolute_error: 28.3430\n",
      "Epoch 35/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4617.8228 - mean_absolute_error: 39.3523 - val_loss: 2147.8303 - val_mean_absolute_error: 28.5027\n",
      "Epoch 36/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4287.2075 - mean_absolute_error: 39.9104 - val_loss: 2018.2970 - val_mean_absolute_error: 27.1328\n",
      "Epoch 37/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5225.9268 - mean_absolute_error: 40.4481 - val_loss: 1862.4048 - val_mean_absolute_error: 25.4145\n",
      "Epoch 38/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6291.1094 - mean_absolute_error: 42.3668 - val_loss: 1915.0089 - val_mean_absolute_error: 26.2728\n",
      "Epoch 39/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6876.1162 - mean_absolute_error: 41.4122 - val_loss: 1823.7488 - val_mean_absolute_error: 24.9085\n",
      "Epoch 40/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5257.6558 - mean_absolute_error: 39.7952 - val_loss: 1976.6506 - val_mean_absolute_error: 26.9501\n",
      "Epoch 41/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4883.4409 - mean_absolute_error: 39.6123 - val_loss: 1937.9094 - val_mean_absolute_error: 26.5655\n",
      "Epoch 42/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4734.5015 - mean_absolute_error: 39.9085 - val_loss: 1821.8781 - val_mean_absolute_error: 25.3321\n",
      "Epoch 43/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4371.7427 - mean_absolute_error: 37.7822 - val_loss: 2078.8899 - val_mean_absolute_error: 27.8537\n",
      "Epoch 44/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3945.2517 - mean_absolute_error: 38.0559 - val_loss: 1901.5397 - val_mean_absolute_error: 26.0012\n",
      "Epoch 45/45\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4326.3325 - mean_absolute_error: 38.2852 - val_loss: 1868.9011 - val_mean_absolute_error: 25.6820\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 13:00:07,546] Trial 96 finished with value: 25.681983163619044 and parameters: {'layer_1': 6, 'layer_2': 5, 'layer_3': 8, 'learning_rate': 0.0029914820127904945, 'dropout_rate': 0.04648462499500445, 'epoch': 45, 'batch_size': 75, 'optimizer': 'RMSprop'}. Best is trial 92 with value: 21.152993560005722.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 74096.6797 - mean_absolute_error: 215.7612 - val_loss: 70000.9609 - val_mean_absolute_error: 214.6485\n",
      "Epoch 2/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71269.1719 - mean_absolute_error: 214.5244 - val_loss: 70000.2344 - val_mean_absolute_error: 214.6463\n",
      "Epoch 3/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70516.4375 - mean_absolute_error: 213.8422 - val_loss: 69998.7578 - val_mean_absolute_error: 214.6410\n",
      "Epoch 4/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75462.0234 - mean_absolute_error: 217.4931 - val_loss: 69996.7500 - val_mean_absolute_error: 214.6332\n",
      "Epoch 5/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74355.8203 - mean_absolute_error: 217.7405 - val_loss: 69994.4062 - val_mean_absolute_error: 214.6242\n",
      "Epoch 6/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70541.3359 - mean_absolute_error: 213.1718 - val_loss: 69991.6484 - val_mean_absolute_error: 214.6137\n",
      "Epoch 7/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72347.5547 - mean_absolute_error: 216.1658 - val_loss: 69988.4453 - val_mean_absolute_error: 214.6019\n",
      "Epoch 8/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74221.1094 - mean_absolute_error: 216.9787 - val_loss: 69984.8906 - val_mean_absolute_error: 214.5893\n",
      "Epoch 9/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73403.7969 - mean_absolute_error: 216.2274 - val_loss: 69980.5391 - val_mean_absolute_error: 214.5749\n",
      "Epoch 10/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75508.4297 - mean_absolute_error: 216.6768 - val_loss: 69975.5859 - val_mean_absolute_error: 214.5594\n",
      "Epoch 11/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71034.8281 - mean_absolute_error: 214.0646 - val_loss: 69970.3984 - val_mean_absolute_error: 214.5429\n",
      "Epoch 12/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 74285.9375 - mean_absolute_error: 216.6165 - val_loss: 69964.6719 - val_mean_absolute_error: 214.5248\n",
      "Epoch 13/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72636.6641 - mean_absolute_error: 215.2298 - val_loss: 69958.5312 - val_mean_absolute_error: 214.5054\n",
      "Epoch 14/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 74275.6016 - mean_absolute_error: 214.9222 - val_loss: 69951.8359 - val_mean_absolute_error: 214.4845\n",
      "Epoch 15/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71392.7422 - mean_absolute_error: 215.3898 - val_loss: 69944.5000 - val_mean_absolute_error: 214.4625\n",
      "Epoch 16/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72001.5469 - mean_absolute_error: 215.2589 - val_loss: 69936.1562 - val_mean_absolute_error: 214.4389\n",
      "Epoch 17/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71712.9531 - mean_absolute_error: 214.8704 - val_loss: 69926.6875 - val_mean_absolute_error: 214.4134\n",
      "Epoch 18/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70604.8359 - mean_absolute_error: 212.1598 - val_loss: 69916.8594 - val_mean_absolute_error: 214.3871\n",
      "Epoch 19/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75017.7500 - mean_absolute_error: 218.2692 - val_loss: 69905.7969 - val_mean_absolute_error: 214.3584\n",
      "Epoch 20/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73976.5859 - mean_absolute_error: 217.3427 - val_loss: 69893.7422 - val_mean_absolute_error: 214.3278\n",
      "Epoch 21/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72147.5469 - mean_absolute_error: 215.6341 - val_loss: 69879.5859 - val_mean_absolute_error: 214.2952\n",
      "Epoch 22/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71850.2734 - mean_absolute_error: 214.8457 - val_loss: 69864.9609 - val_mean_absolute_error: 214.2614\n",
      "Epoch 23/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73377.0859 - mean_absolute_error: 217.7805 - val_loss: 69848.4922 - val_mean_absolute_error: 214.2254\n",
      "Epoch 24/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72389.4062 - mean_absolute_error: 215.1914 - val_loss: 69831.3906 - val_mean_absolute_error: 214.1879\n",
      "Epoch 25/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71536.6953 - mean_absolute_error: 215.8916 - val_loss: 69812.8516 - val_mean_absolute_error: 214.1480\n",
      "Epoch 26/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 69597.3750 - mean_absolute_error: 212.1655 - val_loss: 69793.7422 - val_mean_absolute_error: 214.1069\n",
      "Epoch 27/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71467.8516 - mean_absolute_error: 214.8421 - val_loss: 69774.4375 - val_mean_absolute_error: 214.0648\n",
      "Epoch 28/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72253.2734 - mean_absolute_error: 213.8746 - val_loss: 69754.6172 - val_mean_absolute_error: 214.0212\n",
      "Epoch 29/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71843.3750 - mean_absolute_error: 213.8286 - val_loss: 69734.0703 - val_mean_absolute_error: 213.9763\n",
      "Epoch 30/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71035.9219 - mean_absolute_error: 213.8587 - val_loss: 69712.7656 - val_mean_absolute_error: 213.9296\n",
      "Epoch 31/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72830.9688 - mean_absolute_error: 216.1997 - val_loss: 69690.1250 - val_mean_absolute_error: 213.8807\n",
      "Epoch 32/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70542.9297 - mean_absolute_error: 212.1955 - val_loss: 69666.9297 - val_mean_absolute_error: 213.8300\n",
      "Epoch 33/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73233.7578 - mean_absolute_error: 216.5330 - val_loss: 69644.1250 - val_mean_absolute_error: 213.7792\n",
      "Epoch 34/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73733.8516 - mean_absolute_error: 213.9712 - val_loss: 69620.1250 - val_mean_absolute_error: 213.7261\n",
      "Epoch 35/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73928.3516 - mean_absolute_error: 215.2792 - val_loss: 69594.7812 - val_mean_absolute_error: 213.6703\n",
      "Epoch 36/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67249.6250 - mean_absolute_error: 209.8454 - val_loss: 69569.3438 - val_mean_absolute_error: 213.6138\n",
      "Epoch 37/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72416.2422 - mean_absolute_error: 214.1577 - val_loss: 69540.4141 - val_mean_absolute_error: 213.5512\n",
      "Epoch 38/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73659.0000 - mean_absolute_error: 216.0138 - val_loss: 69512.2500 - val_mean_absolute_error: 213.4893\n",
      "Epoch 39/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71199.2109 - mean_absolute_error: 213.1148 - val_loss: 69483.5391 - val_mean_absolute_error: 213.4261\n",
      "Epoch 40/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74752.2109 - mean_absolute_error: 218.0300 - val_loss: 69452.8125 - val_mean_absolute_error: 213.3586\n",
      "Epoch 41/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 74747.9375 - mean_absolute_error: 216.1837 - val_loss: 69420.7891 - val_mean_absolute_error: 213.2883\n",
      "Epoch 42/42\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72541.7812 - mean_absolute_error: 214.7282 - val_loss: 69386.2500 - val_mean_absolute_error: 213.2130\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 13:00:12,884] Trial 97 finished with value: 213.98199870411477 and parameters: {'layer_1': 7, 'layer_2': 6, 'layer_3': 8, 'learning_rate': 7.312611849599388e-05, 'dropout_rate': 0.020353295923836598, 'epoch': 42, 'batch_size': 91, 'optimizer': 'Adam'}. Best is trial 92 with value: 21.152993560005722.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 67550.7812 - mean_absolute_error: 208.9381 - val_loss: 60102.8594 - val_mean_absolute_error: 196.9562\n",
      "Epoch 2/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56251.0820 - mean_absolute_error: 187.7090 - val_loss: 24379.8086 - val_mean_absolute_error: 123.2468\n",
      "Epoch 3/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26552.4766 - mean_absolute_error: 118.4382 - val_loss: 12136.7080 - val_mean_absolute_error: 86.2449\n",
      "Epoch 4/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15333.9570 - mean_absolute_error: 87.2454 - val_loss: 9556.7549 - val_mean_absolute_error: 75.2349\n",
      "Epoch 5/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14337.5918 - mean_absolute_error: 76.8155 - val_loss: 7361.2583 - val_mean_absolute_error: 63.5701\n",
      "Epoch 6/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8863.8018 - mean_absolute_error: 61.6604 - val_loss: 5612.3726 - val_mean_absolute_error: 53.3744\n",
      "Epoch 7/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8068.6606 - mean_absolute_error: 56.0631 - val_loss: 4607.9033 - val_mean_absolute_error: 46.4469\n",
      "Epoch 8/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5949.0757 - mean_absolute_error: 49.0686 - val_loss: 4332.4009 - val_mean_absolute_error: 45.1895\n",
      "Epoch 9/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6872.5332 - mean_absolute_error: 48.2625 - val_loss: 3646.0632 - val_mean_absolute_error: 39.3459\n",
      "Epoch 10/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9197.9502 - mean_absolute_error: 48.9684 - val_loss: 3397.6934 - val_mean_absolute_error: 37.2407\n",
      "Epoch 11/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6154.2827 - mean_absolute_error: 44.5779 - val_loss: 3194.0496 - val_mean_absolute_error: 36.3479\n",
      "Epoch 12/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8258.0000 - mean_absolute_error: 45.6203 - val_loss: 2981.3748 - val_mean_absolute_error: 34.7732\n",
      "Epoch 13/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4651.8452 - mean_absolute_error: 41.5546 - val_loss: 2778.7583 - val_mean_absolute_error: 33.1809\n",
      "Epoch 14/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5055.7310 - mean_absolute_error: 41.4495 - val_loss: 2904.4324 - val_mean_absolute_error: 34.4558\n",
      "Epoch 15/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5847.5508 - mean_absolute_error: 40.6274 - val_loss: 2851.6814 - val_mean_absolute_error: 34.2517\n",
      "Epoch 16/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4214.3999 - mean_absolute_error: 39.1388 - val_loss: 2395.8894 - val_mean_absolute_error: 29.9013\n",
      "Epoch 17/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5667.3408 - mean_absolute_error: 39.3445 - val_loss: 2268.1565 - val_mean_absolute_error: 28.7117\n",
      "Epoch 18/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5553.0181 - mean_absolute_error: 40.5258 - val_loss: 2232.3562 - val_mean_absolute_error: 28.7230\n",
      "Epoch 19/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5064.7520 - mean_absolute_error: 39.0638 - val_loss: 2076.4116 - val_mean_absolute_error: 27.1763\n",
      "Epoch 20/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5382.7217 - mean_absolute_error: 38.4634 - val_loss: 1988.7881 - val_mean_absolute_error: 26.2420\n",
      "Epoch 21/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3832.8640 - mean_absolute_error: 36.0233 - val_loss: 1944.1202 - val_mean_absolute_error: 25.6153\n",
      "Epoch 22/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5653.3433 - mean_absolute_error: 36.0877 - val_loss: 1908.8236 - val_mean_absolute_error: 25.5443\n",
      "Epoch 23/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3477.9861 - mean_absolute_error: 35.0087 - val_loss: 1942.9249 - val_mean_absolute_error: 25.7968\n",
      "Epoch 24/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4579.5166 - mean_absolute_error: 35.1264 - val_loss: 1944.6085 - val_mean_absolute_error: 25.9922\n",
      "Epoch 25/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4559.7886 - mean_absolute_error: 36.4765 - val_loss: 1927.9193 - val_mean_absolute_error: 26.0161\n",
      "Epoch 26/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4000.1694 - mean_absolute_error: 35.3514 - val_loss: 2104.6301 - val_mean_absolute_error: 27.5290\n",
      "Epoch 27/39\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5259.6357 - mean_absolute_error: 36.0223 - val_loss: 2188.7068 - val_mean_absolute_error: 28.3703\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 13:00:16,966] Trial 98 finished with value: 25.976955126041172 and parameters: {'layer_1': 7, 'layer_2': 5, 'layer_3': 7, 'learning_rate': 0.00414684055229541, 'dropout_rate': 0.03549103468359051, 'epoch': 39, 'batch_size': 55, 'optimizer': 'RMSprop'}. Best is trial 92 with value: 21.152993560005722.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 49819.9688 - mean_absolute_error: 171.0736 - val_loss: 9999.3721 - val_mean_absolute_error: 70.2618\n",
      "Epoch 2/46\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10476.4775 - mean_absolute_error: 62.1929 - val_loss: 4077.4197 - val_mean_absolute_error: 41.5356\n",
      "Epoch 3/46\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5203.3579 - mean_absolute_error: 40.2117 - val_loss: 3424.6035 - val_mean_absolute_error: 39.1772\n",
      "Epoch 4/46\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5133.0908 - mean_absolute_error: 35.4441 - val_loss: 2365.9390 - val_mean_absolute_error: 29.1987\n",
      "Epoch 5/46\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3173.1890 - mean_absolute_error: 29.6028 - val_loss: 2046.2325 - val_mean_absolute_error: 26.2618\n",
      "Epoch 6/46\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2512.0908 - mean_absolute_error: 26.9793 - val_loss: 1966.5854 - val_mean_absolute_error: 25.9184\n",
      "Epoch 7/46\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2449.0200 - mean_absolute_error: 25.6975 - val_loss: 1752.0479 - val_mean_absolute_error: 23.5153\n",
      "Epoch 8/46\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3642.8103 - mean_absolute_error: 25.8733 - val_loss: 1692.5078 - val_mean_absolute_error: 22.5669\n",
      "Epoch 9/46\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1781.9406 - mean_absolute_error: 23.6574 - val_loss: 1670.0779 - val_mean_absolute_error: 22.6390\n",
      "Epoch 10/46\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2690.2620 - mean_absolute_error: 24.2931 - val_loss: 1630.1984 - val_mean_absolute_error: 21.8292\n",
      "Epoch 11/46\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1814.1545 - mean_absolute_error: 22.7944 - val_loss: 1651.6292 - val_mean_absolute_error: 22.7743\n",
      "Epoch 12/46\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2086.0720 - mean_absolute_error: 23.8242 - val_loss: 1614.3940 - val_mean_absolute_error: 21.8181\n",
      "Epoch 13/46\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2386.3748 - mean_absolute_error: 24.4922 - val_loss: 2227.6086 - val_mean_absolute_error: 33.6933\n",
      "Epoch 14/46\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2368.6914 - mean_absolute_error: 25.2721 - val_loss: 1646.6044 - val_mean_absolute_error: 21.7218\n",
      "Epoch 15/46\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2580.7876 - mean_absolute_error: 23.3234 - val_loss: 1646.0931 - val_mean_absolute_error: 21.5757\n",
      "Epoch 16/46\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2616.7439 - mean_absolute_error: 23.3935 - val_loss: 1638.6237 - val_mean_absolute_error: 22.5110\n",
      "Epoch 17/46\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1873.6562 - mean_absolute_error: 22.4573 - val_loss: 1639.4718 - val_mean_absolute_error: 21.4684\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 13:00:19,634] Trial 99 finished with value: 22.362870283837616 and parameters: {'layer_1': 7, 'layer_2': 6, 'layer_3': 8, 'learning_rate': 0.01419476049541233, 'dropout_rate': 0.0006866488745314436, 'epoch': 46, 'batch_size': 80, 'optimizer': 'RMSprop'}. Best is trial 92 with value: 21.152993560005722.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value (MAE): 21.152993560005722\n",
      "Best parameters: {'layer_1': 7, 'layer_2': 5, 'layer_3': 8, 'learning_rate': 0.008009635619625224, 'dropout_rate': 0.0006149438353628724, 'epoch': 45, 'batch_size': 90, 'optimizer': 'RMSprop'}\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adadelta, Adagrad, Adam, RMSprop, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "\n",
    "\n",
    "# Neural Network\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "def objective_neural_network(trial):\n",
    "    layer_1 = trial.suggest_int(\"layer_1\", 2, 8)\n",
    "    layer_2 = trial.suggest_int(\"layer_2\", 2, 8)\n",
    "    layer_3 = trial.suggest_int(\"layer_3\", 2, 8)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.0, 0.5)\n",
    "    epoch = trial.suggest_int(\"epoch\", 10, 50)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 1, 100)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", ['Adadelta', 'Adagrad', 'Adam', 'RMSprop', 'SGD'])\n",
    "\n",
    "    optimizer_map = {\n",
    "        'Adadelta': Adadelta(learning_rate=learning_rate),\n",
    "        'Adagrad': Adagrad(learning_rate=learning_rate),\n",
    "        'Adam': Adam(learning_rate=learning_rate),\n",
    "        'RMSprop': RMSprop(learning_rate=learning_rate),\n",
    "        'SGD': SGD(learning_rate=learning_rate)\n",
    "    }\n",
    "\n",
    "    optimizer = optimizer_map[optimizer_name]\n",
    "\n",
    "    neural_network = Sequential()\n",
    "    neural_network.add(Dense(layer_1, input_shape=(X_train_scaled.shape[1],), activation='relu'))\n",
    "    neural_network.add(Dropout(dropout_rate))\n",
    "    neural_network.add(Dense(layer_2, activation='relu'))\n",
    "    neural_network.add(Dropout(dropout_rate))\n",
    "    neural_network.add(Dense(layer_3, activation='relu'))\n",
    "    neural_network.add(Dropout(dropout_rate))\n",
    "    neural_network.add(Dense(1, activation='relu'))\n",
    "\n",
    "    neural_network.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mean_absolute_error'])\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    neural_network.fit(X_train_scaled, y_train, epochs=epoch, batch_size=batch_size, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "    y_pred = neural_network.predict(X_train_scaled)\n",
    "    mae = mean_absolute_error(y_train, y_pred)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective_neural_network, n_trials=100)\n",
    "\n",
    "print(\"Best value (MAE):\", study.best_value)\n",
    "print(\"Best parameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_pred = stacking_regressor_rf_xgb.predict(test_df.drop(columns=[\"id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(test_df[\"id\"])\n",
    "submission_df[\"Hardness\"] = test_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "predicting_model = \"stack-rf-xgbr\"\n",
    "submission_df.to_csv((\"submission-\" + predicting_model + datetime.now().strftime(\"-%Y %m %d_%Hh %Mm %Ss\") + \".csv\") , index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
